{"pages":[],"posts":[{"title":"【阻塞队列】-- ArrayBlockingQueue源码解析(jdk1.8)","text":"概述​ ArrayBlockingQueue是由数组组成的一个单向有界阻塞队列。ArrayBlockingQueue内部只有一把锁ReentrantLock，通过ReentrantLock的Condition来控制内部的生产与消费。ArrayBlockingQueue创建时必须指定容量，当队列满后会阻塞生产的线程，队列空时会阻塞消费的线程。 结构特点 ArrayBlockingQueue继承了抽象队列，并且实现了阻塞队列，因此它具备队列的所有基本特性。 重要属性123456789101112131415161718192021222324252627public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { //用于存储内部的元素 final Object[] items; //下一个消费坐标 int takeIndex; //下一个生产坐标 int putIndex; //当前队列中的元素数 int count; //重入锁 final ReentrantLock lock; //队列为空的时候，会阻塞消费的线程 private final Condition notEmpty; //队列已满的时候，会阻塞消费的线程 private final Condition notFull; //内部实现的迭代器，用于迭代items数组 transient Itrs itrs = null;} 常用方法构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243//带容量的构造方法，默认使用非公平锁public ArrayBlockingQueue(int capacity) { this(capacity, false);}//可以指定容量与是否公平锁的构造方法public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();}//可以指定容量与是否公平锁的构造方法，构造后默认向队列中填充元素public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) { this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock(); &lt;1&gt;.// Lock only for visibility, not mutual exclusion try { int i = 0; try { //遍历集合插入到队列中 for (E e : c) { checkNotNull(e); items[i++] = e; } } catch (ArrayIndexOutOfBoundsException ex) { //如果传入的集合长度大于我们设置的容量值，那么会抛出异常 throw new IllegalArgumentException(); } //记录当前队列中元素个数 count = i; //如果队列已经满了，那么下一个生产的数据就存放在items数组的0下标处，也就是从头开始 //如果没满，那么i就是下一次生产数据插入的位置 putIndex = (i == capacity) ? 0 : i; } finally { lock.unlock(); }} 上面第三个构造方法中，&lt;1&gt;处，lock.lock()方法处加了一行注释Lock only for visibility, not mutual exclusion，这句话的意思是说，这个锁的操作并不是为了互斥操作，而是保证其可见性。当我们把集合中的数据全部插入队列中之后，我们会修改相应的count以及putIndex的数值，但是如果我们没有加锁，那么在集合插入完成前count以及putIndex没有完成初始化操作的时候如果有其他线程进行了插入等操作的话，会造成数据同步问题从而使得数据不准确。 生产方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798//向队列中添加元素，如果队列已满直接抛出异常public boolean add(E e) { //调用的父类AbstractQueue.class的add方法 return super.add(e);}//父类AbstractQueue.class的add方法public boolean add(E e) { //会间接调用offer方法 if (offer(e)) return true; else //如果失败，那么抛出队列已满异常 throw new IllegalStateException(\"Queue full\");}//向队列中添加元素，获取锁后立即得到插入结果，不会阻塞public boolean offer(E e) { //队列中不允许添加null元素 checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try { //如果容量满了，立即返回false if (count == items.length) return false; else { //向队列添加元素 enqueue(e); return true; } } finally { lock.unlock(); }}//向队列中添加元素，队列满后会阻塞，响应中断public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; //上锁，响应中断 lock.lockInterruptibly(); try { //如果队列满了，立刻阻塞，等待被释放 while (count == items.length) notFull.await(); //释放后，添加元素到队列中 enqueue(e); } finally { lock.unlock(); }}//向队列中添加元素，队列满后超时阻塞，响应中断public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { checkNotNull(e); //计算超时时间 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) { if (nanos &lt;= 0) //超时直接返回false return false; //如果队列满了，超时阻塞 nanos = notFull.awaitNanos(nanos); } enqueue(e); return true; } finally { lock.unlock(); } }//检查插入的元素是否为nullprivate static void checkNotNull(Object v) { if (v == null) throw new NullPointerException();}//入队private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //将元素放入当前putIndex下标 items[putIndex] = x; //++putIndex记录下一次下表位置，如果到队尾了，那么重置下标为0 if (++putIndex == items.length) putIndex = 0; //元素数+1 count++; //有元素入队之后，释放队列不为空信号 notEmpty.signal();} 消费方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//消费数据，获取锁后立即返回状态public E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { //如果队列为空，返回null return (count == 0) ? null : dequeue(); } finally { lock.unlock(); }}//消费数据，如果队列为空会阻塞public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) //如果队列为空，直到队列有元素后，被唤醒 notEmpty.await(); //出队 return dequeue(); } finally { lock.unlock(); }}//消费数据，如果队列为空会超时阻塞public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) { //超时后，直接返回null if (nanos &lt;= 0) return null; //等待超时 nanos = notEmpty.awaitNanos(nanos); } return dequeue(); } finally { lock.unlock(); }}//获取锁定后立刻返回元素，当队列为空时，返回nullpublic E peek() { final ReentrantLock lock = this.lock; lock.lock(); try { return itemAt(takeIndex); // null when queue is empty } finally { lock.unlock(); }}//出队private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") //记录要出对的元素 E x = (E) items[takeIndex]; items[takeIndex] = null; //计算下一次消费的坐标，如果到队列的尾部了，那么从头开始 if (++takeIndex == items.length) takeIndex = 0; //元素数-1 count--; //判断当前迭代器是否为空，如果不为空，那么更新迭代器数据 if (itrs != null) itrs.elementDequeued(); //有元素入队之后，释放队列未满信号 notFull.signal(); return x;}void unlink(Node&lt;E&gt; x) { // assert lock.isHeldByCurrentThread(); Node&lt;E&gt; p = x.prev; Node&lt;E&gt; n = x.next; if (p == null) { unlinkFirst(); } else if (n == null) { unlinkLast(); } else { p.next = n; n.prev = p; x.item = null; // Don't mess with x's links. They may still be in use by // an iterator. --count; notFull.signal(); }} 阻塞队列全部讲完之后，会专门出一章讲阻塞队列中的迭代器。 总结​ 以上就是ArrayBlockingQueue解析的全部内容了。ArrayBlockingQueue通过一把重入锁创建两条等待队列，分别用于生产与消费的情况，通过putIndex与takeIndex用于记录下一个元素入队与出队处的下标。","link":"/2020/03/13/ArrayBlockingQueue/"},{"title":"【阻塞队列】-- BlockingQueue总结(jdk1.8)","text":"概述​ BlockingQueue即是我们所说的阻塞队列，它是一个接口，继承自Queue接口。后面我们要讲的阻塞队列，都实现自该接口。包括： ArrayBlockingQueue LinkedBlockingQueue LinkedBlockingDeque(实现了BlockingDeque，BlockingDeque继承自BlockingQueue) PriorityBlockingQueue … 方法​ BlockingQueue 具有不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。而通过BlockingQueue 实现的阻塞队列，也保留了这些特性。 生产方法123456789101112//向队列中添加元素，如果队列已满直接抛出IllegalStateException异常boolean add(E e);//向队列中添加元素，如果队列已满返回falseboolean offer(E e);//向队列中添加元素，队列已满会阻塞等待，响应中断void put(E e) throws InterruptedException;//向队列中添加元素，队列已满会超时阻塞等待，响应中断boolean offer(E e, long timeout, TimeUnit unit)throws InterruptedException; 消费方法123456789101112131415161718//获取并移除头部元素，如果队列为空会阻塞，响应中断E take() throws InterruptedException;//获取并移除头部元素，如果队列为空返回nullE poll();//获取并移除头部元素，如果队列为空超时阻塞，超时后返回null，并且可以响应中断E poll(long timeout, TimeUnit unit)throws InterruptedException;//获取头部元素，如果队列为空返回nullE peek();//一次从队列中获取所有元素到指定集合中int drainTo(Collection&lt;? super E&gt; c);//一次性获取指定元素个数到指定集合中，该方法不会阻塞int drainTo(Collection&lt;? super E&gt; c, int maxElements);","link":"/2020/03/13/BlockingQueue/"},{"title":"AbstractQueuedSynchronizer源码解析(jdk1.8)","text":"概述AQS(AbstractQueuedSynchronizer)以CLH锁为基础而设计，是并发编程中一个重要的框架类，用于构建锁和其他的同步组件。 我们熟知的ReentrantLock、Semaphore、CountDownLatch等就是基于AQS实现的。AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 CLH锁是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。 结构特点 继承自AbstractOwnableSynchronizer，为创建锁和相关同步器提供了基础。 AQS中还有一个ConditionObject内部类，提供了条件锁的同步实现，详见ConditionObject源码解析。 重要属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//node节点static final class Node { //标记符，表示在共享模式下的同步节点 static final Node SHARED = new Node(); //标记符，表示在独占模式下的同步节点 static final Node EXCLUSIVE = null; //等待状态值，表示同步队列中等待的线程等待超时或被中断 static final int CANCELLED = 1; //等待状态值，当前驱节点释放了同步状态后，会唤醒后驱节点 static final int SIGNAL = -1; //等待状态值，与Condition等待队列相关，表示该标识的结点处于等待队列中，结点的线程等待在Condition队列上 //当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁 static final int CONDITION = -2; //与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 static final int PROPAGATE = -3; //初始化状态，通过addWaiter传入的节点，waitStatus的值会为初始值0 volatile int waitStatus; //当前节点的前驱节点 volatile Node prev; //当前节点的后驱节点，当前节点在释放同步状态后会唤醒后驱节点 volatile Node next; //节点关联的线程，构造时被初始化、用完后置空 volatile Thread thread; //Condition等待队列中指向下一个等待节点 Node nextWaiter; //判断当前节点是否为共享节点 final boolean isShared() { return nextWaiter == SHARED; } //获取前驱节点 final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } //创建一个空节点，用于设置队列头 Node() { } //创建一个新的同步节点，储存传入的线程与同步节点，addWaiter中创建一个新同步节点会用到这个构造方法 //此时node的waitStatus = 0 Node(Thread thread, Node mode) { this.nextWaiter = mode; this.thread = thread; } //创建一个新的等待节点，储存传入的线程与等待状态，这个方法会在Condition等待队列使用 Node(Thread thread, int waitStatus) { this.waitStatus = waitStatus; this.thread = thread; }}//同步队列中的头节点，通过volatile修饰，保证多线程中的可见性private transient volatile Node head;//同步队列中的尾节点，通过volatile修饰，保证多线程中的可见性private transient volatile Node tail;//同步状态，state&gt;0，说明当前线程持有锁，对于独占锁来说，state代表着冲入次数，对于共享锁来说，state就是持有锁的线程数量//当state=0时，表示没有线程在使用资源，继承AQS的子类，通过state来判断获得锁的状态private volatile int state;//超时时间间隔阈值，在获取超时锁中使用，当前获取锁时间距离超时时间不足此间隔//那么没必要对当前线程阻塞，直接快速获取锁操作static final long spinForTimeoutThreshold = 1000L; 常用方法state方法12345678910111213//返回当前的同步状态值。state通过volatile，保证可见protected final int getState() { return state;}//设置同步状态值protected final void setState(int newState) { state = newState;}//通过cas方式设置state的值，成功返回true，否则返回falseprotected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} 独占锁的获取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309//通过该方法获取同步状态，对中断不响应，线程获取锁失败后，会进入同步队列中，//后续对线程进行中断操作，不会将线程从队列中移除public final void acquire(int arg) { //1.tryAcquire(arg)尝试获取锁，成功返回 //2.获取锁失败，通过addWaiter(Node.EXCLUSIVE)构建独占式的节点，加入到同步队列的尾端， //3.acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，通过自旋尝试从同步队列中获取锁 //如果获取不到，则阻塞节点中的线程 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();}//中断当前线程static void selfInterrupt() { Thread.currentThread().interrupt();}//通过该方法获取同步状态，对中断响应public final void acquireInterruptibly(int arg) throws InterruptedException { //如果线程被中断，抛出异常 if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) //获取锁响应中断 doAcquireInterruptibly(arg);}//典型的模板方法，留给子类实现protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();}//添加同步节点private Node addWaiter(Node mode) { //创建一个新节点，记录当前线程，节点类型 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure //记录尾节点 Node pred = tail; //如果尾节点存在，快速入队 if (pred != null) { //设置当前节点的前驱节点未原来的尾节点 node.prev = pred; //通过cas设置node为新的尾节点 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //如果尾节点不存在，或者快速入队失败，那么通过enq将node设置到队尾 enq(node); //返回新节点 return node;}//添加到同步节点末端，返回原尾节点private Node enq(final Node node) { //cas自旋，失败后快速重试 for (;;) { //记录队列尾 Node t = tail; //如果为null，说明当前队列未初始化 if (t == null) { // Must initialize //通过cas设置队列头 if (compareAndSetHead(new Node())) //成功后设置队列尾,此时head = tail,且都为空节点 //继续执行一下次循环，会将node节点，链接到队尾 //这么做的目的是为了保证头节点为空节点 tail = head; } else { //要入队的节点前驱指向尾节点 node.prev = t; //通过cas设置入队节点为尾节点 if (compareAndSetTail(t, node)) { //原未节点的next指向新的尾节点 t.next = node; //返回原尾节点 return t; } } }}//设置头节点private void setHead(Node node) { head = node; node.thread = null; node.prev = null;}//在同步队列中尝试获取锁final boolean acquireQueued(final Node node, int arg) { //失败标记 boolean failed = true; try { //中断标记 boolean interrupted = false; //自旋 for (;;) { //获取前驱节点，如果为null,立刻抛出NullPointException final Node p = node.predecessor(); //如果当前节点的前驱节点为头节点，那么尝试获取锁 if (p == head &amp;&amp; tryAcquire(arg)) { //获取锁成功，设置当前节点为新的头节点 setHead(node); //将原头节点的后驱节点指向置为null，便于GC回收 p.next = null; // help GC //设置失败标记为false，代表着获取锁成功 failed = false; //返回false，tryAcquire中if (!tryAcquire(arg) &amp;&amp;acquireQueued(addWaiter(Node.EXCLUSIVE), arg))会直接返回 return interrupted; } //无限重试，直到将前驱节点的waitStatus设置为-1，设置为-1后阻塞当前线程，等待前驱节点唤醒 //唤醒后会继续执行上面获取的方法，直到获取锁成功或者被阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //parkAndCheckInterrupt()返回true interrupted = true; } } finally { //如果标记失败为true,会取消获取锁 if (failed) //取消获取锁，在当前方法中不会执行，因为没有响应中断,无法跳出上面的for循环 //只有获取锁成功后，才会跳出，但是这时候，failed = false cancelAcquire(node); }}//获取锁，响应中断，方法跟上面acquireQueued差不多private void doAcquireInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //与acquireQueued中不同的地方，如果线程被中断了，会立马抛出InterruptedException //这就是说doAcquireInterruptibly响应中断的原因 throw new InterruptedException(); } } finally { //被中断后，取消获取锁 if (failed) cancelAcquire(node); }}//将node节点的前驱节点的waitStatus置为-1，如果前驱节点状态为取消，那么将所有被取消的前驱节点从//队列中去除private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { //记录前驱节点waitStatus状态值 int ws = pred.waitStatus; //如果前驱节点状态为Node.SIGNAL，返回true，后续会通过parkAndCheckInterrupt()将当前线程挂起 if (ws == Node.SIGNAL) return true; //如果前驱节点被取消，那么将前驱节点从队列中去除，链接前驱节点的上一个节点， //通过while继续判断上一个前驱节点，移除所有被取消的节点 if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { //如果前驱节点为0或者是共享状态，那么直接设置前驱节点为Node.SIGNAL //表示当前驱节点中记录的线程被释放后，要唤醒下一个节点记录的线程 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } //如果ws&gt;0,表示去除了所有被取消的节点，但是这一步还不能保证前驱节点的waitStatus值为Node.SIGNAL， //返回false后，acquireQueued中自旋会再一次调用此方法 return false;}//通过LockSupport将当前线程阻塞，唤醒后会返回interrupted的一个状态值private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();}//取消获取锁private void cancelAcquire(Node node) { //如果节点不存在直接返回 if (node == null) return; //将节点的线程置为null node.thread = null; //记录前驱节点 Node pred = node.prev; //如果前驱节点被取消，那么跳过，直到找到未被取消的前驱节点 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; //记录最后一个未被取消节点的后驱节点 Node predNext = pred.next; //将当前节点的waitStatus值置为1，也就是取消状态 node.waitStatus = Node.CANCELLED; //如果当前当前节点是尾节点，那么设置前驱节点为尾节点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { //设置尾节点成功后，将前驱节点的后驱置为null compareAndSetNext(pred, predNext, null); } else { int ws; //1.pred != head，当前节点的前驱节点,此时pred.waitStatus&lt;=0 //2.如果pred的状态不为为SIGNAL，那么通过cas设置前驱节点的waitStatus为Node.SIGNAL表示该节点记录的线程被释放时，要唤醒下一个节点 //前驱节点的记录的线程不为null if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) { //记录当前节点的后驱节点 Node next = node.next; //如果后驱节点不为null,且没有被取消 if (next != null &amp;&amp; next.waitStatus &lt;= 0) //那么链接前后驱节点 compareAndSetNext(pred, predNext, next); } else { //如果前驱节点为头节点，并且没有被阻塞，且状态为Node.SIGNAL，那么唤醒后驱节点 unparkSuccessor(node); } //断开node链接，帮助回收 node.next = node; // help GC }}//唤醒后驱节点private void unparkSuccessor(Node node) { //记录ws状态，cancelAcquire方法中，通过node.waitStatus = Node.CANCELLED;已经将waitStatus设置为1了 int ws = node.waitStatus; if (ws &lt; 0) //将waitStatus设置为初始值0 compareAndSetWaitStatus(node, ws, 0); //记录后驱节点 Node s = node.next; //如果后驱节点为null，或者被取消 if (s == null || s.waitStatus &gt; 0) { s = null; //从当前同步队列的末尾向前查找，直到前驱节点为null或者node，并记录当前节点为s for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } //如果后续的正常节点存在，那么释放后续节点 if (s != null) LockSupport.unpark(s.thread);}//获取超时锁public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); //如果获取锁失败，那么去同步队列中获取锁 return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);}//获取锁超时，响应中断，超过指定超时时间nanosTimeout还没有获取到锁，那么获取锁失败，从同步队列中将node移除，返回falseprivate boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { //如果超时时间&lt;=0,直接返回false if (nanosTimeout &lt;= 0L) return false; //获取等待过期时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { //自旋 for (;;) { //跟acquireQueued方法中一样处理 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return true; } //获取剩余时间 nanosTimeout = deadline - System.nanoTime(); //如果剩余时间&lt;=0,返回fasle，获取锁失败 if (nanosTimeout &lt;= 0L) //获取锁超时，返回false，此时failed = true，会进入到finally块中 return false; //将前驱节点的waitStatus设置为-1 //如果nanosTimeout&gt;1000L,则需要阻塞，如果nanosTimeout&lt;=1000 //那么直接进行下一次自旋获取锁，spinForTimeoutThreshold的时候很短， //这么短的时间就没有必要进行阻塞操作了，而是快速进入下一次自旋 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) //阻塞当前线程，直到nanosTimeout，进入下一次自旋， //会进入if (nanosTimeout &lt;= 0L)，返回false LockSupport.parkNanos(this, nanosTimeout); //如果线程在阻塞期间被中断了，抛出InterruptedException if (Thread.interrupted()) throw new InterruptedException(); } } finally { //中断线程或者锁超时后，取消获取锁操作 if (failed) cancelAcquire(node); }} 共享锁的获取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143public final void acquireShared(int arg) { //尝试获取共享锁 if (tryAcquireShared(arg) &lt; 0) //如果获取锁失败，到队列中获取共享锁 doAcquireShared(arg);}//获取共享锁，响应中断public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); }//尝试获取共享锁，留给子类实现protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException();}//获取共享锁，不响应中断private void doAcquireShared(int arg) { //创建一个共享锁状态节点，添加到队列末端 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; //自旋 for (;;) { //获取前驱节点 final Node p = node.predecessor(); if (p == head) { //如果当前节点为头节点，直接获取锁 int r = tryAcquireShared(arg); //如果获取锁成功 if (r &gt;= 0) { //acquireQueued中，这步仅仅通过setHead(node)设置了队列头 //共享锁中，获取到共享锁之后，除了要设置队头以外，还需要将判断是否还有剩余资源，如果 //有则唤醒后续共享锁 setHeadAndPropagate(node, r); p.next = null; // help GC //如果当前线程中断，设置当前线程状态为中断 if (interrupted) selfInterrupt(); failed = false; return; } } //获取锁失败后，将node节点的前驱节点的waitStatus设置为-1，阻塞当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //中断后设置interrupted = true interrupted = true; } } finally { //如果标识失败为true,则取消获取锁，此方法不响应中断，不会进入cancelAcquire方法 if (failed) cancelAcquire(node); }}//获取共享锁，响应中断private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //响应中断的关键，抛出异常，会进入finally块中，执行cancelAcquire方法 throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }}//获取共享锁超时，逻辑基本与排他锁一致private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { //与排他锁不同的一点，获取排他锁超时时上面也介绍过 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; } } nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); //超时后，判断是否被中断，抛出异常 if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }}private void setHeadAndPropagate(Node node, int propagate) { //记录头节点 Node h = head; // Record old head for check below //设置新的队列头 setHead(node); //1.propagate &gt; 0,说明当前还有剩余资源，释放后继节点 //2.原头节点h == null || h.waitStatus &lt; 0的时候，说明propagate = 0，头不存在或者为waitStatus&lt;0说明后继节点需要被唤醒 //3.h=head，通过上面设置新的头部后，此时再进行一遍操作2 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; //如果当前节点的后继节点不存在，或者后续节点为共享状态节点，那么释放锁 if (s == null || s.isShared()) //释放共享锁 doReleaseShared(); }} 释放锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public final boolean release(int arg) { //释放锁 if (tryRelease(arg)) { Node h = head; //释放锁成功后，如果头节点不为null(如果为null的话说明同步队列不存在)， //h.waitStatus != 0，如果h.waitStatus==0，说明没有后续节点，改变当前节点的状态，也不需要唤醒后续节点 if (h != null &amp;&amp; h.waitStatus != 0) //唤醒后驱节点 unparkSuccessor(h); //释放锁成功 return true; } //释放锁失败 return false;}//尝试释放锁，留给子类实现protected boolean tryRelease(int arg) { throw new UnsupportedOperationException();}public final boolean releaseShared(int arg) { //尝试释放锁 if (tryReleaseShared(arg)) { //如果失败，在同步队列中释放锁 doReleaseShared(); return true; } return false;}//释放共享锁private void doReleaseShared() { for (;;) { Node h = head; //如果头不存在，且头尾不相等（头尾相等说明当前同步队列中只有一个头节点） if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; //如果头结点的waitStatus为Node.SIGNAL，那么需要唤醒后续节点 if (ws == Node.SIGNAL) { //将头节点waitStatus置为初始值 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } //如果当前waitStatus状态为0，将当前状态设置为Node.PROPAGATE，表示当前线程处于可运行状态 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } //如果头节点没有被其他线程改变，说明当前操作已经成功了，直接跳出循环 if (h == head) // loop if head changed break; }} 总结上面解析了AQS中获取锁、释放锁使用CLH队列管理分配锁的流程。我们针对整个获取锁、释放锁的流程做一个总结。 获取锁: 通过acquire方法获取锁，真正获取锁的操作在tryAcquire方法中，直接使用tryAcquire会抛出UnsupportedOperationException异常，目的是留给子类实现。 通过tryAcquire方法成功后，会直接返回，如果失败，会通过addWaiter方法创建一个新节点加入到同步队列末尾，该节点保存着当前线程以及当前节点的模式（独占或共享） 通过addWaiter方法将节点加入到同步队列末尾后，会通过acquireQueued方法，不断检测当前节点前驱节点的状态(获取共享锁，会执行doAcquireShared方法，逻辑基本跟acquireQueued中方法一致，不过acquireQueued某个节点获取锁成功后，通过setHead方法将被释放的节点置为队头,而doAcquireShared方法会通过setHeadAndPropagate设置队头的同时，将获取锁的消息传播到下一个共享锁节点，释放下一个共享锁节点) 如果前驱节点为头节点，那么尝试获取锁，获取锁成功后，会将当前节点置为头部节点，失败会进入下一次自旋 如果前驱节点不为头节点，那么会通过shouldParkAfterFailedAcquire方法，将当前节点的前驱节点的waitStatus置为 -1 (表示前驱节点被释放后，需要唤醒后续节点，将前驱节点置为-1期间，还会检测同步队列中节点状态，将所有被取消的节点从队列中移除)，完成后会通过parkAndCheckInterrupt方法阻塞当前线程。 通过parkAndCheckInterrupt方法中LockSupport.park阻塞线程后，等待release方法或者中断唤醒，唤醒后返回中断状态。 如果我们使用的acquire方法不响应中断，那么返回中断状态之后，只会保留线程的中断状态 如果我们使用的acquire方法响应中断，那么返回中断状态为true之后(表示被中断唤醒)，那么会直接抛出InterruptedException异常，随即执行finally块中的cancelAcquire取消获取锁 cancelAcquire方法中，会从当前节点向头节点寻找最近一个未被取消的前驱节点A (从前后向前，也就是跳过前面被取消的节点)， 然后将当前取消节点的waitStatus置为1(表示被取消)，如果被取消的节点是同步队列的尾节点，那么直接从A开始截断。 如果当前节点不是尾部节点，判断A是否为头节点，如果不是头节点，那么将A的waitStatus设置为-1 如果A是头节点，说明当前被取消的节点，是同步节点的第一个要唤醒的节点，那么被取消后，下一个节点就是目前要被唤醒的节点，通过unparkSuccessor唤醒下一个节点。 释放锁： 通过release方法释放锁，跟acquire一样，主要释放锁的操作在tryRelease方法中，留给子类实现的。 release成功返回后，会通过unparkSuccessor唤醒下一个节点 unparkSuccessor如果当前节点waitStatus&lt; 0,会将当前节点的waitStatus设置为0，如果失败说明当前节点被取消了 记录下一个节点s,如果s不存在或者waitStatus&gt;0被取消，那么从同步队列尾端向头查找，直到找到s节点，记录最后一个正常的节点为s(也就是要释放的节点)，那么通过LockSupport.unpark释放s的线程(节点释放后，上面获取锁第6步会往下执行)，如果是共享锁，释放锁后，会执行上面获取锁第2步中的操作，将锁传递给下一个共享节点 AQS中获取锁、释放锁流程的总结到这里就结束了。本章只解析了AQS同步器锁的获取与释放，下一章解析AQS中的条件锁ConditionObject传送门。","link":"/2019/07/26/AbstractQueuedSynchronizer/"},{"title":"ArrayList源码解析(jdk1.8)","text":"概述 ArrayList是我们日常开发中比较常见的一个容器类。它底层由动态数组实现， 所以和数组一样，可以根据索引对容器对象所包含的元素，进行快速随机的查询操作 。Arraylist在中间位置插入或者删除元素时，需要对数据进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 结构特点 ArrayList 继承了AbstractList，实现了List。提供了相关的添加、删除、修改、遍历等功能。 实现了RandmoAccess接口，即提供了随机访问功能 ， 这样ArrayList使用for循环遍历元素要比使用迭代器遍历元素要快 。 实现了Cloneable接口， 表示 ArrayList 支持克隆。 实现了 Serializable 接口， 表示 ArrayList 支持序列化的功能 ，可用于网络传输。 ArrayList非线程安全，因此只适用于单线程中。如果在多线程，可使用 CopyOnWriteArrayList和Vector。 Vector方法和ArrayList基本相同，不过在修改方法上，都使用synchronized修饰。 而CopyOnWriteArrayList 采用写时拷贝策略，对其进行修改操作和元素迭代，都是在低层创建一个拷贝数组上进行，兼顾了线程安全的同时，又提高了并发性，性能比Vector有不少提高 。因此，多线程情况下推荐使用CopyOnWriteArrayList。 重要属性1234567891011121314151617public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;,RandomAccess, Cloneable, java.io.Serializable{ //默认容量大小 private static final int DEFAULT_CAPACITY = 10; //空数组，用于其他构造方式扩容，按照1.5倍扩容 private static final Object[] EMPTY_ELEMENTDATA = {}; //空数组，用于无参构造方法初始化，首次扩容为10 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; //底层储存元素的数组 transient Object[] elementData; //实际元素个数 private int size; //最大数组容量 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; } EMPTY_ELEMENTDATA与DEFAULTCAPACITY_EMPTY_ELEMENTDATA相比，扩容策略有所不同 常用方法无参数构造方法1234public ArrayList() { // 将底层数组指向DEFAULTCAPACITY_EMPTY_ELEMENTDATA this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;} 带容量大小的构造函数根据传入的initialCapacity创建ArrayList数组 123456789101112public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { //创建一个initialCapacity大小的数组，底层数组指向此数组 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //如果传入的参数为0，将底层数组指向EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); }} 带Collection对象的构造函数平时用的比较少的一个方法，通过集合类来生成ArrayLIst 1234567891011121314public ArrayList(Collection&lt;? extends E&gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) //c.toArray返回的类型不一定是一个Object[] if (elementData.getClass() != Object[].class) //创建一个size大小的新数组，将原本的elementData数据复制到数组中，最后elementData指向新数组，完成扩容。 elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. //将底层数组指向EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; }} 为什么说c.toArray返回的类型 不一定是一个Object[]。collection.toArray()理论上应该返回Object[]。然而使用Arrays.asList得到的list，其toArray方法返回的数组却不一定是Object[]类型的，而是返回它本来的类型。 add添加方法1234567891011121314151617181920212223242526public boolean add(E e) { //&lt;1&gt;.确保容器的当前容量足够容纳新增的元素 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;}//在指定位置添加元素public void add(int index, E element) { //校验位置是否在数组范围内 rangeCheckForAdd(index); //同&lt;1&gt;处 ensureCapacityInternal(size + 1); // Increments modCount!! /** * &lt;2&gt;.将数组elementData从下标index开始的元素，长度为size - index（即index到size之间的元素）复制 * 到数组elementData以index+1开始的位置，再将element放在数组index的位置。 */ System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;}private void rangeCheckForAdd(int index) { if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));} &lt;2&gt;处arraycopy()方法： public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) src:源数组 srcPos:原数组开始位置 dest:目标数组 desPos:目标数组位置 length: 需要复制的元素个数 复制指定的源数组src的数组，在指定的位置srcPos开始，到目标数组dest的指定位置destPos。一共需要复制length的元素个数。 扩容123456789101112131415161718192021222324252627282930313233//确保容器的当前容量足够容纳新增的元素private void ensureCapacityInternal(int minCapacity) { //&lt;1&gt;.当前实例是否通过无参构造方法生成，且为第一次扩容 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { //&lt;2&gt;.对比当前最大容量与默认的容量10对比，取大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } //确保是否需要扩容 ensureExplicitCapacity(minCapacity);}private void ensureExplicitCapacity(int minCapacity) { //&lt;3&gt;.增加数组修改次数 modCount++; // overflow-conscious code //如果当前所需要的容量，大于当前的容量那么就需要扩容 if (minCapacity - elementData.length &gt; 0) //扩容 grow(minCapacity);}private void grow(int minCapacity) { int oldCapacity = elementData.length; //容器的新长度将设置为原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //如果扩容后的长度小于当前所需的长度，那么设置当前容量的长度为所需长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //如果扩容后的长度大于的长度，判断当前长度是否超过限制的最大长度 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);} &lt;1&gt;处，如果elementData指向DEFAULTCAPACITY_EMPTY_ELEMENTDATA，则表示当前实例是通过无参构造方法创建的，且当前是第一次扩容。 &lt;2&gt;处，将需要的最小容量与默认容量对比，取大值，此时容量默认为10。ArrayList调用无参构造方式时，并没有直接将容量初始化为10，而是通过懒加载的形式 ，在第一次调用add时设置。 &lt;3&gt;，AbstractList包含一个modCount变量，它的初始值是0，当集合中的内容每被修改时（调用add， remove等方法），modCount加1 ,modCount的作用是什么，看看官方的说明： This field is used by the iterator and list iterator implementation returned by the iterator and listIterator methods. If the value of this field changes unexpectedly, the iterator (or list iterator) will throw a ConcurrentModificationException in response to the next, remove, previous, set or add operations. This provides fail-fast behavior, rather than non-deterministic behavior in the face of concurrent modification during iteration. 大概意思就是说：在使用迭代器遍历的时候，用来检查列表中的元素是否发生变化，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。前面也说过ArrayList是非线程安全的。 关于ArrayList的add()方法就分析到这里了， addAll(int index, Collection&lt;? extends E&gt; c)方法思路与上面两个方法基本一致，这里就不分析了。 remove移除方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123//通过下标移除方法public E remove(int index) { //校验参数合法性 rangeCheck(index); //增加数组修改次数 modCount++; //记录要移除的下标元素 E oldValue = elementData(index); //如果numMoved &gt; 0,说明要移除的不是数组末尾的元素，因此需要移动整个数组 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将原本最末尾的元素置为空，便于GC回收 elementData[--size] = null; // clear to let GC do its work //返回被移除的元素 return oldValue;}private void rangeCheck(int index) { //如果传入的下与或者等于当前元素个数，抛出下标越界异常 if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));}//通过指定元素移除public boolean remove(Object o) { if (o == null) { //通过遍历元素的方式，移除匹配元素 for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { //快速移除 fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;}//快速移除，与通过下标移除方法相比，少了一个参数校验的步骤private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work}//范围移除 protected void removeRange(int fromIndex, int toIndex) { modCount++; //获取移除的元素 int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work //记录移除后元素的个数 int newSize = size - (toIndex-fromIndex); //将新元素末尾位置到旧元素末尾位置之间的元素设置为null,便于GC回收 for (int i = newSize; i &lt; size; i++) { elementData[i] = null; } //重新设置容器中的元素个数 size = newSize; }// 删除c中存在的元素public boolean removeAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c); return batchRemove(c, false);}//删除c中不存在的元素public boolean retainAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c); return batchRemove(c, true);}//批量移除元素，complement ：是否移除在集合中存在的元素。retainAll默认为true，也就是做交集。如果为false，也就是做差集。private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) { final Object[] elementData = this.elementData; //r素遍历的位置 w写入覆盖的位置 int r = 0, w = 0; //判断方法是否执行成功的标记 boolean modified = false; try { //遍历所有元素 for (; r &lt; size; r++) // &lt;1&gt;.complement为false，相同的元素会被覆盖，不同的元素会往左边移动 // complement为true，相同的元素往左边移动，同时覆盖掉最前面不同的元素 if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; } finally { // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. //&lt;2&gt;正常情况下遍历完 r == size，r != size，说明发生了异常。 if (r != size) { System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; } // &lt;3&gt;.成功删除了元素，将后面空间置空 if (w != size) { // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; } } return modified;} 针对removeAll方法的情况，此时complement = false &lt;1&gt;. 看到elementData[w++] = elementData[r] 不要懵，跟着往下看。如果容器中存在该元素，并且complement = false时，那么不做处理。如果容器中不存在该元素，并且complement = false时，会把容器w位置的元素替换为r位置的元素，最后得到的结果就是，相同的元素全部被替换了。而不相同的元素，会慢慢跟着w的坐标往左靠… &lt;2&gt;.如果发生了异常。那么将r后面未处理的元素，加入到w的后面，也就是没有修改集合。 &lt;3&gt;.最后根据w的值来删除掉末尾多余的元素。 原数组：{1，2，3，4，5，6，7，8，9，10} c: {1，3，4} 我们来看看程序中 elementData[w++] = elementData[r] 的执行情况： 次数 c中是否存在 是否处理 处理前r和w当前值 处理后的值 处理后r和w的值 1 存在1 不处理 r = 0 ，w = 0 r = 1 ，w = 0 2 不存在2 处理 r = 1 ，w = 0 elementData[0] = 2 &gt;&gt; {2，2，3，4，5，6，7，8，9，10} r = 2 ，w = 1 3 存在3 不处理 r = 2 ，w = 1 r = 3 ，w = 1 4 存在4 不处理 r = 3 ，w = 1 r = 4 ，w = 1 5 不存在5 处理 r = 4， w = 1 elementData[1] = 5 &gt;&gt; {2，5，3，4，5，6，7，8，9，10} r = 5 ，w = 2 6 不存在6 处理 r = 5， w = 2 elementData[2] = 6 &gt;&gt; {2，5，6，4，5，6，7，8，9，10} r = 6 ，w = 3 7 不存在7 处理 r = 6 ，w = 3 elementData[3] = 7 &gt;&gt; {2，5，6，7，5，6，7，8，9，10} r = 7 ，w = 4 8 不存在8 处理 r =7 ，w = 4 elementData[4] = 8 &gt;&gt; {2，5，6，7，8，6，7，8，9，10} r = 8 ，w = 5 9 不存在9 处理 r = 8 ，w = 5 elementData[5] = 9 &gt;&gt; {2，5，6，7，8，9，7，8，9，10} r = 9 ，w = 6 10 不存在10 处理 r = 9 ，w = 6 elementData[6] = 10 &gt;&gt; {2，5，6，7，8，9，10，8，9，10} r = 10 ，w = 7 最终结果：{2，5，6，7，8，9，10，8，9，10} 针对retainAll方法的情况，此时complement = true &lt;1&gt;.如果容器中存在该元素，并且complement = true时，那么不做处理。如果容器中不存在该元素，并且complement = true时，会把容器w位置的元素替换为r位置的元素，最后得到的结果就是，相同的元素全部被替换了。而不相等的元素，会跟着w的坐标往左靠… 原数组：{1，2，3，4，5，6，7，8，9，10} c : {1，3，4} elementData[w++] = elementData[r] 的执行情况： 1 c中是否存在 是否处理 处理前r和w当前值 处理后的值 处理后r和w的值 2 存在1 处理 r = 0 ，w = 0 elementData[0] = 1 &gt;&gt; {1，2，3，4，5，6，7，8，9，10} r = 1 ，w = 1 3 不存在2 不处理 r = 1 ，w = 1 r = 2 ，w = 1 4 存在3 处理 r = 2 ，w = 1 elementData[1] = 1 &gt;&gt; {1，3，3，4，5，6，7，8，9，10} r = 3 ，w = 2 5 存在4 处理 r = 3 ，w = 2 elementData[2] = 1 &gt;&gt; {1，3，4，4，5，6，7，8，9，10} r = 4 ，w = 3 6 不存在5 不处理 r = 4 ，w = 3 r = 5 ，w = 3 接下来因为都不存在，所以后面都不会再处理了，最终结果：{1，3，4，4，5，6，7，8，9，10} &lt;3&gt;.同上处理方法 其他常用方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//通过下标获取元素public E get(int index) { //检查下标是否越界 rangeCheck(index); return elementData(index);}//通过元素寻找下标位置public int indexOf(Object o) { if (o == null) { for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; } return -1;}public Object[] toArray() { return Arrays.copyOf(elementData, size);}//将容器底层数组的元素复制到a中public &lt;T&gt; T[] toArray(T[] a) { if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //将整个底层数组的元素，复制到a中 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a;}public E set(int index, E element) { //检查下标是否越界 rangeCheck(index); //记录旧元素 E oldValue = elementData(index); //替换为指定元素 elementData[index] = element; return oldValue;}@Overridepublic void forEach(Consumer&lt;? super E&gt; action) { //传入的函数不能为空 Objects.requireNonNull(action); //记录期望值 final int expectedModCount = modCount; @SuppressWarnings(\"unchecked\") final E[] elementData = (E[]) this.elementData; final int size = this.size; //遍历执行，函数方法 for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) { action.accept(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); }} iterator迭代器 AbstractList 也提供了一个 Itr 的实现，但是 ArrayList 为了更好的性能，所以自己实现了 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172//ArrayList的内部类，实现了java.util.Iterator 接口 private class Itr implements Iterator&lt;E&gt; { //下一个要访问元素的下标 int cursor; // index of next element to return //返回的最后一个元素的索引（如果没有返回-1） int lastRet = -1; // index of last element returned; -1 if no such //期望修改次数 int expectedModCount = modCount; //是否存在下一个元素 public boolean hasNext() { //如果当前cursor == size说明已经在数组尾部了，无法继续迭代 return cursor != size; } //获取下一个元素 @SuppressWarnings(\"unchecked\") public E next() { //&lt;1&gt;.校验数组是否发生了变化 checkForComodification(); //记录下一个要访问的元素坐标 int i = cursor; //如果下一个元素的坐标，大于或者等于容器中元素的个数，说明获取不到元素了，抛出异常 if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; //如果i大于容器的总长度，说明可能发生并发操作，改变了elementData数组，抛出异常 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //更新下一个要访问元素的坐标 cursor = i + 1; //返回本次获取的元素，并将上一个访问元素的下标置为当前获取元素的坐标 return (E) elementData[lastRet = i]; } //移除元素 public void remove() { //参数不合法，抛出异常 if (lastRet &lt; 0) throw new IllegalStateException(); //同上 checkForComodification(); try { //调用当前容器的remove方法，移除当前元素 ArrayList.this.remove(lastRet); //元素移除后，元素的位置会被下一个元素取代，那么下一次操作的元素的位置，就是当前移除元素的位置 cursor = lastRet; //移除元素时，设置为 -1 ，表示最后访问的元素不存在了 lastRet = -1; /** * &lt;2&gt;.上面调用ArrayList.remove方法会更改modCount，这里需要同步当前的期望值， * 否则下一次调用该remove的方法时，就会出现expectedModCount不一致的情况， * 从而抛出ConcurrentModificationException异常 */ expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { /** * &lt;3&gt;.如果ArrayList.this.remove(lastRet)出现下标越界的情况， * 说明elementData数组的被修改，抛出ConcurrentModificationException异常 */ throw new ConcurrentModificationException(); } } //对每个元素执行某个操作 @Override @SuppressWarnings(\"unchecked\") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) { //传入的元素不能为null Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; //如果超过elementData元素长度，说明数组可能被修改，抛出异常 if (i &gt;= elementData.length) { throw new ConcurrentModificationException(); } while (i != size &amp;&amp; modCount == expectedModCount) { consumer.accept((E) elementData[i++]); } // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); } //迭代期间，如果修改次数与预期值不等，则抛出异常 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } }//ListItr继承自Itr，实现了ListIterator接口private class ListItr extends Itr implements ListIterator&lt;E&gt; { ListItr(int index) { super(); cursor = index; } //上一个元素是否存在 public boolean hasPrevious() { return cursor != 0; } //下一个元素的位置 public int nextIndex() { return cursor; } //上一个元素的位置 public int previousIndex() { return cursor - 1; } //上一个元素 @SuppressWarnings(\"unchecked\") public E previous() { //校验数组是否发生了变化 checkForComodification(); //得到上一个元素位置 int i = cursor - 1; //如果小于0抛出异常 if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; //如果超过elementData元素长度，说明数组可能被修改，抛出异常 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //将当前指针前移 cursor = i; return (E) elementData[lastRet = i]; } //设置当前坐标元素 public void set(E e) { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.set(lastRet, e); } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } //新增元素 public void add(E e) { checkForComodification(); try { //记录下一个操作的元素 int i = cursor; //插入元素 ArrayList.this.add(i, e); //更新下一个操作的元素 cursor = i + 1; //移除元素时，设置为 -1 ，表示最后访问的元素不存在了 lastRet = -1; //更新预期值 expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { //跟&lt;2&gt;一个逻辑 throw new ConcurrentModificationException(); } }} 上面列出了两种迭代器，分别为Iterator与ListIterator，ListIterator继承自Iterator。 ListIterator中对比Iterator增加的方法 增加了nextIndex()和previousIndex()方法，可以获取当前索引的位置。 添加hasPrevious()和previous()方法，可以通过遍历寻找上一个元素，实现反向遍历 增加了set()方法，可以实现元素的修改 增加了add()方法，可以向集合中，添加元素 创建迭代器的几种方式12345678910111213141516//无参构造方法创建iteratorpublic Iterator&lt;E&gt; iterator() { return new Itr();}//无参构造方法创建listIteratorpublic ListIterator&lt;E&gt; listIterator() { return new ListItr(0);}//创建listIterator，指定下一个要操作的下标public ListIterator&lt;E&gt; listIterator(int index) { if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(\"Index: \"+index); return new ListItr(index);} 经常用到过ArrayList的读者，可能知道它在遍历的时候，是不能通过 ArrayList的remove 方法来进行移除元素的操作，因为程序可能会抛出异常。为什么会发生这种情况，我们可以通过以上的源码分析一下。 前面我们已经分析过ArrayList的remove方法，该方法通过匹配后进入fastRemove方法： 12345678private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work} 执行方法会将ArrayList的操作记录数+1。此时,我们通过 iterator 迭代，调用iterator的next方法， 123456789public E next() { //&lt;1&gt;.校验数组是否发生了变化 checkForComodification();}final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException();} 该方法第一步就是调用checkForComodification()方法，检测当前的预期值expectedModCount与当前集合的修改次数是否一直，来判断当前数组是否被更改。如果此时我们调用ArrayList的remove方法来移除元素，那么在下一次调用next的时候，就会因为modCount != expectedModCount ，而抛出异常。 同样的情况，如果我们通过先创建一个iterator ，此时iterator 的expectedModCount会初始化为modCount，然后通过forEach循环中来remove元素，那么modCount的值发生改变，而 iterator 的expectedModCount 中的值没有变。那么我们接下来通过iterator 遍历，调用next的时候，程序就会抛出异常。所以无论我们通过以上两种方式，都会破坏ArrayList结构，让ArrayList变得不安全，最后在使用iterator的next的时候抛出异常。 我们来看看Itr中自带的remove方法: 12345678910111213public void remove() { //... 省略其他操作 checkForComodification(); //... try { //.... ArrayList.this.remove(lastRet); //... expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); }} 刚开始也会通过checkForComodification()方法检查，数组是否改变，接着ArrayList.this.remove(lastRet)调用外部ArrayList的remove方法，接着最重要的一步expectedModCount = modCount，更新expectedModCount 的值，保证预期值与操作数一致。与外部ArrayList的remove方法相比，iterator 的remove的方法增加了这一步，也就是这一步，保证了iterator 遍历时的操作安全。因此，在循环中操作Arraylist删除元素，最安全的方法就是调用内部iterator的remove方法。 ArrayLIst的源码分析到这里就结束了！🎉🎉撒花。如果各位小伙伴读完后，发现文章中有哪些错误或者不足之处，烦请各位在评论区告知笔者，将不胜感激！","link":"/2019/06/08/ArrayList/"},{"title":"ConcurrentHashMap源码解析(jdk1.8)","text":"概述ConcurrentHashMap是HashMap线程安全的版本。jdk1.8以前ConcurrentHashMap采用Segment分段锁技术，Segment继承自ReentrantLock，通过对Segment加锁实现并发操作。 而jdk1.8中抛弃了分段锁，使用CAS+synchronized,通过锁定桶中的头节点，使用cas自旋的方式，进行并发操作。好处在于，通过锁定node节点减少锁的粒度，提高并发效率。相较于HashTable中，锁定整个HashTable对象的方式，ConcurrentHash的优势就很明显了。也正是由于降低了锁的粒度，使得代码的实现变得更加的复杂。 结构特点 继承自AbstractMap,实现了ConcurrentMap接口 实现了 Serializable 接口， 表示 ConcurrentHash支持序列化的功能 ，可用于网络传输。 重要属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable { //最大容量 private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认容量 private static final int DEFAULT_CAPACITY = 16; //转化为数组允许的最大容量 static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //并发级别，遗留下来的，为兼容以前的版本 private static final int DEFAULT_CONCURRENCY_LEVEL = 16; //默认负载因子 private static final float LOAD_FACTOR = 0.75f; //链表转红黑树长度阈值，当链表长度&gt;8时，会转为红黑树 static final int TREEIFY_THRESHOLD = 8; //红黑树还原链表数量阈值，当红黑树数量&lt;6,会转为链表 static final int UNTREEIFY_THRESHOLD = 6; //链表转红黑树长度容量阈值，当哈希表中容量&gt;64,才会将链表转红黑树长度， //否则直接扩容而不是转化为红黑树，为了避免扩容与转化后红黑树之间的冲突，这个值不能小于64. static final int MIN_TREEIFY_CAPACITY = 64; //单个线程最小处理的桶数，扩容时，通过cpu处理器数量，来为每个处理器平均分配需要迁移的桶数 //如果桶数量较小，分配个桶个数&lt;16时，默认每个线程处理16个桶，单核默认处理16个桶 private static final int MIN_TRANSFER_STRIDE = 16; //表示扩容标记 private static int RESIZE_STAMP_BITS = 16; // 2^15-1，帮助扩容的最大线程数 private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1; //并行扩容线程数 private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS; //forwardingNode的hash值,占位符表示正在转移 static final int MOVED = -1; //TreeBin的hash值，当为红黑树节点时，进入特殊处理 static final int TREEBIN = -2; //ReservationNode的hash值，占位符 static final int RESERVED = -3; //0x7FFFFFFF是一个用16进制表示的整型,是整型里面的最大值，转化为二进制为 // 0111 1111 1111 1111 1111 1111 1111 1111，第一位表示正负符号，0表示正，1表示负 //在此类中参与hash计算时，可以保证hash为正数 static final int HASH_BITS = 0x7fffffff; //可用的处理器的数量 static final int NCPU = Runtime.getRuntime().availableProcessors(); //存放数据的table transient volatile Node&lt;K,V&gt;[] table; // 扩容后的新的table数组，为原table的2倍，只有在扩容时才有用 private transient volatile Node&lt;K,V&gt;[] nextTable; //ConcurrentHashMap中元素个数，但不一定是当前真实的元素个数，基于cas无锁定更新 private transient volatile long baseCount; /* * sizeCtl是一个用于同步多个线程的共享变量，用来控制table的初始化和扩容的操作，不同的值有不同的含义 * sizeCtl=0：表示没有指定初始容量。 * sizeCtl=-1,标记作用，告知其他线程，正在初始化。-N代表有N-1个线程正在 进行扩容 * sizeCtl&gt;0：如果table没有被初始化，表示接下来的真正的初始化操作中使用的容量， * table初始化之后，sizeCtl为扩容阈值。 */ private transient volatile int sizeCtl; //表示迁移时的下标，初始为扩容前的table的长度 private transient volatile int transferIndex; //通过cas实现的锁，用于counterCells计数时的锁定操作，0无锁，1获得锁 private transient volatile int cellsBusy; //计数器 private transient volatile CounterCell[] counterCells; private transient KeySetView&lt;K,V&gt; keySet; private transient ValuesView&lt;K,V&gt; values; private transient EntrySetView&lt;K,V&gt; entrySet; } node节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//ConcurrentHashMap内部node节点，用于储存桶内数据static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { //hash值 final int hash; //key值 final K key; //使用get获取val不需要加锁，是因为val通过volatile修饰，可以保证可见性 volatile V val; //后驱节点，通过volatile修饰，可以保证数组扩容时的可见性 volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.val = val; this.next = next; } public final K getKey() { return key; } public final V getValue() { return val; } public final int hashCode() { return key.hashCode() ^ val.hashCode(); } public final String toString(){ return key + \"=\" + val; } //不允许更新value public final V setValue(V value) { throw new UnsupportedOperationException(); } //判断是否同一节点 public final boolean equals(Object o) { Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); } //通过hash与key值，在当前链表中找到对应节点 Node&lt;K,V&gt; find(int h, Object k) { Node&lt;K,V&gt; e = this; if (k != null) { do { K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; } while ((e = e.next) != null); } return null; }} ForwardingNode节点扩容时存放的节点类型，代表此处已完成扩容。它包含一个nextTable指针，用于指向下一个桶。 123456789101112131415161718192021222324252627282930313233343536373839404142static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; { final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) { //hash值默认为-1，key, value, next都为null super(MOVED, null, null, null); this.nextTable = tab; } //从nextTable中查询节点 Node&lt;K,V&gt; find(int h, Object k) { // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) { Node&lt;K,V&gt; e; int n; //如果在当前桶中找不到元素，返回null if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) { int eh; K ek; //找到元素，直接返回 if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; //如果当前元素的hash值&lt;0 if (eh &lt; 0) { //如果当前为ForwardingNode节点 if (e instanceof ForwardingNode) { //将tab指向nextTable，结束自此循环，去nextTable中查找节点（当前要查找的节点已经迁移到nextTable中了） tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; } else //去树节点中查找 return e.find(h, k); } //如果到尾部，还找不到匹配的元素，直接返回null if ((e = e.next) == null) return null; } } }} 常用方法构造方法123456789101112131415161718192021222324252627282930313233343536//无参构造方法public ConcurrentHashMap() {} //指定容量大小public ConcurrentHashMap(int initialCapacity) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); //sizeCtl为初始容量 this.sizeCtl = cap;}public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) { //sizeCtl为默认初始容量 this.sizeCtl = DEFAULT_CAPACITY; putAll(m);}public ConcurrentHashMap(int initialCapacity, float loadFactor) { this(initialCapacity, loadFactor, 1);}public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { //校验参数合法性 if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //初始容量最小为1 if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads //通过传入的长度/加载因子，可以计算一个&gt;=阈值的数，保证本次不会触发扩容 long size = (long)(1.0 + (long)initialCapacity / loadFactor); //计算初始容量 int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;} tableSizeFor方法123456789101112131415161718192021/* * 计算扩容时的阈值，通过位运算，来计算最接近且大于当前输入值的2的幂次方数 * 例如传入的初始容量initialCapacity=7时，返回 8 * initialCapacity = 9，返回 16 */static final int tableSizeFor(int cap) { //假如传入的cap为61，那么 n = 60 int n = cap - 1; // n |= n &gt;&gt;&gt; 1 相当于n = n | n &gt;&gt;&gt; 1,向右边移动1位 // 0111100移动一位后，n = 0111100 | 011110, n = 0111110 n |= n &gt;&gt;&gt; 1; //0111110移动两位后，n = 0111110 || 0011110，n = 0111111 //此时所有的低位都为1，无论怎么位移这个数通过|运算后这个值，都不会再改变了 //此时111111转化为十进制为63 n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; //返回n + 1 = 64 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 上面简单的说明了，该方法是如何通过|运算与位移,来找到最接近输入值的2的幂次方数。为什么最后要一直写到 n |= n &gt;&gt;&gt; 16,int的范围在-2^31 ~ 2^31-1,因此最大2次幂数为2^30,也就是当前容量默认的最大值MAXIMUM_CAPACITY，代码1 + 2 + 4 + 8 + 16 = 31一共向右移了31位，是为了保证高位1以下的低位都会变为1。 spread方法1234static final int spread(int h) { //右移16位与原hashcode进行^操作，保证在不破坏hashcode的特性下，让高低位都参与计算 return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;} spread()同HashMap中hash()方法，使用这种方式主要是为了减少hash冲突。(HashMap源码解析) put系列方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public V put(K key, V value) { return putVal(key, value, false);} /* * onlyIfAbsent：当前onlyIfAbsent为true时，不会改变链表中存在的value */final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //获取key的hash值 int hash = spread(key.hashCode()); //链表长度 int binCount = 0; //死循环table（并发重试补偿，因为节点可能因为存在并发，而操作失败） for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; //如果table未初始化 if (tab == null || (n = tab.length) == 0) //初始化table tab = initTable(); //如果当前位置没有元素 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { //新建node节点，通过cas方法设置到当前位置，可能失败（存在并发） if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) //如果设置成功，跳出死循环 break; // no lock when adding to empty bin } //如果f.hash为-1，说明当前f是ForwardingNode节点，正在被其他线程扩容，帮助其扩容 else if ((fh = f.hash) == MOVED) //帮助扩容 tab = helpTransfer(tab, f); else { V oldVal = null; //通过synchronized锁定当前位置头节点 synchronized (f) { //如果当前位置的头元素为当前锁定元素（二次验证，因为可能被其他线程改变） if (tabAt(tab, i) == f) { //如果当前为链表 if (fh &gt;= 0) { //记录binCount链表长度 binCount = 1; //遍历此条链表，binCount每次+1 for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; //如果新增的key值，在链表中存在 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; //根据是否置换策略，选择是否更新value值 if (!onlyIfAbsent) e.val = value; break; } //记录上次遍历的节点 Node&lt;K,V&gt; pred = e; //如果==null,说明已经遍历到链尾了 if ((e = e.next) == null) { //替换当前新增节点为尾节点 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } //如果当前节点为红黑树 else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; //像树中添加元素 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; //根据是否置换策略，选择是否更新value值 if (!onlyIfAbsent) p.val = value; } } } } //如果binCount不为0，说明操作过链表 if (binCount != 0) { //如果链表长度大于默认的阈值 if (binCount &gt;= TREEIFY_THRESHOLD) //链表转红黑树 treeifyBin(tab, i); if (oldVal != null) //如果oldVal != null，说明当前key值在链表中已存在， //那么直接返回旧值（当然，也不做用做后续长度+1的操作了） return oldVal; break; } } } //当前map长度+1 addCount(1L, binCount); return null;}public void putAll(Map&lt;? extends K, ? extends V&gt; m) { //尝试扩容 tryPresize(m.size()); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) //遍历添加到map中 putVal(e.getKey(), e.getValue(), false);} initTable方法1234567891011121314151617181920212223242526272829303132//初始化tableprivate final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; // while ((tab = table) == null || tab.length == 0) { //说明当前tab正在被其他线程初始化 if ((sc = sizeCtl) &lt; 0) //退出线程竞争，避免当前线程一直占用cpu资源(初始化操作，只能由一个线程进行) Thread.yield(); // lost initialization race; just spin //将SIZECTL设置为-1，表示table正在被初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { //二次验证 if ((tab = table) == null || tab.length == 0) { //sc大于0的情况下，表示扩容量，如果没有指定容量大小，那么为默认容量 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //记录扩容阈值 sc = n - (n &gt;&gt;&gt; 2); } } finally { //如果当前线程初始化成功，设置扩容阈值，失败将sizeCtl还原成初始状态，这样其他线程有机会进行初始化操作，只有某个线程完成初始化操作后，其他线程才会退出while循环 sizeCtl = sc; } break; } } //返回新table return tab;} tryPresize方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//尝试扩容private final void tryPresize(int size) { //如果超过了容量的一半，那么直接设置为最大容量，否则选择大于且最接近当前值的2的幂次方 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; //确保没有其他线程在进行扩容操作的时候执行 while ((sc = sizeCtl) &gt;= 0) { Node&lt;K,V&gt;[] tab = table; int n; //如果table没有被初始化 if (tab == null || (n = tab.length) == 0) { n = (sc &gt; c) ? sc : c; //cas修改sizeCtl为-1，表示table正在进行扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { ///确认其他线程没有对table修改 if (table == tab) { //初始化table @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc = 0.75*n,负载因子在ConcurrentHashMap中默认为0.75 sc = n - (n &gt;&gt;&gt; 2); } } finally { //设置容量为当前扩容值 sizeCtl = sc; } } } //如果扩容大小没有达到阈值，或者超过最大容量 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //tab == table说明还没开始迁移节点 else if (tab == table) { //通过容量n，计算rs。通过对rs的移位处理，可以求出新的sizeCtl值 int rs = resizeStamp(n); //sc&lt;0,说明正在被其他线程扩容 if (sc &lt; 0) { Node&lt;K,V&gt;[] nt; //如果sc前 16 位如果不等于标识符，则表示标识符已经被改变 //第一个线程扩容时，设置(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2，如果sc == rs + 1，说明第一个 //线程已经完成扩容了（完成的时候会-1） //如果达到了最大帮助线程的数量，那么当前不参与扩容 // if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //帮助扩容，扩容线程数+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } //如果当前线程为扩容的第一个线程，设置(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); } }} &lt;1&gt;处，如果当前线程是扩容的第一个线程，那么会将sizeCtl以CAS的方式设置为(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2，通过resizeStamp获取到的rs，左移16位 + 2后，返回1000 0000 0001 1011 0000 0000 0000 0010。它的高16位由risizeCtl(n)的结果组成，如果有n个线程加入扩容，低16位的值为1+n。由于此时sizeCtl的符号位为1，所以处于扩容状态sizeCtl的值总是负数。 resizeStamp方法123456//根据传入桶的长度，生成一个扩容戳static final int resizeStamp(int n) { //numberOfLeadingZeros：该方法的作用是返回无符号整型i的最高非零位前面的0的个数，包括符号位(最高位)在内 //1 &lt;&lt; (RESIZE_STAMP_BITS - 1)：把1左移(RESIZE_STAMP_BITS - 1)位，也就是15位 return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));} 如果传入的桶长度为16，Integer.numberOfLeadingZeros(n) = 27(16转化为二进制后，1前面有27个0)，转化为二进制为：0000 0000 0000 0000 0000 0000 0001 1011 ，异或运算0000 0000 0000 0000 0000 0000 0001 1011 || 0000 0000 0000 0000 1000 0000 0000 0000 = 0000 0000 0000 0000 1000 0000 0001 1011 helpTransfer方法12345678910111213141516171819202122232425//帮助扩容，当前线程不是第一个扩容的线程的时候，才会进入此方法final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) { Node&lt;K,V&gt;[] nextTab; int sc; //如果当前tab存在并且，扩容未完成，并且指向的下一个桶已经初始化 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) { //获取标识符 int rs = resizeStamp(tab.length); //如果nextTab没有被其他线程修改，sizeCtl&lt;0扩容还在进行 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) { //同上面介绍的tryPresize方法中一样 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; //帮助扩容，扩容线程数+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) { transfer(tab, nextTab); break; } } return nextTab; } return table;} transfer方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189//核心方法，也是ConcurrentHashMap的精华部分private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; //stride为每个cpu所需要处理的桶个数，stride单核下为n，多核情况下，如果桶较少，那么默认一个线程处理16个 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range 细分范围 //如果新的桶还没有初始化，第一个扩容的线程会进入此方法 if (nextTab == null) { // initiating try { @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; //设置新的桶为原来的一倍 nextTab = nt; } catch (Throwable ex) { // try to cope with OOME //扩容失败，设置sizeCtl为最大扩容量 sizeCtl = Integer.MAX_VALUE; return; } //nextTable指向新tab nextTable = nextTab; //transferIndex初始化为，原tab长度 transferIndex = n; } //新tab的长度 int nextn = nextTab.length; // 创建一个 ForwardingNode 节点，用于占位。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // advance 指的是做完了一个位置的迁移工作，寻找下一个需要迁移的位置 boolean advance = true; //完成状态，代表所有迁移已经完成 boolean finishing = false; // to ensure sweep before committing nextTab //i数组下标，bound表示迁移任务的边界值，从后向前 for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; //如果advance为true，说明可以进行下一个位置的迁移了 while (advance) { int nextIndex, nextBound; //--i,表示下一个要处理的桶下标，如果--i&gt;=bound表示当前线程还未完成所有迁移工作，或者通过&lt;4&gt;处，已经将已经将i设置为n了，说明当前任务已经完成了 //将advance置为false，那么会继续进行下一个桶的迁移任务 //如果finishing为true（说明下面&lt;4&gt;处，已经将i设置为n了，）,说明所有任务已经迁移完成了，将advance置为false，那么此时i=n,会进入到&lt;5&gt;处，完成迁移操作 if (--i &gt;= bound || finishing) advance = false; //第一个线程扩容时，会将transferIndex置为原table的长度，也就是需要扩容桶的最大位置，如果 //transferIndex&lt;=0,说明所有的位置都有对应的线程去处理了 else if ((nextIndex = transferIndex) &lt;= 0) { //&lt;1&gt;.进入到下面的for循环中，判断所有迁移任务是否完成 i = -1; advance = false; } //分配迁移区间,通过cas将transferIndex置为下一次迁移的最大下标 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { //此时bound代表，线程负责桶区间当前最小下标 bound = nextBound; //此时i代表，线程负责桶区间当前最大下标 i = nextIndex - 1; //分配区间完成，退出while循环 advance = false; } } //&lt;5&gt;.i&lt;0（满足&lt;1&gt;处,i = -1）说明所有区间已经分配完了，i &gt;= n（满足&lt;2&gt;处，i=n),说明所有的迁移已经完成了 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; if (finishing) { //如果迁移完成，将nextTable置为null nextTable = null; //table指向扩容后的新tab table = nextTab; //n时原来table长度，左移动一位后为2n，n向右移动一位为n/2,2n - 0.5n = 0.75n //所以sizeCtl为新数组长度的0.75，此时的sizeCtl也就是扩容阈值了 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; } //通过cas将当前SIZECTL - 1，代表当前线程完成迁移，迁移线程数-1 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) //当前迁移完成，退出(因为其他区间都已经分配了) return; //&lt;4&gt;.如果(sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT表示所有的迁移，已经完成了，之后会回到上面的finishing，完成整个迁移操作 finishing = advance = true; //&lt;2&gt;将i置为n,再次检查整个table i = n; // recheck before commit } } //获取原来tab位置的元素，如果为null,那么设置为ForwardingNode节点占位 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 如果f存在且该位置处是一个 ForwardingNode，代表已经被其他线程处理过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed else { //开始迁移，锁定节点，避免其他线程putVal操作当前链表 synchronized (f) { //二次校验 if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) { //节点的hash值要么为0，要么为n int runBit = fh &amp; n; //最后遍历的节点 Node&lt;K,V&gt; lastRun = f; //遍历链表 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; //第一次，runBit = 0，b = n，记录高位,设置runBit = n //第二次，runBit = n, b = n,不记录 //第三次，runBit = n, b = 0, 设置低位，设置runBit = 0 if (b != runBit) { runBit = b; //更新最后遍历节点 lastRun = p; } } //如果最后更新的runBit==0，设置低位节点，此时后面的节点都为低位，且存在链接关 系，不用再处理 if (runBit == 0) { ln = lastRun; hn = null; } //如果最后更新的runBit!=0，设置高位节点，此时后面的节点都为低位，且存在链接关 系，不用再处理 else { hn = lastRun; ln = null; } //如果此时lastRun为高位，那么lastRun后面的都为低位 //如果此时lastRun为低位，那么lastRun后面的都为高位 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) //将当前节点链接到低位的头节点（从后向前） //如果原来ln为2-&gt;4，当前节点为1，那么ln为1-&gt;2-&gt;4 ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else //将当前节点链接到高位的头节点（从后向前） hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } //低位的链表在当前桶位置 setTabAt(nextTab, i, ln); //高位的链表在当前桶i+n位置（跟HashMap中一样，扩容后，元素要么在当前位置，要么 在当前位置+n位置） setTabAt(nextTab, i + n, hn); //fwd占位，代表当前位置已经被处理 setTabAt(tab, i, fwd); //处理完成当前位置，继续处理下一个位置 advance = true; } //如果为树节点，跟上面一样 else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } //如果元素迁移后，树长度不满足要求，则转化为链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; //同上面链表迁移的操作 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } } } } }} tabAt系列方法12345678910111213//获取table上下标为i的头结点，通过cas同步static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) { return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);}//基于CAS尝试更新table上下标为i的结点的值为v，设置成功说明获取到锁static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) { return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);}//setTabAt用于设置table上下标为i的结点为vstatic final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) { U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);} addCount方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//x代表要添加元素的个数，check表示是否需要进行扩容检查，如果&gt;=0,需要检查//因此通过putVal进入此方法,每次添加元素之后都会进行检查private final void addCount(long x, int check) { CounterCell[] as; long b, s; //如果计数器存在，说明当前map被其他线程操作过，直接统计baseCount不一定准确，使用counterCells统计 //计数器不存在，且修改baseCount失败（说明并发冲突)，通过fullAddCount统计数量 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) { CounterCell a; long v; int m; boolean uncontended = true; //如果as==null，说明上面修改baseCount失败，存在并发 //&lt;1&gt;.如果as!=null,存在值，并且当前线程获取到的Probe位置有值，且通过cas设置单元值成功，那么通过sumCount()统计总数 //否则进入到fullAddCount方法中 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) //只有as!=null,存在值，并且当前线程获取到的Probe位置有值的情况下，uncontended才会为false（存在竞争）,否则为true，表示未竞争 fullAddCount(x, uncontended); return; } //如果check&lt;=1 if (check &lt;= 1) return; s = sumCount(); } //扩容检查 if (check &gt;= 0) { Node&lt;K,V&gt;[] tab, nt; int n, sc; //此时s为统计后的map中元素的总数 //如果s&gt;=扩容阈值，并且tab存在，且容量小于默认的最大容量，那么接下来的操作跟tryPresize中一样 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n); if (sc &lt; 0) { if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //如果有其他线程正在扩容，帮助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } //如果当前为第一个扩容的线程 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); //帮助扩容完成后，统计元素总数，如果仍然大于扩容阈值，可能进行下一次扩容 s = sumCount(); } }} &lt;1&gt;处，ThreadLocalRandom.getProbe()，ThreadLocalRandom是一个线程私有的伪随机数生成器，每个线程的probe都是不同的，通过ThreadLocalRandom.getProbe() &amp; m每次都能找当当前线程对应的CounterCell，可以认为每个线程的probe就是它在CounterCell数组中的hashcode。 size方法12345678//获取ConcurrentHashMap中size的方法，通过统计多个CounterCell计数器的value来计算最终的sizepublic int size() { //统计总数 long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);} sumCount方法12345678910111213final long sumCount() { CounterCell[] as = counterCells; CounterCell a; //baseCount为当前size long sum = baseCount; //如果计数器存在，那么统计计数器中的所有值 if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum;} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113private final void fullAddCount(long x, boolean wasUncontended) { //当前线程的probe int h; //判断当前有没有初始化过ThreadLocalRandom，没有则初始化 if ((h = ThreadLocalRandom.getProbe()) == 0) { ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); //进入该方法中表示不存在竞争 wasUncontended = true; } //当前CounterCell中是否存在冲突，默认不冲突 boolean collide = false; // True if last slot nonempty for (;;) { CounterCell[] as; CounterCell a; int n; long v; //如果计数器存在且不为空 if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) { //如果没有找到当前线程对应的计数器 if ((a = as[(n - 1) &amp; h]) == null) { //当前无锁 if (cellsBusy == 0) { // Try to attach new Cell //创建一个value为x的计数器 CounterCell r = new CounterCell(x); // Optimistic create //通过cas，改变CELLSBUSY为1，获取锁 if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { boolean created = false; try { // Recheck under lock CounterCell[] rs; int m, j; //如果当前线程计数器不存在，为当前线程创建计数器 if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { rs[j] = r; created = true; } } finally { //释放锁 cellsBusy = 0; } //表示增加的count已经成功设置到CounterCell中了，结束方法 if (created) break; continue; // Slot is now non-empty } } //当前CounterCell中没有出现冲突 collide = false; } //addCount中，通过cas设置单元值失败uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))失败，自旋重试 else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash //addCount中没有机会进行的cas操作，as == null || (m = as.length - 1) &lt; 0 ||(a = as[ThreadLocalRandom.getProbe() &amp; m]) == null，在此处执行 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; //如果计数器被其他线程改变或者计数器个数超过处理器数量 else if (counterCells != as || n &gt;= NCPU) //设置当前线程循环失败，不进行扩容 collide = false; // At max size or stale else if (!collide) //设置当前CounterCell存在冲突，如果下循环的时候有机会对counterCells扩容 collide = true; //如果当前线程存在计数器，获取锁，collide = true为true时，才会进入此方法，代表着冲突频繁 else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { try { //确保没有被其他线程操作过 if (counterCells == as) {// Expand table unless stale //将CounterCell容量增大为原来的2倍，减少冲突 CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) //复制到新CounterCell中 rs[i] = as[i]; //更换为新的counterCells counterCells = rs; } } finally { //释放锁 cellsBusy = 0; } collide = false; continue; // Retry with expanded table } h = ThreadLocalRandom.advanceProbe(h); } //抢锁，如果counterCells没有被改变，且为null,那么初始化counterCells else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { //初始化完成标时 boolean init = false; try { // Initialize table //二次检查 if (counterCells == as) { //初始化一个长度为2的CounterCell数组 CounterCell[] rs = new CounterCell[2]; //取模计算下标，要么在0要么在1 rs[h &amp; 1] = new CounterCell(x); counterCells = rs; //初始化完成 init = true; } } finally { //释放锁 cellsBusy = 0; } //如果初始化成功，结束当前方法 if (init) break; } //如果counterCells被别的线程初始化了，那么继续更新baseCount的值，如果设置成功，结束当前方法 else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; // Fall back on using base }} get方法1234567891011121314151617181920212223242526public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //通过key的hashcode计算下标 int h = spread(key.hashCode()); //如果key对应的value值存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { //如果头节点就是当前要查找的值，直接返回 if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } //如果当前hash&lt;0,说明当前为ForwardingNode节点或者树节点，使用它们自带的find方法查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //遍历节点 while ((e = e.next) != null) { //找到指定节点，直接返回 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } //如果没有找到，返回null return null;} remove系列方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104//通过key移除元素public V remove(Object key) { //删除节点 return replaceNode(key, null, null);}/*** 实现四种公共删除/替换方法:* 用v替换节点值，条件是匹配cv非空。如果结果值为空，则删除。* v代表要替换的值*/final V replaceNode(Object key, V value, Object cv) { //获取元素hash值 int hash = spread(key.hashCode()); for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; //如果table存在，并且hash计算的下标桶不存在，那么直接结束方法(可能被其他用户删除了) if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; //如果当前桶位置为ForwardingNode节点，那么帮助扩容 else if ((fh = f.hash) == MOVED) //扩容完成后返回新的tab，回到for循环再次执行删除 tab = helpTransfer(tab, f); else { V oldVal = null; boolean validated = false; //锁定头节点 synchronized (f) { //二次校验 if (tabAt(tab, i) == f) { //如果fh&gt;=0，说明为链表结构 if (fh &gt;= 0) { validated = true; //遍历链表 for (Node&lt;K,V&gt; e = f, pred = null;;) { K ek; //如果找到对应的value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { V ev = e.val; //判断cv==null,或者cv符合节点value指向删除操作 if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) { //记录被覆盖的值 oldVal = ev; //如果value！=null，说明当前只是替换操作 if (value != null) //替换原来的值 e.val = value; else if (pred != null) //从链表中截断当前节点，也就是删除。 pred.next = e.next; else //如果pred==null，说明要删除的为当前链表的头节点 //那么将下一个节点置为当前链表的头节点 setTabAt(tab, i, e.next); } break; } pred = e; //如果遍历到链表末尾还没找到元素，跳出循环，结束方法 if ((e = e.next) == null) break; } } else if (f instanceof TreeBin) { validated = true; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; r, p; if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) { V pv = p.val; if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) { oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } } //是否对节点进行了操作 if (validated) { //如果oldVal != null，说明上面方法对节点进行了处理 if (oldVal != null) { //如果是删除节点动作 if (value == null) //将table元素个数-1 addCount(-1L, -1); //返回旧值 return oldVal; } break; } } } //没找到返回null return null;} 总结ConcurrentHashMap源码部分篇幅较长，且难以理解，容易看了前面忘了后面。此处对ConcurrentHashMap中最核心的putVal方法进行一个总结。 通过int hash = spread(key.hashCode())获取hash。如果当前table没有初始化，那么通过initTable方法初始化 通过hash计算下标,如果当前桶中没有元素,创建一个节点,通过cas设置到当前桶 如果当前桶节点hash = -1,说明当前map正在扩容,helpTransfer(tab, f)方式帮助扩容,完成扩容后返回tab 如果当前桶存在元素且没有扩容,锁定头节点,判断当前桶类是链表还是红黑树,通过遍历链表或红黑树的方式,通过cas方式将节点设置到链表(期间如果链表长度&gt;8,会触发转红黑树操作)或红黑树中. 如果添加元素在链表或红黑树中存在,那么覆盖掉原节点的value,如果不存在那么添加一个新的节点,并且通过addCount(1L, binCount)方法,将元素数量+1","link":"/2019/07/15/ConcurrentHashMap/"},{"title":"CountDownLatch源码解析(jdk1.8)","text":"概述​ CountDownLatch是基于AQS实现的一个同步工具类。它允许一个线程一直等待，直到其他线程执行完成后再执行。CountDownLatch源码比较简单，基于AQS实现共享锁的等待 ，初始化时只需要设置一个初始值，后续针对锁的状态进行控制，最后根据锁的状态来释放等待线程即可。CountDownLatch跟CyclicBarrier不同，8.19是不可复用的，CountDownLatch释放等待线程后，就不能再次使用了。看此源码之前，建议先看AQS源码解析。 代码解析以下就是CountDownLatch的全部代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class CountDownLatch { //基于AQS实现的共享锁 private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; //构造方法，设置一个初始count， //当count==0时，释放被await方法阻塞的线程 Sync(int count) { setState(count); } //获取锁的state状态，也就是count int getCount() { return getState(); } //尝试获取共享锁 protected int tryAcquireShared(int acquires) { //如果state已经为0了，返回1，后续的await操作不会被阻塞，也就是说 //CountDownLatch已经失效了，如果返回-1，获取锁失败，那么会创建记录该线程 //的node节点加入到同步队列中，等待被唤醒 return (getState() == 0) ? 1 : -1; } //尝试释放共享锁 protected boolean tryReleaseShared(int releases) { for (;;) { int c = getState(); //如果state为0，直接返回false，表示锁未完全释放 if (c == 0) return false; int nextc = c-1; //否则，将state-1 if (compareAndSetState(c, nextc)) //如果nextc已经为0，说明当前锁已经完全释放了，返回成功 //通过共享锁的传播性，最终所有被await阻塞的线程，都会被陆续唤醒 return nextc == 0; } } } private final Sync sync; public CountDownLatch(int count) { //初始值不能小于0 if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count); } //阻塞调用线程 public void await() throws InterruptedException { //调用AQS的方法，响应中断 sync.acquireSharedInterruptibly(1); } //超时阻塞调用线程 public boolean await(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); } //每一次调用countDown时，state都会-1，直到state==0为止 public void countDown() { //释放共享锁，state会-1，state=0时，会释放await等待的线程。 sync.releaseShared(1); } //获取当前数量，也就是还需要执行多少次countDown后才会释放await等待线程的数量 public long getCount() { return sync.getCount(); } public String toString() { return super.toString() + \"[Count = \" + sync.getCount() + \"]\"; }} 总结​ 上面就是针对CountDownLatch的全部解析了，可以看出来代码量很少，实现的逻辑也很简单(主要的代码都在AQS中)。CountDownLatch就像是一个计数器，初始化时执行一个计数值，每一次调用countDown时，就将值-1，当值到0时，释放等待线程。","link":"/2019/11/23/CountDownLatch/"},{"title":"DataWorks初探","text":"概述DataWorks数据工场，是MaxComputer的可视化开发平台，一站式开发、管理界面。我们可以通过DataWorks来使用MaxCompute，实现一站式的数据同步、业务流程设计、数据开发、管理和运维功能。 MaxCompute（ODPS）是适用于数据分析场景的企业级SaaS（Software as a Service）模式云数据仓库，以Serverless架构提供快速、全托管的在线数据仓库服务，消除了传统数据平台在资源扩展性和弹性方面的限制，最小化用户运维投入，可以经济并高效地分析处理海量数据。 准备工作需要购买DataWorks、MaxComputer、RDS服务，购买时最好保证在同一个地域和可用区。 购买DataWorks服务，DataWorks (按量付费) 购买MaxComputer服务，大数据计算服务MaxCompute（按量计费） 进入DataWorks工作台，创建工作空间，选择购买的MaxComputer 创建成功后，可以看到自己的工作空间 购买RDS，创建实例，&lt;&lt;云数据库 RDS 按量付费&gt;&gt; 创建好RDS实例后，进入dataworks控制台，选择数据源管理，列表应该已经存在一个MaxCompute的数据源，点击新增数据源，将mysql数据源加入，填好基本信息后，测试一下与资源组的连通性，连通成功表示可以在dataworks中使用该数据源了。 创建同步任务数仓分层 ADS一定要是面向业务的，不是面向开发的，这部分数据让业务能最短的时间去理解，甚至直接使用。 DWS必须是指标，也是刚才前面讲的指标体系的一个承载体，都由DWS去做，DWS汇总基本上就是ADS的支撑。 DWD就是明细层，明细层怎么建呢？我们建议采用的是维度建模的方式，企业有维表，有事实表，维表也有很多层级维度，比如枚举维度，事实表有周期快照。当然在这里有一个点就是DWD的字段必须是可被直接理解的，不要有二义性，一旦有二义性的时候，DWS使用的时候会有问题，会导致整个上游应用都有问题。 ODS基本上大家理解应该都保持一致，就是业务数据直接同步过来。但是现在有一些架构的演变，大家喜欢在ODS做一个初步的ETL处理，这样会导致ODS的数据跟企业业务的数据不一致。其实我们建议是不这样做，原因很简单，我们要保证ODS跟业务库保持一致，这样当出现问题的时候，我们能很快定位到问题的原因。一旦做了ETL，有可能ETL的过程是有bug的，会导致两边数据不一致。所以如果企业是严格要求从业务库的数据到ODS不允许做任何的逻辑的处理，那么出现问题的时候，只能是中间件或者是其他的任何存储出了问题导致的，不应该是业务逻辑导致的。 数据脚本MySql表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(32) DEFAULT NULL COMMENT '名称', `phone` varchar(32) DEFAULT NULL COMMENT '手机号', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='用户表';CREATE TABLE `sku` ( `id` int(11) NOT NULL, `product_id` int(11) NOT NULL COMMENT '产品ID', `price` decimal(10,2) NOT NULL COMMENT '价格', `stock` int(10) NOT NULL DEFAULT '0' COMMENT '库存', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;CREATE TABLE `product` ( `id` int(11) NOT NULL, `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT '商品名称', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='商品表';CREATE TABLE `order_product` ( `id` int(11) NOT NULL, `product_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '产品名称', `product_price` decimal(10,2) NOT NULL COMMENT '产品价格', `product_total` int(10) NOT NULL COMMENT '产品数量', `order_no` varchar(32) NOT NULL COMMENT '订单编号', `product_id` int(10) NOT NULL COMMENT '产品id', `sku_id` int(11) NOT NULL COMMENT 'sku_id', PRIMARY KEY (`id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='订单产品快照表';CREATE TABLE `order` ( `order_no` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '订单号', `order_name` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '下单人', `order_phone` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '下单手机号', `pay_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '支付时间', `pay_price` decimal(10,2) DEFAULT NULL COMMENT '支付金额', `order_price` decimal(10,2) NOT NULL COMMENT '订单金额', `pay_out_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '订单超时支付事件', `order_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '下单时间', `order_total` int(10) NOT NULL COMMENT '订单数', PRIMARY KEY (`order_no`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='订单表';CREATE TABLE `comment` ( `id` int(11) NOT NULL, `comment` varchar(255) DEFAULT NULL COMMENT '评价', `star_level` tinyint(1) DEFAULT NULL COMMENT '星级', `user_id` int(11) NOT NULL COMMENT '用户ID', `order_no` int(11) NOT NULL COMMENT '订单编号', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '评价时间', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='评价表'; ODPS表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748CREATE TABLE ods_users ( `id` bigint, `name` varchar(32) COMMENT '名称', `phone` varchar(32) COMMENT '手机号') COMMENT '用户表';CREATE TABLE ods_sku ( `id` bigint, `product_id` int COMMENT '产品ID', `price` decimal(10,2) COMMENT '价格', `stock` int COMMENT '库存') COMMENT 'sku表';CREATE TABLE ods_product ( `id` bigint, `name` varchar(255)COMMENT '商品名称') COMMENT '商品表';CREATE TABLE ods_order_product ( `id` bigint, `product_name` varchar(64) COMMENT '产品名称', `product_price` decimal(10,2) COMMENT '产品价格', `product_total` int COMMENT '产品数量', `order_no` varchar(32) COMMENT '订单编号', `product_id` bigint COMMENT '产品id', `sku_id` bigint COMMENT 'sku_id') COMMENT '订单产品快照表';CREATE TABLE ods_order ( `order_no` varchar(32) COMMENT '订单号', `order_name` varchar(32)COMMENT '下单人', `order_phone` varchar(32) COMMENT '下单手机号', `pay_time` timestamp COMMENT '支付时间', `pay_price` decimal(10,2) COMMENT '支付金额', `order_price` decimal(10,2) COMMENT '订单金额', `pay_out_time` timestamp COMMENT '订单超时支付事件', `order_time` timestamp COMMENT '下单时间', `order_total` int COMMENT '订单数') COMMENT '订单表';CREATE TABLE ods_comment ( `id` bigint, `comment` varchar(255) COMMENT '评价', `star_level` tinyint COMMENT '星级', `user_id` bigint COMMENT '用户ID', `order_no` varchar(32) COMMENT '订单编号', `create_time` timestamp COMMENT '评价时间') COMMENT '评价表'; 新建流程进入dataworks控制台，选择数据开发，新建业务流程。 执行流程 以上就是一个简单的通过dataworks将mysql数据清洗到ODPS的过程。","link":"/2021/07/27/DataWorks/"},{"title":"ConditionObject源码解析(jdk1.8)","text":"概述ConditionObject是AQS的内部类，是一个单向队列，提供了条件锁的同步实现。 在一个AQS同步器中，可以定义多个ConditionObject对象，因此AQS中可以存在多个等待队列，根据每个队列的条件不同，控制线程的挂起与唤醒。 结构特点1.实现了Condition中await(),signal()等方法。 2.实现了 Serializable 接口， 表示 ArrayList 支持序列化的功能 ，可用于网络传输 重要属性ConditionObject是一个FIFO单向队列，队列中每个节点都记录着当前线程的引用。外部类AQS中node节点的nextWaiter指向队列中下一个等待节点。 12345678910111213public class ConditionObject implements Condition, java.io.Serializable { //等待队列头，Node节点在外部类AQS中 private transient Node firstWaiter; //等待队列尾 private transient Node lastWaiter; //异常标识符，针对响应中断的await方法，如果用户中断动作发生在signal后，会返回REINTERRUPT //表示不会对中断做出响应，只会保留线程中断状态 private static final int REINTERRUPT = 1; //抛出异常标识，针对响应中断的await方法，如果用户中断动作发生在signal前，会抛出InterruptedException响应中断 private static final int THROW_IE = -1; } 常用方法构造方法12//无参构造方法，在AQS中创建一个等待队列public ConditionObject() { } await方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156//释放持有的锁，阻塞当前线程，不响应中断public final void awaitUninterruptibly() { //添加一个新的等待节点 Node node = addConditionWaiter(); //释放锁 int savedState = fullyRelease(node); boolean interrupted = false; //如果node已经在同步队列中，跳出while while (!isOnSyncQueue(node)) { //将当前线程阻塞，通过signal等方法唤醒后，会判断当前线程在阻塞期间是否被中断 //进入下一次循环，此时node通过signal等方法后，最终被设置到同步队列中了 LockSupport.park(this); if (Thread.interrupted()) //从这里就可以看出，该方法是不响应中断的 interrupted = true; } //acquireQueued(node, savedState) 方法，在AQS中已经解析过 //被其他线程通过signal等方法唤醒后，会通过acquireQueued从同步队列中获取锁 //如果获取锁失败，判断线程是否被中断，标记中断 if (acquireQueued(node, savedState) || interrupted) selfInterrupt();}//阻塞等待，将当前线程加入等待队列中，并释放当前锁//当其他线程调用signal()会重新请求锁，线程被中断有两种情况//1.线程是在调用signal方法之前被中断，那么抛出异常，响应中断//2.线程是在调用notity方法之后被中断，那么不会响应中断,只会保留中断状态public final void await() throws InterruptedException { //如果线程被中断，直接响应 if (Thread.interrupted()) throw new InterruptedException(); //方法同上awaitUninterruptibly Node node = addConditionWaiter(); //释放等待节点对应的锁 int savedState = fullyRelease(node); int interruptMode = 0; //检查当前节点是否在同步队列中 while (!isOnSyncQueue(node)) { //阻塞当前线程，等待被唤醒 LockSupport.park(this); //检查是否是由于被中断而唤醒，如果是，则跳出循环 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } //在同步队列中获取锁，如果线程中断且中断的方式不是抛出异常，则设置中断后续的处理方式设置为REINTERRUPT if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; //遍历等待队列，移除所有被取消的节点 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) //通过interruptMode判断，线程中断后要处理的模式，是直接设置当前线程的中断状态 //还是直接抛出InterruptedException reportInterruptAfterWait(interruptMode);}//阻塞超时到指定秒之后，针对中断的响应与await()方法一致public final long awaitNanos(long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); //记录获取锁超时时间 final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (nanosTimeout &lt;= 0L) { //将node节点添加到同步队列中 transferAfterCancelledWait(node); break; } //跟独占锁中获取锁超时方法一样，如果距离最后超时时间&lt;spinForTimeoutThreshold, //那么不会阻塞，直接进入下一次检查 if (nanosTimeout &gt;= spinForTimeoutThreshold) //阻塞指定时长 LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); } //跟await方法一样 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); //返回超时剩余时间 return deadline - System.nanoTime();}//阻塞超时到指定日期之前，针对中断的响应与await()方法一致，逻辑基本与awaitNanos一致public final boolean awaitUntil(Date deadline) throws InterruptedException { //获取指定日期毫秒数 long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (System.currentTimeMillis() &gt; abstime) { timedout = transferAfterCancelledWait(node); break; } //阻塞到指定时间 LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout;}//阻塞到指定时长，可以设置时长单位，逻辑基本与await()方法一致public final boolean await(long time, TimeUnit unit) throws InterruptedException { //计算超时时间 long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (nanosTimeout &lt;= 0L) { timedout = transferAfterCancelledWait(node); break; } if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); } if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout;} addConditionWaiter方法1234567891011121314151617181920212223//添加一个等待节点，如果队尾节点已经被移动到同步队列中，//那么遍历等待队列移除所有移动到同步队列中的节点private Node addConditionWaiter() { //记录尾节点 Node t = lastWaiter; //如果等待队列存在，并且节点的状态不为Node.CONDITION（说明该节点被其他线程唤醒移动到同步队列中了） if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { //将所有已经移动到同步队列中的节点从等待队列中移除 unlinkCancelledWaiters(); t = lastWaiter; } //创建一个等待节点 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) //如果等待队列不存在，那么设置等待队列头 firstWaiter = node; else //将创建的等待节点链接到等待队列尾 t.nextWaiter = node; //将队尾指向创建的新节点 lastWaiter = node; return node;} unlinkCancelledWaiters方法123456789101112131415161718192021222324252627282930//将所有已经移动到同步队列中的节点从等待队列中移除private void unlinkCancelledWaiters() { //记录等待队列中的头节点 Node t = firstWaiter; //记录状态为Node.CONDITION遍历的最后一个节点 Node trail = null; //遍历等待队列 while (t != null) { Node next = t.nextWaiter; //如果该节点已经被转移到同步队列中 if (t.waitStatus != Node.CONDITION) { //从队列中移出 t.nextWaiter = null; //trail == null，说明移除的是队头 if (trail == null) //记录新的队头 firstWaiter = next; else trail.nextWaiter = next; //next == null说明当前已经到队尾了 if (next == null) //设置队尾 lastWaiter = trail; } else //更新trail trail = t; t = next; }} checkInterruptWhileWaiting方法123456789private int checkInterruptWhileWaiting(Node node) { //1.Thread.interrupted()判断线程中断状态 //2.如果线程被中断，通过transferAfterCancelledWait可以知道当前线程被中断是发生在notify之后还是之前，true表示之前，false表示之后 //3.如果线程已经在同步队列中了，返回THROW_IE，否则返回REINTERRUPT //4.如果线程未被中断返回0 return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;} reportInterruptAfterWait方法12345678910//根据标识判断中断方式，是设置线程中断状态，还是直接抛出InterruptedExceptionprivate void reportInterruptAfterWait(int interruptMode) throws InterruptedException { if (interruptMode == THROW_IE) //抛出异常 throw new InterruptedException(); else if (interruptMode == REINTERRUPT) //设置线程中断状态 selfInterrupt();} signal方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//唤醒节点，将头节点从等待队列转移到同步队列中public final void signal() { //在独占锁模式下，状态是否被占用，使用该方法需要先获取锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) //唤醒队头 doSignal(first);}//唤醒所有节点public final void signalAll() { //在独占锁模式下，状态是否被占用，使用该方法需要先获取锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) //唤醒所有节点 doSignalAll(first);}//唤醒等待节点private void doSignal(Node first) { do { //如果下一个等待节点不存在，那么将当前等待节点置为null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; //将当前节点从等待队列中移除 first.nextWaiter = null; //将节点从等待队列转移到同步队列中，如果此次操作失败，说明操作的节点已经被其他的线程唤醒 //（或者在await方法fullyRelease中，释放锁失败，节点状态被设置为取消），那么直接寻找下一个节点 //如果下一个等待节点存在，那么继续唤醒下一个线程，直到成功或者下一个节点不存在为止 } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);}//通知所有的等待节点，将等待队列中所有节点转移到同步队列中private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null);} ConditionObject中其他方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546//是否为当前同步器持有final boolean isOwnedBy(AbstractQueuedSynchronizer sync) { return sync == AbstractQueuedSynchronizer.this;}//等待队列是否存在，也就是说是否还有线程处于wait状态protected final boolean hasWaiters() { //在独占锁模式下，状态是否被占用，也就是说使用此方法，需要先获取锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //判断等待队列中，是否存在Node.CONDITION节点 for (Node w = firstWaiter; w != null; w = w.nextWaiter) { if (w.waitStatus == Node.CONDITION) return true; } return false;}//获取等待队列的中Node.CONDITION等待节点的长度protected final int getWaitQueueLength() { //在独占锁模式下，状态是否被占用，也就是说使用此方法，需要先获取锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; //统计节点为Node.CONDITION的数量 for (Node w = firstWaiter; w != null; w = w.nextWaiter) { if (w.waitStatus == Node.CONDITION) ++n; } return n;}//获取所有等待节点的线程protected final Collection&lt;Thread&gt; getWaitingThreads() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) { if (w.waitStatus == Node.CONDITION) { Thread t = w.thread; if (t != null) list.add(t); } } return list;} 外部类AQS方法transferForSignal方法1234567891011121314151617//将当前节点从等待队列转移到同步队列中final boolean transferForSignal(Node node) { //通过cas将节点的WaitStatus设置为0，如果失败说明线程已经中断了(也可能释放锁失败，被取消)，返回false if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //通过doSignal等方法唤醒线程后，会将节点的WaitStatus设置为0，之后加入到同步节点末尾 //添加到同步队列末尾，返回原同步队列中的尾节点 Node p = enq(node); //判断原尾节点waitStatus，如果ws &gt; 0，说明为CANCELLED状态，节点被取消 //设置原尾节点waitStatus为Node.SIGNAL，表示被释放后，要唤醒当前节点 //如果设置waitStatus失败，说明节点的线程已经被取消 //此时原尾节点p的ws值为1（判断了ws&gt;0之后被取消的），unpark后，后续同步队列通过自旋，获取锁 int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} isHeldExclusively方法123456//在独占锁模式下，状态是否被占用。留给子类实现，如果返回false，也就是说未被占用//那么使用过if (!isHeldExclusively()) throw new IllegalMonitorStateException()；的方法//最终都会抛出IllegalMonitorStateException，因此我们在使用这些方法之前，必须先获取锁protected boolean isHeldExclusively() { throw new UnsupportedOperationException();} fullyRelease方法12345678910111213141516171819202122//释放持有当前节点的所有锁final int fullyRelease(Node node) { boolean failed = true; try { //获取当前锁状态 int savedState = getState(); //释放锁 if (release(savedState)) { failed = false; //返回锁状态 return savedState; } else { //释放锁失败，抛出异常 throw new IllegalMonitorStateException(); } } finally { if (failed) //如果释放锁失败，设置node节点等待状态为Node.CANCELLED，表示被取消 //被取消后，该节点一样会被转移到同步队列中 node.waitStatus = Node.CANCELLED; }} isOnSyncQueue方法123456789101112131415161718192021222324//是否在同步队列中final boolean isOnSyncQueue(Node node) { //1.node.waitStatus == Node.CONDITION，表示当前节点在等待队列中 //2.node.prev == null，等待队列是单向节点，没有前驱节点的，说明该节点在等待队列中 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; //如果有后继者，说明当前当前节点一定在同步队列中（等待队列中的节点只有nextWaiter） if (node.next != null) // If has successor, it must be on queue return true; //node.next == null，也有可能当前node在同步队列中的末尾，去同步队列中查找（从尾节点开始） return findNodeFromTail(node);}//判断节点是否在同步队列中存在，从尾节点开始查找(效率比较高，如果没有其他线程获取锁的情况下，那么尾节点可能就直接匹配上当前节点了)private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) return false; t = t.prev; }} transferAfterCancelledWait方法12345678910111213141516//将节点转移到同步队列中final boolean transferAfterCancelledWait(Node node) { //将节点的WaitStatus设置为0,如果通过checkInterruptWhileWaiting中调用此方法， //成功则说明中断发生在signal调用之前，（因为signal方法会将状态设置为0，此处应该会失败），那么加入到同步队列尾端并返回true，从这里我们知道，不管什么时候调用中断，该节点始终会被转移到同步队列中 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) { //加入到同步队列末尾 enq(node); return true; } //如果上面通过cas设置失败，判断是否在同步队列中 while (!isOnSyncQueue(node)) //退出线程竞争，保证资源不会一直被当前线程占用 Thread.yield(); //到这步说明其他线程可能通过signal等方法已经将node转移到同步队列中了 return false;} 总结上面已经解析了ConditionObject、以及相关联的外部类AQS中的方法。如果已经看过上一章AbstractQueuedSynchronizer的解析，再看这章就容易得多。按照惯例，我们将所有方法串起来做一个总结。 条件等待： 使用await方法，将线程等待。需要注意的是，在使用await方法之前，我们需要获取重入锁。调用await方法后，通过addConditionWaiter创建一个等待节点A，并加入到等待队列末尾。 节点入队后，通过fullyRelease方法，释放当前线程持有的重入锁。 释放锁后，会以自旋的方式通过isOnSyncQueue方法，判断A节点，是否被转移到同步队列中。 如果A节点，还未转入同步队列，那么通过LockSupport.park阻塞当前线程，等待被唤醒。 被唤醒后，通过checkInterruptWhileWaiting方法，检查是否是由于被中断而唤醒，如果被中断唤醒，会通过transferAfterCancelledWait判断是在调用signal之前被中断，还是调用signal之后被中断。如果是，则跳出循环，退出自旋。 如果判断是通过signal方式唤醒，那么会进入下一次自旋，此时节点A已经被转移到同步队列中了，也会退出自旋。 退出自旋后，通过acquireQueued方法，自旋从同步队列中获取锁(上一章AQS中已经详细解析了，acquireQueued方法)。acquireQueued方法结束后，判断记录的interruptMode中断模式，如果interruptMode != THROW_IE，那么将interruptMode = REINTERRUPT，表示方法结束后，只需要记录中断状态就行。 如果A后面还有下一个等待节点。那么通过unlinkCancelledWaiters方法，将等待节点中所有被取消的节点清除 条件唤醒： 通过使用signal方法，唤醒节点线程。调用signal方法后，会通过isHeldExclusively判断当前是否已经持有独占锁。如果没有就会抛出IllegalMonitorStateException异常。从这里就可以看出，要想使用signal必须先获取重入锁。 唤醒等待节点头A，如果节点A没有后驱节点，那么将A节点置为null，否则后驱节点记录为新的头节点，并将A节点从等待队列中移除。 transferForSignal中通过cas设置A的waitStatus为0。如果设置失败，说明线程已经中断了(也可能释放锁失败，A节点被取消了)，返回false后，signal会向等待队列后面查找节点，直到节点被转移成功为止。 cas设置成功后，会将A节点转移到同步队列队尾，并返回旧的队尾。如果旧的队尾的waitStatus&gt; 0(表示被取消)，或者设置waitStatus为Node.SIGNAL失败，那么A将不会被唤醒，那么通过LockSupport.unpark唤醒当前线程(此时程序会执行上面的第4步，判断是否中断，自旋获取锁)，后续同步队列通过自旋，获取锁。","link":"/2019/08/07/ConditionObject/"},{"title":"【阻塞队列】-- CyclicBarrier源码解析(jdk1.8)","text":"概述​ CyclicBarrier与CountDownLatch类似，它们都是阻塞一组线程直到某个事件的发生。CyclicBarrier与CountDownLatch的关键区别在于，CyclicBarrier中的所有的线程必须同时达到屏蔽点才能继续执行，如果其中一个线程被中断，那么所有的等待的线程都会立刻被唤醒，并且抛出异常。而CountDownLatch中线程之间不会收到干扰。CyclicBarrier可以复用，每次打破屏障后，都会生成一个新的屏障，供下次使用，而CountDownLatch用一次之后就无效了。 解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191public class CyclicBarrier { //内部类，表示屏障 private static class Generation { //当前屏障是否被打破，屏障被打破后，等待的线程才会执行 boolean broken = false; } private final ReentrantLock lock = new ReentrantLock(); private final Condition trip = lock.newCondition(); //屏障拦截的线程数 private final int parties; //栅栏打破后，执行的线程 private final Runnable barrierCommand; //初始一个新的屏障 private Generation generation = new Generation(); private int count; //屏障被打破后，会调用此方法，重置屏障，以便下次复用 private void nextGeneration() { //唤醒所有等待的线程 trip.signalAll(); //初始化拦截的线程数 count = parties; //初始化新的屏障 generation = new Generation(); } //打破屏障 private void breakBarrier() { //屏障标识设置为true，标识被打破 generation.broken = true; //初始化拦截的线程数 count = parties; //唤醒所有等待的线程 trip.signalAll(); } //线程等待，timed是否超时，超时时间 private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; lock.lock(); try { final Generation g = generation; //如果屏障已经被打破，那么抛出异常 if (g.broken) throw new BrokenBarrierException(); //如果线程被中断，那么打破当前屏障，其他被拦截到屏障前的线程将得到释放 if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } //当前拦截数-1 int index = --count; //如果拦截数为0，说明达到了突破屏障的条件 if (index == 0) { // tripped //标记执行状态 boolean ranAction = false; try { final Runnable command = barrierCommand; //如果预设的打破屏障后的方法存在，那么执行 if (command != null) command.run(); ranAction = true; //重置屏障 nextGeneration(); return 0; } finally { //栅栏打破后，执行的线程如果出现异常，或者屏障重置失败，那么打破屏障 //打破屏障后，所有等待的线程都将被唤醒，并抛出BrokenBarrierException异常 if (!ranAction) breakBarrier(); } } //如果当前还没有达到打破屏障的条件，并且线程未被中断 for (;;) { try { //是否锁超时 if (!timed) //如果没启用，那么直接调用条件锁的等待方法，响应中断 trip.await(); else if (nanos &gt; 0L) //如果启用，那么直接调用条件锁的超时等待方法，响应中断 nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { //如果等待的途中，被中断 //判断当前屏障是被重置，并且未被打破 if (g == generation &amp;&amp; ! g.broken) { //那么打破屏障 breakBarrier(); throw ie; } else { //如果屏障已经被其他线程重置了，或者被打破了，那么响应中断 Thread.currentThread().interrupt(); } } //判断屏障是否被打破，如果被打破，那么抛出异常 if (g.broken) throw new BrokenBarrierException(); //如果屏障被重置，说明已经达到突破屏障的条件了，返回index,执行线程 if (g != generation) return index; //如果当前启动锁超时，那么检测当前是否等待超时，如果等待超时 //那么打破屏障 if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { //无论是否成功，最终都会释放锁 lock.unlock(); } } //栅栏的初始方法，执行一个等待屏障的线程数parties，以及打破屏障后执行的一个Runnable public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } public CyclicBarrier(int parties) { this(parties, null); } public int getParties() { return parties; } //等待阻塞，直到屏障被打破 public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } //等待阻塞，直到屏障被打破或者超时等待 public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException { return dowait(true, unit.toNanos(timeout)); } //当前屏障是否被打破 public boolean isBroken() { final ReentrantLock lock = this.lock; lock.lock(); try { return generation.broken; } finally { lock.unlock(); } } //重置屏障 public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { //跳过当前的屏障，之前的等待的线程，会抛出异常 breakBarrier(); // break the current generation //打开一个新的屏障 nextGeneration(); // start a new generation } finally { lock.unlock(); } } //获取等待的线程数 public int getNumberWaiting() { final ReentrantLock lock = this.lock; lock.lock(); try { return parties - count; } finally { lock.unlock(); } }}","link":"/2019/12/25/CyclicBarrier/"},{"title":"【阻塞队列】-- DelayQueue源码解析(jdk1.8)","text":"概述​ DelayQueue是一个基于PriorityQueue优先级队列实现的有序的无界阻塞队列。放入队列的元素必须实现Delayed接口，其中的对象只能在其到期时才能从队列中取走。 结构 DelayQueue实现了BlockingQueue，具有阻塞队列的特征 DelayQueue还实现了Delayed接口，实现了 compareTo和getDelay方法，compareTo用于PriorityQueue中对比时间排序， getDelay用于获取剩余时间。 属性1234567891011121314public class DelayQueue&lt;E extends Delayed&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt; { private final transient ReentrantLock lock = new ReentrantLock(); //PriorityQueue作为内部实现优先级 private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); //用于优化内部阻塞通知的线程 private Thread leader = null; //用于控制的锁 private final Condition available = lock.newCondition();} 方法在上一章PriorityBlockingQueue源码解析中已经介绍过优先阻塞队列了，本章的PriorityQueue跟PriorityBlockingQueue中元素的插入删除操作基本一致，这里就不在介绍了，想了解的可以去看看上一章。 构造方法12345678910111213141516171819public DelayQueue() {}//通过集合初始化的构造方法public DelayQueue(Collection&lt;? extends E&gt; c) { this.addAll(c);}//父类AbstractQueue.class中的方法public boolean addAll(Collection&lt;? extends E&gt; c) { if (c == null) throw new NullPointerException(); if (c == this) throw new IllegalArgumentException(); boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified;} 生产方法12345678910111213141516171819202122232425262728293031//添加元素，交给offerpublic boolean add(E e) { return offer(e);}public boolean offer(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { //通过PriorityQueue来实现插入 q.offer(e); //如果队首元素是刚插入的元素，则设置leader为null，并且唤醒一个阻塞的线程 if (q.peek() == e) { leader = null; available.signal(); } return true; } finally { lock.unlock(); }}//添加元素，交给offerpublic void put(E e) { offer(e);}//添加元素，交给offerpublic boolean offer(E e, long timeout, TimeUnit unit) { return offer(e);} 消费方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129//移除并返回元素，获取不到元素时不回阻塞，直接返回nullpublic E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { //查看头部元素 E first = q.peek(); //如果不存在或者还未到时间，那么返回null //first.getDelay方法，获取剩余时间 if (first == null || first.getDelay(NANOSECONDS) &gt; 0) return null; else //否则返回 return q.poll(); } finally { lock.unlock(); }}//移除并返回元素，响应中断，获取不到元素时阻塞public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { //查看元素 E first = q.peek(); //如果不存在，那么阻塞 if (first == null) available.await(); else { //获取元素的剩余时间 long delay = first.getDelay(NANOSECONDS); //如果元素时间到了，那么返回 if (delay &lt;= 0) return q.poll(); first = null; // don't retain ref while waiting //如果已经有等待的线程 if (leader != null) //那么等待被唤醒 available.await(); else { //如果没有，那么设置当前线程为正在等待的线程 Thread thisThread = Thread.currentThread(); leader = thisThread; try { //等待剩余时间 available.awaitNanos(delay); } finally { //将leader置为null if (leader == thisThread) leader = null; } } } } } finally { //如果最终等待的线程不存在，队列不为空，说明没有其他线程再等待，那么通知一个后续的线程 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); }}//移除并返回元素，响应中断，获取不到元素时阻塞超时public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { //检查头部元素 E first = q.peek(); if (first == null) { //如果头部不存在，并且已经超时了，那么返回null if (nanos &lt;= 0) return null; else //否则超时阻塞 nanos = available.awaitNanos(nanos); } else { //获取延迟的剩余时间 long delay = first.getDelay(NANOSECONDS); //时间已到返回元素 if (delay &lt;= 0) return q.poll(); //如果等待超时返回null if (nanos &lt;= 0) return null; //释放引用 first = null; // don't retain ref while waiting //如果超时的时间小于剩余时间或者没有再等待的线程 if (nanos &lt; delay || leader != null) //阻塞超时 nanos = available.awaitNanos(nanos); else { Thread thisThread = Thread.currentThread(); leader = thisThread; try { //等待超时，唤醒后返回timeLeft，表示剩余时间 long timeLeft = available.awaitNanos(delay); //delay - timeLeft表示阻塞已用的时间，最终计算nanos还需要等待的 //剩余时间 nanos -= delay - timeLeft; } finally { if (leader == thisThread) leader = null; } } } } } finally { //如果最终等待的线程不存在，队列不为空，说明没有其他线程再等待，那么通知一个后续的线程 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); }}//获取头部元素public E peek() { final ReentrantLock lock = this.lock; lock.lock(); try { return q.peek(); } finally { lock.unlock(); }}","link":"/2020/03/16/DelayQueue/"},{"title":"Windows下使用Docker启动常用工具","text":"以下配置说明都是基于windows系统 Docker常用命令 docker search 镜像名 ：搜索一个指定的镜像。例如docker search redis,可能会搜索出多个，但是一般选择第一个，也就是starts数最高的一个。 docker pull 镜像:版本号: 拉取一个镜像到本地的docker仓库，如果未选择版本号，那么默认使用镜像的最新版本。例如docker pull redis默认会拉取名为redis:latest的镜像，docker pull redis:6.0会拉拉取一个redis 6.0版本的镜像。想知道具体有哪些版本的可以去DockerHub中查看。 docker images:查看当前容器的所有镜像，如果刚才使用了docker pull redis命令来拉取，那么此时我们本地仓库中应该就有一个redis镜像。REPOSITORY表示资源，IMAGE_ID就表示镜像的ID，TAG表示镜像的版本，我们也可以将TAG修改为我们自己习惯的标签。 docker run -itd -v 宿主机目录:容器目录 -p 宿主机端口:容器端口 --name 容器名 --restart=always 镜像ID ： 1docker run -itd -v /C/redis/redis.conf:/etc/redis/redis.conf -v /C/redis/data:/data -p 6379:6379 --name redis-server /etc/redis/redis.conf --restart=always redis 通过docker run命令启动一个容器： -i ：以交互模式运行容器，通常与 -t 同时使用。 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 -d ：后台运行容器，并返回容器ID -e ：传递环境变量 上面三个命令可以写到一起也就是上面的-itd，当然你也可以-i -t -d -v ：挂载宿主机的一个目录，上面就是将容器中/etc/redis/redis.conf的文件挂载到我本机的C盘下redis目录下的redis.conf文件，同理/C/redis/data:/data就是将容器中的/data目录挂载到C盘下的/redis/data目录中。 -p：映射一个端口，本机上可以通过映射的端口访问到容器的端口 --name：为启动的容器起一个名称 --restart=always：表示是否随docker启动，类似于windows中的一个开机启动。如果未设置那么默认为不随docker启动 IMAGE_ID ：表示通过指定镜像启动的容器，上面命令中是通过REPOSITORY来启动的，效果跟直接使用IMAGE_ID 一样，通过REPOSITORY:TAG的方式可以确定一个镜像，上面未指定TAG默认为redis:latest。 docker ps：查看运行中的容器，如果通过docker run启动成功后，就有一个名为 redis-server的容器了，CONTAINER ID表示容器ID，IMAGE表示基于哪一个镜像启动的。 docker ps -a：查看所有容器 docker exec -it 容器ID /bin/bash：表示在运行的容器中执行命令 docker cp 容器ID:目录路径 宿主机路径：将容器中指定目录文件拷贝到宿主机目录中 docker cp 宿主机路径 容器ID:目录路径：将宿主机目录的文件拷贝到容器中 docker stop 容器ID：停止一个容器 docker start 容器ID: 启动一个容器 docker restart 容器ID：重启一个容器 docker rm 容器ID：删除一个容器 docker rmi 镜像ID：删除一个镜像，如果镜像下面有容器，会提示无法删除，如果强制删除添加-f docker commit -a 提交人 -m 备注 容器ID 仓库名:标签：将容器提交为一个镜像。例如：docker commit -m 'commit images' -a 'zhangsan' 9adeb59430256 redis:test docker load -i myredis.tar:将宿主机的myredis.tar加载到docker中，加载成功后docker中会多一个刚才导入的镜像 docker save -o es.tar redis:test1 redis:test2:将docker中的多个镜像打包到宿主机中 docker logs --since 30m 容器ID：查询指定容器30分钟内的日志 Docker启动portainerPortainer是Docker的图形化管理工具，提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作。启动命令： 1docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v /C/portainer:/data --name portainer-server --restart=always portainer/portainer -v /var/run/docker.sock:/var/run/docker.sock：加上此设置表示本地模式，不加表示远程模式。 -v /C/portainer:/data：将portainer的数据目录映射到本机中。 如果是在windows中使用portainer,由于portainer是在容器中，此时portainer想管理宿主机中的docker服务，就必须将宿主机的端口暴露出来，让portainer访问。 右键docker图标打开setting-&gt;General会看到Expose daemon on tcp://localhost:2375 without TLS选项，将这个设置勾上即可。 通过http://localhost:9000访问到`portainer`后，如果是第一次访问需要先设置密码，登陆后在`Remote`标签页`EndPoint Url处填上docker.for.win.localhost:2375，name自己随便取个名，然后点击Connect`按钮即可。 Docker启动redis1docker run -itd -v /C/redis/redis.conf:/etc/redis/redis.conf -v /C/redis/data:/data -p 6379:6379 --name redis-server --restart=always redis /etc/redis/redis.conf --appendonly yes -v /C/redis/redis.conf:/etc/redis/redis.conf：将redis的配置映射出来，这样每次修改配置通过本机即可 -v /C/redis/data:/data：将redis中的数据目录映射出来，避免误删容器导致数据丢失。 --appendonly yes：打开redis持久化配置 --restart=always：随容器启动 Docker启动nginx12docker run -itd -p 80:80 -v /C/nginx/nginx.conf:/etc/nginx/nginx.conf -v /C/nginx/conf.d/default.conf -v /C/nginx/log:/var/log/nginx --name nginx-server nginx--restart=always -v /C/nginx/nginx.conf:/etc/nginx/nginx.conf：将nginx的配置文件映射出来 -v /C/nginx/log:/var/log/nginx：将日志映射出来 --restart=always：随容器启动 Docker启动mysql此处使用5.7版本，8.0版本需要设置加密方式比较麻烦 12docker run -itd -p 3307:3306 -v /C/mysql/my.cnf:/etc/mysql/my.cnf -v /C/mysql/data:/var/lib/mysql --name mysql-server -e MYSQL_ROOT_PASSWORD=123456 --restart=always mysql:5.7 -v /C/mysql/my.cnf:/etc/mysql/my.cnf：将mysql的配置文件映射出来 -v /C/mysql/data:/var/lib/mysql：将mysql的数据目录映射出来 -e MYSQL_ROOT_PASSWORD=123456：首次启动时需要指定root密码 --restart=always：随容器启动 Docker启动rabbitmqdocker search rabbitmq:3.7.7-management这种是带控制台的，如果直接使用rabbitmq拉取的没有控制台 1docker run -itd -p 5672:5672 -p 15672:15672 -v --hostname my-rabbitmq -e RABBITMQ_DEFAULT_VHOST=my-vhost -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin --name rabbitmq-server --restart=always rabbitmq:3.7.7-management -p 5672:5672 -p 15672:15672：1572是rabbitmq服务端口，15672是rabbitmq控制台端口 --hostname my-rabbitmq ：主机名 -e RABBITMQ_DEFAULT_VHOST=my-vhost：指定虚拟机 -e RABBITMQ_DEFAULT_USER=admin ：指定用户名 -e RABBITMQ_DEFAULT_PASS=admin：：指定密码 --restart=always：随容器启动 Docker启动nacos通过mysql创建 nacos-db.sql 中的表，由于nacos和mysql都在docker中，配置MYSQL_SERVICE_HOST时，使用docker中mysql服务的ip地址。 1docker run -itd -e PREFER_HOST_MODE=hostname -v /C/nacos/logs:/home/nacos/logs -e MODE=standalone -e SPRING_DATASOURCE_PLATFORM=mysql -e MYSQL_SERVICE_HOST=172.17.0.3 -e MYSQL_SERVICE_PORT=3306 -e MYSQL_SERVICE_USER=root -e MYSQL_SERVICE_PASSWORD=123456 -e MYSQL_SERVICE_DB_NAME=nacos-config -e MYSQL_SLAVE_SERVICE_HOST=172.17.0.3 -p 8848:8848 --name nacos-server --restart=always nacos/nacos-server -e PREFER_HOST_MODE=hostname ：表示支持hostname，默认为ip模式 -e MODE=standalone：表示单机模式 -v /C/nacos/logs:/home/nacos/logs：将日志映射出来 -e MYSQL_SERVICE_*：MYSQL_SERVICE_开头的为mysql的配置信息 Docker启动elasticsearch1docker run -itd --restart=always --name elasticsearch-server -v /C/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /C/elasticsearch/data:/usr/share/elasticsearch/data -v /C/elasticsearch/logs:/usr/share/elasticsearch/logs -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch","link":"/2020/05/03/DockerTools/"},{"title":"HashMap源码解析(jdk1.8)","text":"概述HashMap基于哈希算法实现，用于存储 key-value 键值对的数据结构，底层由数组+链表+红黑树(jdk_1.8新增)组成。HashMap相比于之前介绍的的ArrayList与linkedList结构要复杂得多。 ArrayList底层由数据组成，查找容易，插入、删除的效率不高。linkedList由链表组成，插入、删除容易、查询的效率不高。而基于散列表的HashMap，在保证高效查询的情况下，还能保证插入、删除的效率。HashMap允许使用null值和null键，HashMap非线程安全。 结构特点 HashMap继承了AbstractMap，实现了Map接口。 实现了Cloneable接口， 表示 HashMap支持克隆。 实现了 Serializable 接口， 表示 HashMap支持序列化的功能 ，可用于网络传输。 重要属性123456789101112131415161718192021222324252627282930public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable { //默认容量大小（必须为2的幂次方） static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表转红黑树长度阈值，当链表长度&gt;8时，会转为红黑树 static final int TREEIFY_THRESHOLD = 8; //红黑树还原链表数量阈值，当红黑树数量&lt;6,会转为链表 static final int UNTREEIFY_THRESHOLD = 6; //链表转红黑树长度容量阈值，当哈希表中容量&gt;64,才会将链表转红黑树长度，否则直接扩容而不是转化为红黑树，为了避免扩容与转化后红黑树之间的冲突，这个值不能小于64. static final int MIN_TREEIFY_CAPACITY = 64; //存放数据的桶，每一个桶中都有一段链表或红黑树（桶长度必须为2的幂次方） transient Node&lt;K,V&gt;[] table; //存储键值对形成的entrySet transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //元素数量 transient int size; //修改次数(如果在entrySet中遍历时，出现modCount与预期值不一致，那么会抛出 //ConcurrentModificationException异常，表示正在被多个线程同时操作，存在线程安全问题) transient int modCount; //扩容时的阈值 （负载因子 * 容量） int threshold; //负载因子 final float loadFactor;} Node节点1234567891011121314151617181920212223242526272829303132333435363738394041424344//HashMap的内部单链表，用来储存桶中的元素，指定条件下会转为红黑树static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { //当前node的hash值 final int hash; //当前node的key final K key; //当前node的value V value; //下一个节点 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; }} 常用方法无参构造方法1234public HashMap() { //负载因子设置为默认值 this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted} 带容量大小的构造方法123456789101112131415161718192021222324public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);}//带容量大小，初始因子的默认构造方法（一般不使用）public HashMap(int initialCapacity, float loadFactor) { //如果初始容量&lt;0抛出异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); //如果初始容量&gt;最大容量，则设置当前容量为最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //校验负载因子合法性 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; /* * 计算扩容时的阈值 * 例如传入的初始容量initialCapacity=7时，threshold = 8 * initialCapacity = 9，threshold = 16 */ this.threshold = tableSizeFor(initialCapacity);} 123456789101112131415161718192021/* * 计算扩容时的阈值，通过位运算，来计算最接近且大于当前输入值的2的幂次方数 * 例如传入的初始容量initialCapacity=7时，返回 8 * initialCapacity = 9，返回 16 */static final int tableSizeFor(int cap) { //假如传入的cap为61，那么 n = 60 int n = cap - 1; // n |= n &gt;&gt;&gt; 1 相当于n = n | n &gt;&gt;&gt; 1,向右边移动1位 // 0111100移动一位后，n = 0111100 | 011110, n = 0111110 n |= n &gt;&gt;&gt; 1; //0111110移动两位后，n = 0111110 || 0011110，n = 0111111 //此时所有的低位都为1，无论怎么位移这个数通过|运算后这个值，都不会再改变了 //此时111111转化为十进制为63 n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; //返回n + 1 = 64 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 上面简单的说明了，该方法是如何通过|运算与位移,来找到最接近输入值的2的幂次方数。为什么最后要一直写到 n |= n &gt;&gt;&gt; 16,int的范围在-2^31 ~ 2^31-1,因此最大2次幂数为2^30,也就是当前容量默认的最大值MAXIMUM_CAPACITY，代码1+2+4+8+16=31一共向右移了31位，是为了保证高位1以下的低位都会变为1。 带Map对象的构造方法1234public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);} putMapEntries方法1234567891011121314151617181920212223242526272829303132//该方法会被HashMap的public HashMap(Map&lt;? extends K, ? extends V&gt; m)构造函数、clone方法，以及Map接口的putAll方法调用。final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) { //获取传入的map长度 int s = m.size(); //传入的数据&gt;0时，才有意义 if (s &gt; 0) { /* * 如果当前table == null,说明当前是通过调用l构造函数、clone方法或者构造后还没有 * 放入任何元素，此时需要设置对象的扩容阈值 */ if (table == null) { // pre-size //通过传入的长度/加载因子，可以计算一个&gt;=阈值的数，保证本次不会触发扩容 float ft = ((float)s / loadFactor) + 1.0F; //如果大于最大容量，那么设置t为最大容量数 int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //如果t&gt;阈值,那么需要重新设置阈值数，保证阈值为2的幂次方，如果t=阈值 //那么就等到下次插入元素时，再进行扩容操作 if (t &gt; threshold) threshold = tableSizeFor(t); } //table != null,说明当前HashMap已经初始化过了，如果s&gt;阈值，那么HashMap就需要扩容了 else if (s &gt; threshold) resize(); //扩容 // 将map中的所有元素添加至HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); //往HashMap中添加元素 putVal(hash(key), key, value, false, evict); } }} 上面的方法有个很重要的一点，为什么此处float ft = ((float)s / loadFactor) + 1.0F需要 + 1，如果((float)s / loadFactor)算出来的是小数，此时如果向下取整，那么可能会导致容量不够大。 我们在计算HashMap阈值时（详见resize()函数中newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE)）向下取整（如果向上取整，那么当放入容器的元素，也就是size&gt;threshold阈值时，可能就无法进行resize()扩容操作了）。反过来想，float ft = ((float)s / loadFactor)得到的参数，向上取整也就是顺理成章的事情了。 但是向上取整，也会带来一些问题。假如我们默认加载因子0.75，此时HashMap默认容量为16，那么阈值就是12，我们传入map的size为12，那么12 / 0.6 + 1 = 17，此时通过tableSizeFor()计算后，得到的容量为32，阈值为24，导致内存浪费。（但是为了稳定性，也只能牺牲一部分了） resize方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111//扩容方法final Node&lt;K,V&gt;[] resize() { //记录原来的table Node&lt;K,V&gt;[] oldTab = table; //记录原table长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //记录扩容阈值 int oldThr = threshold; int newCap, newThr = 0; //&lt;1&gt;.如果原table长度大于0 if (oldCap &gt; 0) { //&lt;2&gt;.如果长度&gt;最大容量值 if (oldCap &gt;= MAXIMUM_CAPACITY) { //设置阈值为最大int数，之后也不会触发扩容了 threshold = Integer.MAX_VALUE; return oldTab; } //newCap = oldCap &lt;&lt; 1，新容量设置为原来的容量的两倍，如果 //新容量小于最大容量，判断原来容量是否大于默认容量16，否则设置新的 //扩容阈值为原来的一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //设置新阈值为原来的一倍 newThr = oldThr &lt;&lt; 1; // double threshold } //&lt;3&gt;.如果原来的table长度=0，ldThr &gt; 0说明是第一次带参数初始化，设置新容量为原来的threshold else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults //&lt;4&gt;.进入当前方法说明，当前HashMap通过无参构造方法构造的 //设置新容量为默认值16 newCap = DEFAULT_INITIAL_CAPACITY; //新阈值为16 * 0.75 = 12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } //如果新阈值为0，说明程序运行到&lt;3&gt;处，也就是通过带参数初始化构建的HashMap if (newThr == 0) { //计算阈值（由于loadFactor的不稳定，得到的阈值可能为小数） float ft = (float)newCap * loadFactor; //如果小于最大容量值，向下取整，保证容量达到阈值后，进行扩容操作 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } //设置新阈值 threshold = newThr; //创建newCap长度的node数组，也就是扩容 @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果原来的table有数据，那么将原来的数据复制到新的table中 if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { //记录当前桶链表 Node&lt;K,V&gt; e; //复制所有非空的桶 if ((e = oldTab[j]) != null) { //将原桶置空，便于gc回收 oldTab[j] = null; //如果当前链表没有下级元素，不存在链表转红黑树的情况，直接放置到新的table中 if (e.next == null) //&lt;5&gt;.通过e.hash &amp; (newCap - 1)计算下标，放到指定的桶内 newTab[e.hash &amp; (newCap - 1)] = e; //当前是否为树节点（红黑树） else if (e instanceof TreeNode) //将节点分割到不同桶中，可能会触发树转链表操作 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果是链表,且存在下级元素 else { // preserve order //记录原位置节点头 Node&lt;K,V&gt; loHead = null, loTail = null; //记录 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { //记录下级元素 next = e.next; //&lt;6&gt;如果(e.hash &amp; oldCap) == 0，说明原来的元素位置没有变化，后面会解释 //会将链表中所有位置节点的元素放到头节点为loHead的链表中 if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; }//否则将元素放到头节点为hiHead的链表中 else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); //如果loTail不为null，说明改链表中有元素 if (loTail != null) { loTail.next = null; //将当前链表放置到桶中 newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; //将当前链表放置到桶中,当前获取的(下标j + 原来的容量)位置 newTab[j + oldCap] = hiHead; } } } } } //返回扩容后的新table return newTab;} &lt;5&gt;处，通过e.hash &amp; (newCap - 1)计算index下标，为什么要通过这种方式来计算下标？我们知道table的容量设定为2的幂次方，而2的幂次方 - 1后，它的二进制低位都为1。这种情况下通过&amp;运算，index的结果等同于HashCode后几位的值。因此只要我们输入的HashCode本身分布均匀，通过这种算法每次分布的index就是均匀的。 可能有人不明白，为什么index的结果等同于HashCode后几位的值的意思。我们现在就来举个例子。假如我们table的容量为默认值16，那么16 - 1 = 15，15的二进制位为00001111。此时hash值假设为00011110，00001111 &amp; 10011110 = 00001110，因此无论hashcode的前几位如何变化，得到的下标值，只与newCap - 1二进制低位有关，且当前得到的index，不可能超过当前容量。 &lt;6&gt;处，如果(e.hash &amp; oldCap) ，它得到的结果只会有两种情况，要么是 0，要么是 oldCap。例如当前oldCap = 16。hash分别为 12 ， 18 ， 33，49时，他的结果为 0，16，0 ，16 ,此时12 、33组成新的链表，index = 12(后续的都会假如到这个链表当中);而18，49组成新的index = 12 + 16; 其实这一步就是将原来链表中的数据，均匀分布到桶中，减少单个桶中的数据，保证table中数据分布均匀。同时避免对原来的数据进行resize操作，提高效率。（针对jdk1.7之后做的一个优化） put系列方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//map中添加元素，如果map中存在重复的key值，那么覆盖并返回原来的值public V put(K key, V value) { //hash(key)计算key的hash值, onlyIfAbsent = false,默认如果key对应的值存在，那么覆盖 return putVal(hash(key), key, value, false, true);}//向map中添加元素，如果map中存在重复的key值，那么不会放入值@Overridepublic V putIfAbsent(K key, V value) { //hash(key)计算key的hash值, onlyIfAbsent = true,默认如果key对应的值存在，不会放入值 return putVal(hash(key), key, value, true, true);} /* * onlyIfAbsent：当前onlyIfAbsent为true时，不会改变链表中存在的value * evict：HashMap中没有用到，作用在LinkHashMap中，如果基于LinkHashMap实现LUR缓存的话 * 该值就会用到，后续分析LinkHashMap的时候会讲到 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为null或者为空，需要初始化 if ((tab = table) == null || (n = tab.length) == 0) //初始化容量并返回长度，默认16 n = (tab = resize()).length; //&lt;1&gt;.通过hash计算当前元素放置的位置下表（前面说明过）， //如果当前下标桶内没有元素，没有冲突，那么直接放置元素 if ((p = tab[i = (n - 1) &amp; hash]) == null) //向桶内插入节点，此时下个节点为null tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; //如果当前已经存在key值，那么记录当前存在的节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果为树节点，那么假如到树节点中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//如果为链表，那么此时的p就为链表中的头节点，遍历链表，binCount记录链表长度 for (int binCount = 0; ; ++binCount) { //如果当前下一个节点为null，说明当到链表的尾部了，且当前链表中没有已存在的节点 if ((e = p.next) == null) { //创建新节点，下一节点为null p.next = newNode(hash, key, value, null); //如果链表长度超过TREEIFY_THRESHOLD，那么尝试将当前链表转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //尝试将链表转为红黑树，如果桶的长度没有超过默认的 //MIN_TREEIFY_CAPACITY（64），那么会扩容而不是转树 treeifyBin(tab, hash); break; } //如果在链表中发现节点已存在，那么不在循环，记录当前存在的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //找到存在的节点后跳出循环 break; p = e; } } //如果e != null，说明当前链表中已存在节点，那么替换掉value if (e != null) { // existing mapping for key V oldValue = e.value; //如果当前允许对存在的key对应的值更新，或者原来的值为null的时候。才会替换原来的值为新值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); //返回旧的value，说明是更新操作 return oldValue; } } //记录操作数 ++modCount; //如果当前元素超过阈值，那么就需要扩容了 if (++size &gt; threshold) resize(); // Callbacks to allow LinkedHashMap post-actions //空方法，留给子类LinkedHashMap去实现 afterNodeInsertion(evict); //如果链表中没有存在的值，返回null，说明时新增操作 return null;} hash方法1234567//计算当前key的hash值static final int hash(Object key) { int h; //&lt;1&gt;.hashcode向右无符号移动16位（右边补0），也就是取int类型的一半， //然后运用^（位不同那么结果为1，否则为0）计算得到hashcode return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);} &lt;1&gt;处，为什么要把hashcode向右无符号移动16位，再进行^运算呢？上面我们说过，我们获取桶的index下标是通过e.hash &amp; (newCap - 1)计算，如果这个时候，我们假设容器长度为默认的16： hashcode的值 1001 0010 1011 0010 1110 0010 1010 0111 容器长度16 - 1 0000 0000 0000 0000 0000 0000 0000 1111 hashcode&amp;（16 -1）运算后 0000 0000 0000 0000 0000 0000 0000 1111 我们这个时候可以看到，hashcode前面28位都是没有参与运算的，位数越高参与度越低。如果通过这种方式，我们实际可能用到高位的情况就很少，那么我们在计算index下标时就会丢失高位的特性。假如两个hashcode相当接近的时候，可能就因为我们丢失高位的差异，导致产生一次hash碰撞。因此为尽可能减少发生碰撞的可能，将hashcode折中向右移16位，此时所有的高位都会移动到低位，通过^运算，此时hashcode的高位和低位都会参与计算，影响着hashcode的生成。而为什么会用^运算？如果使用&amp;运算，那么计算的位会向0靠拢，使用|又会向1靠拢，而^可以保留hashcode的原始特性。 get系列方法12345678910111213141516171819202122232425262728293031323334353637//通过key获取对应的valuepublic V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;}//通过hash值，key获取对应的节点final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //通过hash值计算桶的index，如果当前桶存在值，那么在桶中遍历查找对应的节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { //判断是否为头节点，如果是直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //遍历链表（也可能是红黑树） if ((e = first.next) != null) { //如果是树节点，那么遍历树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { //如果找到对应的key值，那么直接返回节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } //如果key值不存在，返回null return null;}//重写的map的方法，传入key和一个默认值，如果hashmap中找不对对应的key值，那么返回默认值@Overridepublic V getOrDefault(Object key, V defaultValue) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value;} remove系列方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//通过key移除节点public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;}//matchValue：是否需要匹配值，movable：LinkedHashMap中会用到final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //通过hash值计算桶的index，如果当前桶存在值，那么在桶中遍历查找对应的节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; //判断是否为头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //&lt;1&gt;.记录要移除的节点 node = p; //如果不是头节点，那么遍历查找 else if ((e = p.next) != null) { //如果为树节点，遍历红黑树查找并返回 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { //在链表中遍历查找 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { //如果找到，记录 node = e; break; } //记录当前遍历的节点，如果找到存在的节点后，那么p节点就为要移除节点的上一节点 p = e; } while ((e = e.next) != null); } } //根据hash值和key查找数据，且与value匹配(matchValue 是否需要匹配值) if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { //如果该节点为树节点 if (node instanceof TreeNode) //去树中移除（可能触发树转链表操作） ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果node == p，说明要移除的是头节点(对应操作&lt;1&gt;) else if (node == p) //替换头节点 tab[index] = node.next; else //如果不为头节点，将当前节点从链表中截断 //（例如：a -&gt; b -&gt; c 变成a -&gt; c,b就是我们移除的节点） p.next = node.next; //记录操作数 ++modCount; //map长度-1 --size; //空方法，由linkedHashMap实现，一般没用的node节点，会将后驱节点置为null便于GC回收， //而此时node的后驱节点并未清除，是为了node节点的完整，用于linkedHashMap的扩展 afterNodeRemoval(node); //返回被移除的节点 return node; } } //如果要移除的节点不存在，返回null return null;} 总结HashMap部分的源码解析就到这里。目前只分析了HashMap初始化、扩容、操作等核心代码。但没有红黑树部分代码的解析，由于考虑到红黑树代码部分较长，后面会针对红黑树单独出一期，所以就不再这里阐述了。如果各位小伙伴读完文章后，发现文章中有哪些错误或者不足之处，还请在评论区中留言。笔者看到也会尽快回复。","link":"/2019/06/23/HashMap/"},{"title":"【深入理解java虚拟机】-- 虚拟机类加载机制","text":"本系列内容，大量引用自《深入理解java虚拟机》。 类加载时机​ 类在虚拟机中整个声明周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段。其中验证、准备、解析3个部分统称为连接。 ​ ​ 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的(按照顺序按部就班的开始，是不是按照顺序完成就不一定了)，而解析阶段则不一定：它在某种情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定(也称为动态绑定或晚期绑定)。 类加载过程加载“加载”是“类加载”过程的一个阶段，在加载阶段，虚拟机需要完成三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表整个类的java.lang.Class对象，作为方法区这个类的各种数据访问入口。 “通过一个类的全限定名来获取定义此类的二进制字节流”，并没有指明二进制字节流要从要给Class文件中获取，准确的说是根本没有指明要从哪里获取，怎样获取。 从ZIP包获取，我们常见的JAR,EAR,WAR 从网络获取，这种场景最典型的就是Applet 运行时计算生成，这种场景使用得最多的就是动态代理技术，在java.lang.reflect.Proxy中，就是用了proxyGenerator.generateProxyClass来为特定接口生成形式为“*$Proxy”的代理类的二进制字节流。 其他文件生成，典型的就是由JSP文件生成对应的Class类。 从数据库读取，比较少见。有些中间件服务器可以选择把程序安装到数据库中来完成程序代码在集群间的分发 相对于类加载过程的其他阶段，一个非数组类的加载阶段是开发人员可控性最强的，可以选择使用系统提供的引导类加载器来完成，也可以由用户自定义的类完成(例如重写一个类加载器的loadClass方法)。 ​ 而数组类本身不通过类加载器创建，它是由虚拟机直接创建的。但是数组类与类加载器仍然存在关系，因为数组类的元素类型最终是要由类加载器去创建，一个数组类创建的过程遵循以下规则： 如果数组的组件类型是引用类型，那就递归加载过程去加载这个组件类型。 如果不是组件类型(例如int[])，java虚拟机会将把数组标记为与与引导类加载器关联。 数组类的可见性与其他的组件类型的可见性一直，如果组件类型不是引用类型，那数组类的可见性将默认为public。 ​ 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区。然后再内存中实例化一个Java.lang.Class类对象。这个对象将作为程序访问方法区中的这些类型数据的外部接口。 验证​ 验证时连接阶段的第一步，确保Class文件的字节流包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 ​ 验证阶段大致上会完成下面4个阶段的校验动作： 文件格式验证 是否以魔数0xCAFEBABE开头。 主、次版本号是否在当前虚拟机处理范围之内。 常量池中的常量是否有不被支持的常量类型(检查常量tag标志)。 CONSTANT_Utf8_info类型的常量中是否有不符合UTF8编码的数据。 Class文件中各个部分及文件本身是否有被删除的或者附加的其他信息 …… 元数据验证 这个类是否有父类(除了java.lang.Object之外，所有类都应该有父类) 这个类是否继承了不允许被继承的类(被final修饰的类) 如果不是抽象类，是否实现了其父类或接口中要求实现的所有方法 类中的字段、方式是否与父类产生矛盾(例如覆盖了父类的final字段，或者出现不符合规范的方法重载) 字节码验证 第三阶段时整个验证过程中最复杂的阶段，主要目的是通过数据流和控制流分析，确定程序语义是否合法、符合逻辑。保证被校验类的方法在运行时不会出现危害虚拟机安全的事件 保证任何时刻操作数栈的数据类型与指令代码序列都能配合工作。例如不会出现：在操作数栈方值了一个int类的的数据，使用时却按照long类型来加入到本地变量表中。 保证跳转指令不会跳转到方法体以外的字节码指令上。 保证方法体中的类型转换是有效的，例如把父类对象赋值给子类数据类型，甚至把对象赋值给与他毫无继承关系、完全不相干的一个数据类型，则是危险且不合法的。 符号引用验证 ​ 最后一个阶段的校验发生在虚拟机将符号引用转化为直接引用的时候，整个转化动作将在连接的第三个阶段–解析阶段中发生。符号引用验证可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性校验，通常需要校验下列内容： 符号引用中通过字符串描述的全限定名是否能找到对应的类。 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。 符号引用中的类、字段、方法的访问性是否可以被当前类访问 ​ 如果无法通过符号引用验证，那么会抛出一个java.lang.IncompatibleClassChangeError异常的子类，如java.lang.IllegalAccessError、java.lang.NoSuchFieldError、java.lang.NoSuchMethodError等。 ​ 对于虚拟机类加载机制来说，验证是一个非常重要的的、但不一定必须要的阶段(对运行期无影响)。如果所运行的全部代码(包括自己编写的代码)都已经被反复使用和验证过，那么可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载时间。 准备​ 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。注意，类变量(被static修饰的变量)不包括实例变量，实例变量会在对象实例化时随对象一起分配在Java堆中。其次，这里说的初始值“通常情况”时数据类型的零值，假设一个类变量定义为： 1public static int value = 123; 那变量value在准备阶段过后的初始值为0为不是123，把value赋值为123的动作将在初始化阶段才会执行。有一个例外，如果字段属性表中存在ConstantValue属性，那么在准备阶段就会初始为ConstantValue属性指定的值,例如： 1public static final int value = 123; 解析​ 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，符号引用前面讲Class文件格式出现过多次，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现，那么解析阶段所说的直接引用与符号引用的关系又有什么关联呢？ 符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现地内存布局不管，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受地符号引用必须是一致的，因为符号引用的字面量形式明确定义在java虚拟机规范的Class文件格式中。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能直接定位到目标的句柄。直接引用和虚拟机实现的内存布局相关，同一个符号引用在不同虚拟机实力上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化​ 类初始化阶段是类加载过程的最后一步。到了初始化，才真正开始执行类中定义的Java程序代码 ​ java虚拟机规范并没有强制约束类什么时候加载，但是对于初始化阶段，虚拟机严格规定了5种情况必须对类进行“初始化”(加载、验证、准备自然需要在此之前开始)： 需要new、getstatic、putstatic或invokestatoc这4条字节码指令时，如果类没有进行过初始化。则需要先触发其初始化。使用整个4条指令常见的Java代码场景时：使用new实例化对象、读取或者设置一个类的静态字段(不包括被final修饰的，因为编译的时候已经把结果放入到了常量池中)，以及调用一个类的静态方法的时候。 使用Java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类，如果发现父类还没有进行过初始化，则需要先触发父类的初始化。 虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类(包括main()方法的那个类)。 当使用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_pubStatic、REF_invokeStatic的方法句柄、并且这个方法句柄所对应的类没有进行过初始化、则需要先触发其初始化。 ​ 对于这5中会触发类进行初始化的场景、虚拟机规范中使用了一个很强烈的限定语：“有且只有”，这5中场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方法都不会触发初始化，称为被动引用。例如：通过子类引用父类的静态字段。 1234567891011121314class Father{ static{ System.out.print('father init'); } public static int value = 123;}class Children extends Father{ System.out.print('children init');}main(){ System.out.print(Children.value);} ​ 此时只会输出“father init”，而不会输出“children init”。对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。致于是否要触发子类的加载和验证，虚拟机终规范中没有明确规定。对于Hot Spot虚拟机来说，可通过-XX:+TraceClassLoading参数观察到此操作会导知子类的加载。 类加载器类与类加载器​ 类加载虽然只用于实现类的加载动作，但是它的作用远远不限于此。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。通俗点就是说，两个类是否相等，不仅需要来源同一个Class文件，还需要被同一个虚拟机架加载。 ​ 这里的”相等”，包括代表类的Clas对象的equals()方法，isAssignableForm()方法、isInstance()方法的返回结果，也包括使用instanceof判定对象所属关系等情况。 双亲委派模型从java虚拟机的角度来讲，只存在两种不同加载器： 启动类加载器(Bootstrap ClassLoader)，这个类加载器使用C++语言实现，是虚拟机自身的一部分 所有其他类加载器，都有java语言实现，独立于虚拟机外部，并且全部都继承自抽象类java.lang.ClassLoader。 从java开发人员角度来看，类加载器可以分的更细致，绝大部分java程序都会使用以下三种系统提供的类加载器。 启动类加载器(Bootstrap ClassLoader)，就是上面介绍的，主要负责讲存在\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。 扩展类加载器(Extension ClassLoader): 由sun,misc.Launcher$ExtClassLoader实现，负责加载\\lib、ext目录中的，或者被java。ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 引用程序类加载器(Application ClassLoader):这个类加载由sun,misc.Launcher$App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径(ClassPath)上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们应用程序都是由这三种类加载机相互配合加载的，如果有必要还可以加入自己定义的类加载器。它们之间的关系如图： ​ 图中展示的类加载器之间的这种层级关系，称之为类加载器的双亲委派模型。双亲委派模型要求除了顶层的启动类加载器外、其余的类加载器都应当有自己的父类加载器。这里的类加载器之间的关系一般不会以继承的关系实现，而是都使用组合关系来复用父加载器的代码。 ​ 双亲委派模型的工作过程是：如果一个类收到了类加载的请求，他首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层级的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器，只有当父类加载器反馈自己无法完成这个加载请求时(它的搜索范围类没有找到所需的类)，子加载器才会尝试自己去加载。 ​ 双亲委派模型好处就是Java类随着它的类加载器一起具备了一种带有优先级的层级关系。例如类Java.lang.Object,存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。如果用户没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为Java.lang.Object的类(实际上虚拟机不允许用户自己加载以“java.lang”开头的类，会抛出异常)，并存放在程序的ClassPath中，那么系统中将会出现多个不同的Object类，java类型体系中最基础的行为也无法保证，引用程序也将会变得一片混乱。 ​ 双亲委派模型实现非常简单，实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass()方法中。大致流程：先检查是否已经被加载过，如果没有则调用父加载器的loadClass()方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父类加载失败，抛出ClassNotFoundException异常后，再调用自己的findClass()方法进行加载。 12345678910111213141516171819202122232425262728293031323334353637383940protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { //如果父类不为null，那么使用父类加载 if (parent != null) { c = parent.loadClass(name, false); } else { //如果父类为null，那么使用启动类加载器加载 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } //如果父类没找到，那么由当前加载器加载 if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); //通过findClass方法，搜索class文件 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 破坏双亲委派模型​ 双亲委派并不是强制性的约束模型，而是java设计者推荐给开发者的类加载器实现方式。如果某些情况我们要突破这种模型的限制该如何做：其实java中也出现过双亲模型被破坏的情况。 上面loadClass方法的代码，就是一个被破坏的入口，当用户去继承java.lang.ClassLoader并重写loadClass方法，那么双亲委派模型就会被打破，想符合双亲委派模型也很简单，只需要重写findclass方法，最终通过defineClass方法将找到的类加入到虚拟机即可。 还有一种情况是由这个模型自身缺陷所导致的，双亲委派模型中，我们加载类都是委托给父类加载，最终经过启动类加载器，可能访问到启动类加载器中加载的java.lang.Object类，如果此时Object需要调回用户代码的时候呢。 一个典型的例子便是JNDI，JNDI现在已经时java标准服务，他的代码由启动类加载器去加载，但是JNDI的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在引用程序的ClassPath下的JDNI接口提供者(SPI，Service Provider Interface)的代码，但是启动类加载器不可能”认识“这些代码。为了解决这个问题，java设计团队引入了一个不太优雅的设计：线程上下文加载器(Thread Context ClassLoader)。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时还未被设置，它将从父线程中继承一个，如果应用在全局范围内都没有设置过，那这个类加载器默认就是应用程序类加载器。​ 有了线程上下文加载器，JDNI服务就可以使用这个线程上下文加载器去加载所需要的SPI代码，也就是父类记载器亲求子类加载器去完成类加载的动作，通过逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则。 第三次被“破坏”是由于用户对程序动态性的追求而导知的，这里说的“动态性”指的是：代码热替换(HotSwap)、模块部署(Hot Deployment)等。OSGI中实现模块化热部署的关键是它自定义的类加载器机制的实现。每个程序模块(OSGI中称为Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就要把Bundle连同类加载器一起替换掉一实现代码的热替换。 在OSGI环境下，类加载不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，当收到类加载请求时，OSGI将按照下面的顺序进行类搜索: 将以java.*开头的类委派给父类加载器加载。 否则，将委派列表名单内的类委派给父类加载器加载。 否则，将Import列表中的类委派给Export这个类的Bundle的类加载器加载。 否则，查找当前Bundle的ClassPath,使用自己的类加载器加载。 否则，查找类是否在自己的Fragment Bundel中，如果在，则委派给Fragment Bundel的类加载器加载 否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载 否则，类查找失败。 上面的查找顺序只有开头两点符合双亲委派规则，其余的类查找都是在平级的类加载器中进行的。","link":"/2020/04/22/JVM-ClassLoading/"},{"title":"【阻塞队列】-- LinkedBlockingDeque源码解析(jdk1.8)","text":"概述​ LinkedBlockingDeque与LinkedBlockingQueue不同，它是一个由链表组成的无界双端阻塞队列，生产消费用一把锁，头尾都可以生产消费元素，由于多了一个生产插入的入口，因此多线程情况下，入队的效率会提升一倍。 结构 LinkedBlockingDeque继承AbstractQueued,实现了BlockingDeque，BlockingDeque还继承了BlockingQueue,也就是LinkedBlockingDeque是具备队列的所有基本特性的一个双端队列。 属性1234567891011121314151617181920212223242526272829303132333435363738public class LinkedBlockingDeque&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingDeque&lt;E&gt;, java.io.Serializable { //用户储存元素的节点 static final class Node&lt;E&gt; { E item; //指向上一个节点 Node&lt;E&gt; prev; //指向下一个节点 Node&lt;E&gt; next; Node(E x) { item = x; } } //头节点 transient Node&lt;E&gt; first; //尾节点 transient Node&lt;E&gt; last; //元素个数 private transient int count; //容量 private final int capacity; final ReentrantLock lock = new ReentrantLock(); //控制消费的条件锁 private final Condition notEmpty = lock.newCondition(); //控制生产的条件锁 private final Condition notFull = lock.newCondition();} 方法构造方法1234567891011121314151617181920212223242526272829//初始化，默认容量为Integer.MAX_VALUEpublic LinkedBlockingDeque() { this(Integer.MAX_VALUE);}//初始化，指定容量public LinkedBlockingDeque(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity;}//通过集合初始化public LinkedBlockingDeque(Collection&lt;? extends E&gt; c) { this(Integer.MAX_VALUE); final ReentrantLock lock = this.lock; lock.lock(); // Never contended, but necessary for visibility try { for (E e : c) { //传入的元素，不能为null if (e == null) throw new NullPointerException(); //将元素插入到队尾，如果传入的集合长度超过默认的容量Integer.MAX_VALUE，抛出异常 if (!linkLast(new Node&lt;E&gt;(e))) throw new IllegalStateException(\"Deque full\"); } } finally { lock.unlock(); }} 生产方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186//添加元素到队尾，队列满的情况下抛出异常，成功添加返回truepublic boolean add(E e) { addLast(e); return true;}//添加元素到队尾，队列满的情况下返回false，成功添加返回truepublic boolean offer(E e) { return offerLast(e);}//添加元素到队尾，队列满的情况下会阻塞，响应中断public void put(E e) throws InterruptedException { putLast(e);}//添加元素到队尾，队列满的情况下会超时阻塞，响应中断public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { return offerLast(e, timeout, unit);}//添加元素到队列头public void addFirst(E e) { if (!offerFirst(e)) throw new IllegalStateException(\"Deque full\");}//添加元素到队列尾public void addLast(E e) { if (!offerLast(e)) throw new IllegalStateException(\"Deque full\");}//通过linkFirst实现元素的插入public boolean offerFirst(E e) { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try { return linkFirst(node); } finally { lock.unlock(); }}//通过linkLast实现元素的插入public boolean offerLast(E e) { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try { return linkLast(node); } finally { lock.unlock(); }}//向队列头添加元素，响应中断public void putFirst(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try { //如果向队列头添加元素失败，说明队列满了，那么等待 while (!linkFirst(node)) notFull.await(); } finally { lock.unlock(); }}//向队列尾添加元素，响应中断public void putLast(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try { //如果向队列尾添加元素失败，说明队列满了，那么等待 while (!linkLast(node)) notFull.await(); } finally { lock.unlock(); }}//向队列头添加元素，响应中断，超时阻塞public boolean offerFirst(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //如果向队列头添加元素失败，说明队列满了，那么超时等待 while (!linkFirst(node)) { //已超时，返回false if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); } return true; } finally { lock.unlock(); }}//向队列尾部添加元素，响应中断，超时阻塞public boolean offerLast(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //如果向队列尾添加元素失败，说明队列满了，那么超时等待 while (!linkLast(node)) { //已超时，返回false if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); } return true; } finally { lock.unlock(); }}//将元素插入到队列头private boolean linkFirst(Node&lt;E&gt; node) { // assert lock.isHeldByCurrentThread(); //必须要先获取锁 //如果队列已经满了，直接返回false if (count &gt;= capacity) return false; //记录头节点 Node&lt;E&gt; f = first; //插入到头节点 node.next = f; //更新头节点 first = node; //如果尾节点为null,那么设置为尾节点 if (last == null) last = node; else //将旧的头节点指向新的头节点node f.prev = node; //元素数量+1 ++count; //唤醒一个消费的线程 notEmpty.signal(); return true;}//将元素插入到队列尾private boolean linkLast(Node&lt;E&gt; node) { // assert lock.isHeldByCurrentThread(); //必须要先获取锁 //如果队列已经满了，直接返回false if (count &gt;= capacity) return false; //记录尾节点 Node&lt;E&gt; l = last; //将插入节点的prev指向尾节点 node.prev = l; //将node置为新的尾节点 last = node; //如果头为null,那么将node设置为新的头 if (first == null) first = node; else //否则将原来的尾节点的next指向新的尾节点node l.next = node; //元素数量+1 ++count; //唤醒一个消费的线程 notEmpty.signal(); return true;} 消费方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195//移除队头元素并返回public E remove() { return removeFirst();}//public E poll() { return pollFirst();}public E take() throws InterruptedException { return takeFirst();}public E poll(long timeout, TimeUnit unit) throws InterruptedException { return pollFirst(timeout, unit);}//将头节点从链表中断开并返回，如果不存在返回nullprivate E unlinkFirst() { // assert lock.isHeldByCurrentThread(); Node&lt;E&gt; f = first; if (f == null) return null; Node&lt;E&gt; n = f.next; E item = f.item; f.item = null; f.next = f; // help GC first = n; if (n == null) last = null; else n.prev = null; --count; notFull.signal(); return item;}//将尾节点从链表中断开并返回，如果不存在返回nullprivate E unlinkLast() { // assert lock.isHeldByCurrentThread(); Node&lt;E&gt; l = last; if (l == null) return null; Node&lt;E&gt; p = l.prev; E item = l.item; l.item = null; l.prev = l; // help GC last = p; if (p == null) first = null; else p.next = null; --count; notFull.signal(); return item;}//移除头节点并返回，如果队列为空，抛出异常public E removeFirst() { E x = pollFirst(); if (x == null) throw new NoSuchElementException(); return x;}//移除队尾点并返回，如果队列为空，抛出异常public E removeLast() { E x = pollLast(); if (x == null) throw new NoSuchElementException(); return x;}//移除队头，通过unlinkFirst方法实现，如果队列为空，返回nullpublic E pollFirst() { final ReentrantLock lock = this.lock; lock.lock(); try { return unlinkFirst(); } finally { lock.unlock(); }}//移除队尾，通过unlinkLast方法实现，如果队列为空，返回nullpublic E pollLast() { final ReentrantLock lock = this.lock; lock.lock(); try { return unlinkLast(); } finally { lock.unlock(); }}//消费队头，如果队列为空，那么阻塞public E takeFirst() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lock(); try { E x; while ( (x = unlinkFirst()) == null) notEmpty.await(); return x; } finally { lock.unlock(); }}//消费队尾，如果队列为空，那么阻塞public E takeLast() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lock(); try { E x; while ( (x = unlinkLast()) == null) notEmpty.await(); return x; } finally { lock.unlock(); }}//移除队头，通过unlinkLast方法实现，如果队列为空，超时阻塞public E pollFirst(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { E x; while ( (x = unlinkFirst()) == null) { if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); } return x; } finally { lock.unlock(); }}//移除队尾，通过unlinkLast方法实现，如果队列为空，超时阻塞public E pollLast(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { E x; while ( (x = unlinkLast()) == null) { if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); } return x; } finally { lock.unlock(); }}//获取队头，如果队列为空，那么抛出异常public E getFirst() { E x = peekFirst(); if (x == null) throw new NoSuchElementException(); return x;}//获取队尾，如果队列为空，那么抛出异常public E getLast() { E x = peekLast(); if (x == null) throw new NoSuchElementException(); return x;}//返回队头，如果队列为空，返回nullpublic E peekFirst() { final ReentrantLock lock = this.lock; lock.lock(); try { return (first == null) ? null : first.item; } finally { lock.unlock(); }}//返回队尾，如果队列为空，返回nullpublic E peekLast() { final ReentrantLock lock = this.lock; lock.lock(); try { return (last == null) ? null : last.item; } finally { lock.unlock(); }}","link":"/2020/03/15/LinkedBlockingDeque/"},{"title":"【阻塞队列】--  LinkedBlockingQueue源码解析(jdk1.8)","text":"概述​ LinkedBlockingQueue是由链表组成的单向无界阻塞(严格意义上来并不是无界限) 队列。与ArrayBlockingQueue 不同的是，LinkedBlockingQueue生产消费各用一把锁，生产用的是putLock，消费是takeLock，目的就是为了增大吞吐量，但是因为每个节点都是一个对象，所以比较耗费内存。LinkedBlockingQueue默认大小为Integer.MAX_VALUE，如果出现生产大于消费的情况，导致队列中存放着大量未被消费的元素，那么有可能出现OOM。 结构 LinkedBlockingQueue继承了抽象队列，并且实现了阻塞队列，因此它具备队列的所有基本特性。 属性12345678910111213141516171819202122232425262728293031323334public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { //用来存放元素的节点 static class Node&lt;E&gt; { E item; //指向下一个节点 Node&lt;E&gt; next; Node(E x) { item = x; } } //队列的容量 private final int capacity; //队列的元素个数，线程安全 private final AtomicInteger count = new AtomicInteger(); //节点头（头节点元素值为null,不存放实际数据) transient Node&lt;E&gt; head; //节点尾 private transient Node&lt;E&gt; last; //消费锁 private final ReentrantLock takeLock = new ReentrantLock(); //控制消费的条件锁 private final Condition notEmpty = takeLock.newCondition(); //生产锁 private final ReentrantLock putLock = new ReentrantLock(); //控制生产的条件锁 private final Condition notFull = putLock.newCondition();} 方法构造方法12345678910111213141516171819202122232425262728293031323334353637//初始化，默认容量为Integer.MAX_VALUEpublic LinkedBlockingQueue() { this(Integer.MAX_VALUE);}//初始化，指定容量public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; //初始化头尾节点，内部元素为空 last = head = new Node&lt;E&gt;(null);}//通过集合初始化public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) { this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; //从未竞争，但对于可见性而言却是必需的，跟ArrayBlockingQueue中一样，为什么这里要加上锁呢？ putLock.lock(); // Never contended, but necessary for visibility try { int n = 0; for (E e : c) { if (e == null) throw new NullPointerException(); if (n == capacity) //如果传入的集合长度超过默认的容量Integer.MAX_VALUE，抛出异常 throw new IllegalStateException(\"Queue full\"); //加入到链表尾部 enqueue(new Node&lt;E&gt;(e)); ++n; } //元素数+1 count.set(n); } finally { putLock.unlock(); }} 生产方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109//向队列中添加元素响应中断public void put(E e) throws InterruptedException { //队列不能插入元素为null if (e == null) throw new NullPointerException(); int c = -1; //创建一个新的节点用于存储元素 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; //&lt;1&gt;.为啥要用AtomicInteger来记录count final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { //如果超过了容量，那么等待 while (count.get() == capacity) { notFull.await(); } //加入到尾部 enqueue(node); //将容量数+1，但是注意 count.getAndIncrement()结果返回的是count未+1前的结果 c = count.getAndIncrement(); //如果链表长度没有超过限制容量，那么唤醒其中一个生产线程 //&lt;2&gt;.为什么要在这里唤醒一个其他的生产线程 if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } //如果c==0，代表之前队列是空的，现在有数据了，那么要释放其他等待的消费线程 //&lt;3&gt;为什么容量为0的时候才唤醒消费线程，之前不是空的时候，就不能释放么 if (c == 0) signalNotEmpty();}//向队列中添加元素响应中断，超时阻塞public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); //计算超时时间 long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { //如果队列满了阻塞 while (count.get() == capacity) { //如果超时了直接返回false if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); } //添加元素到队列尾部 enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } if (c == 0) signalNotEmpty(); return true;}////向队列中添加元素响应中断，获取锁后，如果队列满，立即返回falsepublic boolean offer(E e) { if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try { //如果队列还没满 if (count.get() &lt; capacity) { enqueue(node); //元素数+1，返回旧的count值 c = count.getAndIncrement(); //如果队列至少还有一个空余，那么唤醒其中一个生产线程 if (c + 1 &lt; capacity) notFull.signal(); } } finally { putLock.unlock(); } if (c == 0) signalNotEmpty(); return c &gt;= 0;}//释放队列不为空的信号，唤醒其中一个消费的线程private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); }}//添加元素到链表尾部private void enqueue(Node&lt;E&gt; node) { // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node;} &lt;1&gt;处，为什么我们上面要用到AtomicInteger来更新count,以上面的put方法为例，由于生产消费不是使用的同一把锁，因此使用put方法生产元素的时候，其他生产的线程会被阻塞，但是消费的线程不会阻塞。将count进行自增操作时候，可能会出现不一致的情况。因此必须使用AtomicInteger来保证它的线程安全。 &lt;2&gt;处，为什么要通过c + 1 &lt; capacity这里判断，来唤醒生产线程，因为notFul这里可能阻塞着多个生产线程，而取元素的时候，只有是队列是满的时候，才会通过signalNotFull()方法唤醒一个生产线程。 那么，为什么队列满的时候才唤醒notFull呢，因为唤醒是需要加上putLock的，为了减少锁的次数，所以在这里索性就检测一下，未满就释放其他notFull上面的线程。 &lt;3&gt;处，为什么容量为0的时候才唤醒消费线程，之前不是空的时候，就不能释放么。其实道理跟&lt;2&gt;处，一样都是为了减少锁的次数，才选择到临界条件时，通过获取对方锁来唤醒线程的操作。 消费方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121//从队列中消费消息，响应中断public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { //如果队列为空，那么阻塞等待被唤醒 while (count.get() == 0) { notEmpty.await(); } //将头节点从队列中移除，并返回新的头节点 x = dequeue(); //元素数-1 c = count.getAndDecrement(); //如果队列中至少还有一个元素，那么唤醒别的消费线程 if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } //如果元素数等于容量，也就是说之前队列是满的，现在未满，那么唤醒一个生产线程 if (c == capacity) signalNotFull(); return x;}//从队列中消费消息，响应中断，超时阻塞//逻辑基本跟上面的一样public E poll(long timeout, TimeUnit unit) throws InterruptedException { E x = null; int c = -1; long nanos = unit.toNanos(timeout); final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); } x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x;}//从队列中消费消息，如果发现队列为空，立即返回null,否则将节点从队列中移除并返回public E poll() { final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { if (count.get() &gt; 0) { x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); } } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x;}//从队列中获取最新的元素，public E peek() { if (count.get() == 0) return null; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { Node&lt;E&gt; first = head.next; if (first == null) return null; else return first.item; } finally { takeLock.unlock(); }}//&lt;1&gt;将节点从链表中移除并返回private E dequeue() { // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; //头节点的item为null Node&lt;E&gt; h = head; // Node&lt;E&gt; first = h.next; //引用自身，帮助GC回收 h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;}//获取生产锁，唤醒其他生产线程private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); }} &lt;1&gt;处。队列中头结点和尾结点一开始总是指向一个哨兵的结点，它不持有实际数据，当队列中有数据时，头结点仍然指向这个哨兵，尾结点指向有效数据的最后一个结点。这样做的好处在于，与计数器 count 结合后，对队头、队尾的访问可以独立进行，而不需要判断头结点与尾结点的关系。","link":"/2020/03/14/LinkedBlockingQueue/"},{"title":"LinkedHashMap源码解析(jdk1.8)","text":"概述LinkedHashMap是Map 接口的哈希表和链接列表实现，具有可预知的迭代顺序。 此实现提供所有可选的映射操作，并允许使用null值和null键。由于LinkedHashMap中很多方法直接继承自HashMap，因此在看本章之前，建议先看看HashMap的源码解析。 结构特点 LinkedHashMap继承自HashMap,实现了Map的接口。与HashMap不同之处在于，LinkedHashMap通过维护着一条双向链表，解决了HashMap 不能随时保持遍历顺序和插入顺序一致的问题，并且LinkedHashMap提供了特殊的构造方法来创建链接哈希映射。 实现了Cloneable接口， 表示 LinkedHashMap支持克隆。 实现了 Serializable 接口， 表示 LinkedHashMap支持序列化的功能 ，可用于网络传输。 重要属性123456789101112131415//LinkedHashMap中通过Entry维护着元素的前后驱节点static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; { Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) { //通过HashMap中的node创建 super(hash, key, value, next); }}//链表头transient LinkedHashMap.Entry&lt;K,V&gt; head;//链表尾transient LinkedHashMap.Entry&lt;K,V&gt; tail;//如果为true，则表示访问有序（新访问的数据会被移至到链尾）。如果为false,表示插入有序。通过此参数，可以//使用LinkedHashMap设计LRU缓存;final boolean accessOrder; 常用方法构造方法12345678910111213141516171819202122232425262728293031323334//无参构造方法，默认accessOrder为falsepublic LinkedHashMap() { //调用父类构造方法 super(); accessOrder = false;}//带初始容量的构造方法，默认accessOrder为falsepublic LinkedHashMap(int initialCapacity) { super(initialCapacity); accessOrder = false;}//带初始容量、负载因子的构造方法，默认accessOrder为falsepublic LinkedHashMap(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor); accessOrder = false;}//带map对象的构造方法，默认accessOrder为falsepublic LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) { super(); accessOrder = false; //将元素放置到map中 putMapEntries(m, false);}//使用此方法，指定accessOrder为true，可以针对访问顺序调整链表顺序public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder;} Node节点12345678910111213141516171819202122232425//LinkedHashMap中的节点，e为nullNode&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) { //创建Entry LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); //将改节点插入到链表尾部 linkNodeLast(p); return p;}private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) { //记录尾节点 LinkedHashMap.Entry&lt;K,V&gt; last = tail; //将元素置为尾节点 tail = p; //如果尾节点为空，说明该链表中没有元素 if (last == null) //将元素置为头节点 head = p; else { //否则将该元素置为尾节点 p.before = last; last.after = p; }} HashMap预留的后置方法123void afterNodeAccess(Node&lt;K,V&gt; p) { }void afterNodeInsertion(boolean evict) { }void afterNodeRemoval(Node&lt;K,V&gt; p) { } 前面我们解析HashMap的时候，就发现HashMap在执行一些方法后，就会执行上面空方法，而这些空方法就是留给LinkedHashMap扩展实现的。LinkedHashMap正是通过重写这三个方法来保证链表的插入、删除的有序性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//移除指定节点的后置方法，将节点从当前LinkedHashMap的双向链表中去除void afterNodeRemoval(Node&lt;K,V&gt; e) { // unlink //记录节点，b前驱节点，a后驱节点 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //当前节点前后驱节点置为null，便于gc回收 p.before = p.after = null; //如果b为null,说明被移除的是头节点，那么记录后驱节点a为头节点 if (b == null) head = a; else //否则将前驱节点b的后驱节点指向后驱节点a b.after = a; //如果a为null，说明被移除的是尾节点，那么记录前驱节点为头节点 if (a == null) tail = b; else //否则将后驱节点a的前驱节点指向前驱节点b a.before = b;}//添加节点的后置方法，可能移除当前双向链表中最老的节点，evict为truevoid afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first;， //如果evict为true,当前双向链表中存在元素，且允许移除最老的节点 if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) { K key = first.key; //移除头节点 removeNode(hash(key), key, null, false, true); }}// 返回false, 所以LinkedHashMap不会删除最少使用的节点，子类可以通过覆盖此方法实现不同策略的缓存protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return false;}//访问节点的后置方法，将节点移动到双向链表的尾部void afterNodeAccess(Node&lt;K,V&gt; e) { // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; //accessOrder 为 true，表示访问过后的节点，移动到链表的尾部 if (accessOrder &amp;&amp; (last = tail) != e) { LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; //操作数+1 ++modCount; }} get方法1234567891011121314151617181920//通过key找寻对应的值public V get(Object key) { Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; //accessOrder为true，将访问的节点移动到链表尾部 if (accessOrder) afterNodeAccess(e); return e.value;}//通过key找寻对应的值，如果没找到，返回默认值public V getOrDefault(Object key, V defaultValue) { Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return defaultValue; //accessOrder为true，将访问的节点移动到链表尾部 if (accessOrder) afterNodeAccess(e); return e.value;} 总结LinkedHashMap的源码解析就到这里了。从上面的一些方法中就可以看出来LinkedHashMap的特点：LinkedHashMap 通过 Entry 维护了一条双向链表，实现了散列数据结构的有序遍历。同时内部支持通过访问顺序，来调整双向链表的节点顺序，可以通过此特性，实现LRU算法。","link":"/2019/07/06/LinkedHashMap/"},{"title":"对DDD的总结","text":"前言第一次听到DDD，还是通过技术群内部大佬们的闲聊得知。本着求知的心态，在网上简单看了一下DDD相关的知识。晦涩的术语，抽象的描述，看了半天不禁感叹，大佬们之间的聊天话题，果然不是我等咸鱼可以企及的。看着大佬们在群里谈笑风生，羡慕他们广阔的知识面之余，我也对DDD产生了兴趣，接着便是加大力度在网上搜索相关的文章、视频。文章很多，视频很少，能让我这种咸鱼看完之后能理解的，更是少之又少。不过也不是毫无收获，总的看下来，对DDD也是有了一定的理解。接下来我将通过我所看到的文章、视频、以及我自身对DDD的理解，以我能理解的方式，对DDD中比较常见的概念、术语做一个总结，除了巩固一下自身对DDD的认识，也希望能给看到这篇文章的同学，提供学习DDD方面的参考。在这里给大家推荐&lt;&lt;阿里技术专家详解DDD系列&gt;&gt;。 什么是DDDDDD即domain-driven design（领域驱动设计)，它是一种架构思想，而非实际使用的框架。在传统的开发模式中，经常是接到业务后，我们就开始根据业务涉及的场景、交互方式、页面元素等信息，来构建我们的表模型、画流程图，最终通过对数据的操作来实现我们的功能，这就是典型的数据驱动设计。而DDD思想主张从业务角度出发，对业务模型进行分析，通过构建我们的领域模型，由领域来驱动设计。 DDD术语领域驱动设计主要分为了两个过程：战略设计、战术设计。战略设计主要是通过系统整体，来帮助我们划分领域以及处理领域间的关系；而战术设计则从设计实现的层面教会我们如何具体地实施DDD，更偏向于开发。 战略设计DDD的战略设计主要包括领域/子域、通用语言、限界上下文等概念。 领域百度百科对领域的解释： 具体指一种特定的范围或区域，一种专门活动或事业的范围、部类或部门。 由此可以看出：领域就是来确定范围的，范围即边界，DDD 的领域就是要解决的业务范围。例如在电商系统中，可能有“商品领域”，“订单领域”，“仓储领域”，“物流领域”。而领域模型指的就是业务的载体，例如，商品，订单。 子域既然领域是用来限定业务边界和范围的，那么就会有大小之分，领域越大，业务范围就越大，反之则相反。如果一个领域过大，还可以把领域可以进一步划分为子领域。划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。根据重要性与功能将可以领域分为大致三类的多个子域，分别是核心域、支撑子域和通用子域。 核心域：决定产品和公司核心竞争力的子域，是业务成功的主要因素和公司的核心竞争力。 支撑子域：既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，但又是必需的支撑域。支撑域具有企业特性，但不具通用性，例如数据代码类的数据字典等系统。 通用子域：没有太多个性化需求，同时被多个子域使用的通用功能子域。比如认证、权限等，无企业特点限制，无需太多定制化。 例如在一个商城系统中，用户下单、支付、退款是商城中最基本也是最核心的功能，也就是核心域；会员、意见反馈等不影响主要功能的就是支撑子领域；认证、权限、消息等基础服务，可通用且与业务关系不大的功能就是通用子域。 Bounded Context（限界上下文） 每个限界上下文专注于解决某个特定的子域的问题。 每个子域都对应一个明确的问题，提供独立的价值，所以每个子域都相对独立。 子域及其对应的限界上下文中的模型会因为其要解决的问题变化而变化，不会因为其他子域的变化而变化，即低耦合；当一个子域发生变化时，只需要修改其对应限界上下文中的模型，不需要变动其他子域的模型，即高内聚。 我们对Context（上下文）的概念应该并不陌生，平时开发中我们经常会将“上下文”理解为“作用域”，或者说是一个“范围”。例如我们的Spring Context、Session Context。我们通过当前所处的上下文环境，来判断某些状态、行为的作用或代表的含义。DDD中的限界上下文也是同一个道理，它表示领域的边界。在上下文覆盖的范围，领域内的状态或行为有自己的含义。 例如：我购买了一套复式的毛坯房，准备自己装修设计，一楼朝南部分划分一大块区域做为客厅，旁边划分一小块区域做为厨房，朝北的做为厕所。二楼划分了两块，大的一块做为卧室、小的做为阳台。我通过房子的朝向、风口，来划分客厅、阳台、厕所，其实就是通过分析当前的场景，来划分领域的动作。区域覆盖的范围，代表不同的领域，它的边界，就是我们的所说的“限界上下文”，范围也被赋予了含义。 Context Map（上下文映射）上下文映射，表示界限上下文的一种映射关系，它可以让我们从宏观上看到每个上下文之间的联系，一旦发现某个限界上下文与过多的其它限界上下文具有联系，我们就可以对限界上下文进行细分了。前面我们将房子根据场景分配了几个大小不一区域，从客厅去我们的卧室，需要通过连接一楼到二楼的楼梯，去厨房我们需要经过走廊，从一个领域到达另一个领域，连接楼层的楼梯与连接客厅厨房的走廊，其实就对应着领域上下文之间的映射。 Ubiquitous Lanuage（上下文通用语言）限界上下文需要通过上下文通用语言来理解领域模型代表的动作与含义。还是用前面建房子来举例，我分配完各自的区域后，需要在各自的区域装上门，将门装到厕所，它就是厕门；装在客厅，它就是大门。同样的门，被安装在不同的区域（领域上下文），表达的意思也不同，这就是我们所说的“上下文通用语言”。在汉语中，我们可以将界限上下文理解为“语境”，上下文通用语言理解为“语意”。在不同的“语境”，“语意”的含义也不同。 战术设计与战略设计不同，战术设计更关注代码层面的实现，通过面向对象的思维设计类的属性与方法，将DDD落地到实际的开发中。 基本概念Entity（实体）通俗来讲，就是由方法和属性实现业务的类，与传统的VO（View Object）只有getter、setter方法不同，实体一般由唯一标识ID和值对象组成，并且有自己的状态和行为，并且状态的变更也会影响到行为，状态与行为应该保持一致。DDD中将VO（View Object）这种只有getter、setter方法，没有状态、行为的对象称之为“贫血对象”，而Entity是属于“充血对象”的一种。对象是否拥有状态与行为，是判断对象是否贫血的依据。 例如：人通过身份证号作为唯一标识，具有唯一性，我们也有自己状态，与自己的行为。 12345678910111213141516171819202122232425262728293031public class Person { //Id作为唯一标识 private String idCard; //姓名 private String name; //年龄 private String age; //性别 private Integer sex; //家庭住址 private Address address; //是否已成年, 表示状态 public boolean isAdult() { return age &gt;= 18; } //喝酒 public void drinkWine(){ if(!isAdult()) { System.out.print(\"未成年人不能饮酒！\") } else { System.out.print(\"吨吨吨。。。\") } }} Value Object（值对象） 没有唯一标识，不具备唯一性，具有校验、判断逻辑，只关心对象的值，没有状态和行为。 值对象，顾名思义这是一个由“值”组成的对象。“值”代表的含义，其实就是指没有状态的属性。 例如：在一个订单领域中，Address只作为地址信息来说，它就不具备唯一性，作为一个值对象，它没有任何行为。当然你也可以为Address赋予唯一的含义与标识，在地图领域中，Address可能代表的是北京、或者上海，你可以给它加上唯一标识，但此时，他也就不是一个值对象了。也就是说，一个对象在DDD的概念中，对象代表的概念，并不是非黑即白。当它处于不同的领域上下文时，代表着不同的含义，其实也就是上面所说到的“限界上下文”这么一个概念。 12345678910111213public class Address { private String city; private String province; private String district; //获取完整地址 public String getCompleteAddress (){ return province + city + district }} Aggregate（聚合） 聚合中所包含的对象之间具有密不可分的联系，一个聚合中可以包含多个实体和值对象，因此聚合也被称为根实体。 聚合在DDD中是跟领域挂钩的，它通过实体与值对象组成；本质上就是建立了一个比对象粒度更大的边界，用于聚集那些紧密关联的对象，形成了一个业务上的对象整体。例如下面这个类： 12345678910111213141516171819202122232425public class Emp { //员工ID，值对象 private AgentId agentId; //员工基础信息, 值对象 private EmpBaseInfo empBaseInfo; //个人身份信息，实体 private Person person; //工作地址 private Address address;}//员工基本信息public class EmpBaseInfo { //花名 private String nickName; //职级 private Integer level;} Factories（工厂）复杂对象的创建是领域层的职责，但这项任务并不一定属于那些用于表示模型的对象，他们没有对应模型中的事物，但又确实承担了领域层的职责。应该将创建复杂对象和聚合的职责转移给单独的对象，这个对象本身可能没有承担领域模型中的职责，但它仍然是领域设计的一部分。提供一个封装所有复杂装配操作的接口，而且这个接口不需要客户引用要被实例化的对象的具体类。在创建聚合时要把它作为一个整体，并确保它满足固定规则。 Repositories（仓储）日常开发中，我们经常会用到到Repositories，作为一个Dao，它主要负责操作DO对象，与底层数据库进行交互。但是在DDD中，Repositories不等于Dao，Repository对应的是对Entity对象读取储存的抽象，在接口层面做统一，不关注底层实现。Repository的具体实现类通过调用Dao来实现各种操作，通过Builder/Factory对象实现DO到Entity之间的转化。DDD中数据资源的访问与维护只能由Repositories来操作。 Domain Service (领域服务)当某个行为不属于任何一个领域时，那么就需要领域服务来涉及多个领域对象的操作。&lt;阿里技术专家详解DDD系列&gt;&gt;中就举了一个玩家打怪兽的例子，如果玩家有攻击怪兽这么一个行为，映射到我们领域模型中，那么是在玩家领域中攻击了怪兽，还是怪兽领域中被玩家攻击，此时在代码层面，攻击野兽这个行为，无论放到哪个领域中都不太合理，因此需要一个领域服务来专门处理这种跨领域的行为。 Domain Primitive（基础类型） Domain Primitive 是一个在特定领域里，拥有精准定义的、可自我验证的、拥有行为的 Value Object。 Domain Primitive（DP）是Value Object的进阶版，在原始VO的基础上要求每个DP拥有概念的整体，而不仅仅是值对象。其主要作用： 让隐性的概念显性化 让隐性的上下文显性化 封装多对象行为 常见的 DP 的使用场景包括： 有格式限制的 String：比如Name，PhoneNumber，OrderNumber，ZipCode，Address等 有限制的Integer：比如OrderId（&gt;0），Percentage（0-100%），Quantity（&gt;=0）等 可枚举的 int ：比如 Status（一般不用Enum因为反序列化问题） Double 或 BigDecimal：一般用到的 Double 或 BigDecimal 都是有业务含义的，比如 Temperature、Money、Amount、ExchangeRate、Rating 等 复杂的数据结构：比如 Map&lt;String, List&gt; 等，尽量能把 Map 的所有操作包装掉，仅暴露必要行为 DDD分层架构前面战术设计主要介绍了，DDD中的一些基本概念。现在我们就来讲讲DDD在我们工作中如何具体的实施，不同于传统的三层模型，Controller、Service、Dao不同，DDD的分层更加复杂，从下图可以看出架构中的层级关系。 Interaface（接口层）接口层处于架构的最上层，提供系统对外暴露的接口。主要功能是接收外部的请求，调用底层的服务，然后将底层服务返回的数据返回给调用者。这一层只包含对外的DTO对象的声明，接口声明，DTO对象转换，日志打印等。不能包含因为逻辑。 Application（应用层）应用层描述了整个系统的全部功能，它不实现业务逻辑，只对底层的领域对象进行编排以实现用例。一般在这一层里使用Repositories（仓储）对数据进行读取和保存。事务处理一般也在这一层。这一层主要包括Service，用来调用Domain层的对象完成一个业务。访问第三方的远程调用一般也是在这一层。 Domain（领域层）Domain模块是核心业务逻辑的集中地，包含有状态的实体、聚合、领域服务Domain Service、以及各种外部依赖的接口类（如Repository、ACL、中间件等。领域层出现的pojo对象只有领域对象，不能出现别的DTO，DO，VO这些对象； Infrastructure（基础设施层）负责所有的对外的交互。比如数据库访问层实现，RPC接口，MQ等。 服务视图DDD实战12 接下来我们将从实际的业务出发 未完待续。。。 参考文档 https://ld246.com/article/1574177012526 https://zhuanlan.zhihu.com/p/366395817 https://insights.thoughtworks.cn/ddd-aggregation-bounded-context/","link":"/2021/07/18/DDD-learn/"},{"title":"LinkedList源码解析(jdk1.8)","text":"概述跟ArrayList一样，LinkedList也是List的实现类。不过ArrayList是基于数组实现的，而LinkedList是基于链表实现的。 LinkedList比较适合进行增加、删除的操作，因为只需要改变链表中节点的指向。而对于获取元素，LinkedList则没那么容易。与ArrayList不同，只需要传入坐标位置，就能根据底层数组，获取到指定位置的元素。LinkedList需要通过遍历列表的方式来匹配元素，因此效率比较低。最后，LinkedList是线程不安全的。 结构特点 LinkedList继承了AbstractList 、AbstractSequentialList ，实现了List。提供了相关的添加、删除、修改、遍历等功能。AbstractSequentialList 不像 AbstractList 可以实现随机访问。AbstractSequentialList 只支持次序访问。如果想访问某个元素， 必须从链头开始顺着指针才能找到。 LinkedList实现了Deque，因此LinkedList既是一个列表的同时，也是一个双端队列。提供了相关出队、入队等功能。 实现了Cloneable接口， 表示 LinkedList支持克隆。 实现了 Serializable 接口， 表示 LinkedList支持序列化的功能 ，可用于网络传输。 重要属性123456789101112131415161718192021222324252627public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable{ //实际元素个数 transient int size = 0; //头节点 transient Node&lt;E&gt; first; //尾节点 transient Node&lt;E&gt; last; //内部类node，用于储存元素的节点 private static class Node&lt;E&gt; { //当前节点元素 E item; //上一个节点 Node&lt;E&gt; next; //下一个节点 Node&lt;E&gt; prev; //创建节点，指定上一个和下一个节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; } }} 常用方法构造方法LinkedList是由链表组成的无界队列，不需要指定容器，也不需要扩容。 1234567891011//无参构造方法，用于创建LinkedList实例public LinkedList() {}//通过传入的Collection集合，创建拥有指定节点的LinkedList实例public LinkedList(Collection&lt;? extends E&gt; c) { //使用无参构造方法创建实例 this(); //将所有元素添加到LinkedList中 addAll(c);} 添加元素方法add方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104//将指定的集合中的所有元素添加到LinkedList中public boolean addAll(Collection&lt;? extends E&gt; c) { //将所有的元素添加到LinkedList的末尾 return addAll(size, c);}//将指定集合所有的元素添加到LinkedList的指定位置后public boolean addAll(int index, Collection&lt;? extends E&gt; c) { checkPositionIndex(index); //将传入的集合转化为数组 Object[] a = c.toArray(); int numNew = a.length; //如果传入的元素为空，返回失败 if (numNew == 0) return false; //pred:插入元素位置的上一个元素 succ：被插入的当前元素 Node&lt;E&gt; pred, succ; if (index == size) { //&lt;1&gt;.index==size，说明插入的位置在LinkedList的末尾，此时，index下没有元素 succ = null; //当前index的上一个元素，也就是末尾元素 pred = last; } else { //获取下标获取当前元素 succ = node(index); //记录上一个元素 pred = succ.prev; } //遍历插入 for (Object o : a) { @SuppressWarnings(\"unchecked\") E e = (E) o; //为当前传入的元素创建节点，指定上一个节点，下一节点为null Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) //如果上一个元素为null，说明当前LinkedList中不存在元素，指定头结点为当前节点 first = newNode; else //否则指定下一个节点为当前节点 pred.next = newNode; //对于下一个要插入的元素来说，上一个节点，就是当前节点 pred = newNode; } if (succ == null) { //如果succ == null，根据&lt;1&gt;处，说明当前是向末尾插入元素， //那么最后一个插入的元素，就是新的尾节点 last = pred; } else { //否则，最后插入的元素的下一个，就是被插入的元素 pred.next = succ; //同理，被插入的元素的上一个就是最后一个插入的元素 succ.prev = pred; } //节点数增加numNew个元素 size += numNew; //操作数+1 modCount++; return true;}//向LinkedList末尾添加元素public boolean add(E e) { //向尾部添加节点 linkLast(e); return true;}//向指定的位置加入元素public void add(int index, E element) { //校验传入参数 checkPositionIndex(index); if (index == size) //index == size，向尾部添加元素 linkLast(element); else //否则就是在指定节点前，添加元素 linkBefore(element, node(index));}//检查当前的传入的坐标是否越界private void checkPositionIndex(int index) { if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));}//检查当前坐标是否在元素列表范围内private boolean isPositionIndex(int index) { return index &gt;= 0 &amp;&amp; index &lt;= size;}//向头部添加元素，用于兼容Deque中的方法public void push(E e) { addFirst(e);}//向头部添加元素，用于兼容Deque中的方法public void addFirst(E e) { linkFirst(e);}//向尾部添加元素，用于兼容Deque中的方法public void addLast(E e) { linkLast(e);} 上述方法中，存在着许多相似的方法，但它们的应用场景有所不同，后面offer方法中会提出。 link方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//将节点插入到尾部void linkLast(E e) { //记录尾节点 final Node&lt;E&gt; l = last; //创建节点，指定上一节点为当前的尾节点，下一节点为null final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //替换尾节点为当前插入的节点 last = newNode; if (l == null) //如果记录的尾节点为null，说明集合中不存在元素，那么首尾为同一节点 first = newNode; else //否则,记录的尾节点的下一个节点为新的尾节点 l.next = newNode; //节点数+1 size++; //操作数+1 modCount++;}//将节点插入到头部private void linkFirst(E e) { //记头尾节点 final Node&lt;E&gt; f = first; //创建节点，指定上一节点为null，下一节点为记录的头结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //替换头节点为当前插入的节点 first = newNode; if (f == null) //如果记录的头节点为null，说明集合中不存在元素，那么首尾为同一节点 last = newNode; else //否则,记录的头节点的上一个节点为新的尾节点 f.prev = newNode; //节点数+1 size++; //操作数+1 modCount++;}//将元素插入到指定节点前void linkBefore(E e, Node&lt;E&gt; succ) { //记录被插入节点的上一个节点 final Node&lt;E&gt; pred = succ.prev; //创建节点，指定上一节点为pred，下一节点为succ final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //指定被插入节点的上一节点为新建节点 succ.prev = newNode; if (pred == null) //如果pred == null，说明插入到了头部，那么设置新的头结点为新节点 first = newNode; else //否则，指定pred的下一个节点为新创建的节点 pred.next = newNode; size++; modCount++;} 从link方法前缀就可以看出，上面的方法是作为一个链表时的操作。 offer方法（实现Deque中的方法）12345678910111213141516//添加元素到末尾public boolean offer(E e) { return add(e);}//添加元素到头部public boolean offerFirst(E e) { addFirst(e); return true;}//添加元素到末尾public boolean offerLast(E e) { addLast(e); return true;} 看到这里有些读者可能会疑惑，上面的三个方法，看起来作用跟add的方法类似，那么它们的区别是什么，为什么要这么做。 LinkedList实现了List和Deque接口，兼容了Deque中的方法。因此，LinkedList即是一个列表，也是一个队列。把LinkedList当做一个List时，通过调用add方法压入/获取对象 。而把LinkedList当做一个Deque的时候，通过调用 offer方法，实现队列的入队出队操作。因此上面几个方法，作用看似差不多，但是应用场景不同。 node节点方法重要属性中已经介绍了Node节点的相关信息，接下来看看Node的方法: 123456789101112131415161718192021//获取指定坐标的节点Node&lt;E&gt; node(int index) { // assert isElementIndex(index); //&lt;1&gt;.如果当前坐标位置,小于当前元素大小的一半，那么就从头部开始遍历节点，直到找到指定节点 //位运算符&gt;&gt;, size &gt;&gt; 1相当于size/2 if (index &lt; (size &gt;&gt; 1)) { //记录头部 Node&lt;E&gt; x = first; //从头部，依次遍历 for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { //记录尾部 Node&lt;E&gt; x = last; //从尾部，依次遍历 for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } &lt;1&gt;处,也就是说，如果当前坐标，在链表的中间点前，也就是比较靠近头部，那么从头开始查找，如果当前靠近尾部，那么从尾部开始查找，最近原则。 获取元素12345678910111213141516171819202122232425262728293031323334353637383940//获取下标元素public E get(int index) { //&lt;1&gt;.检查传入的index合法性 checkElementIndex(index); //返回指定位置节点的元素 return node(index).item;}//获取头元素public E element() { return getFirst();}//获取头元素,如果不存在，抛出异常public E getFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; }//获取头元素,如果不存在，抛出异常public E getLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; }//获取头元素，如果队列为空，返回nullpublic E peek() { final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;}//获取头元素，并移除。如果队列为空，返回nullpublic E poll() { final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);} 虽然LinkedList没有禁止添加null元素，但是一般情况下Queue的实现类都不允许添加null元素。因为poll这种方法在异常的时候返回也是null，如果有null元素，就很难分辨这些函数返回null到底是出现错误了还是在正常运行。 &lt;1&gt;处，检查元素下标是否在范围内 123456789private void checkElementIndex(int index) { if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));}private void checkPositionIndex(int index) { if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));} 移除元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161//出队public E pop() { //返回被移除的头节点 return removeFirst();}//移除头节点并返回元素public E removeFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); //移除返回头节点 return unlinkFirst(f);}//移除尾节点并返回元素public E removeLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); //移除返回尾节点 return unlinkLast(l);}//从指定节点位置截断链表，保留后段链表，返回指定节点元素，调用此方法传入的f == first都为头节点//这也是方法叫做unlinkFirst的原因吧private E unlinkFirst(Node&lt;E&gt; f) { // assert f == first &amp;&amp; f != null; //当前节点元素 final E element = f.item; //记录下一个节点 final Node&lt;E&gt; next = f.next; //当前节点元素,和指向置为null，便于gc回收 f.item = null; f.next = null; // help GC //当下一节点置为头节点 first = next; if (next == null) //如果next == null，说明移除的节点为尾节点，将last置为null，相当于删除了整个链表节点 last = null; else //否则，next成头节点后，不存在上一个节点，因此置为null next.prev = null; //只移除了头节点，节点数量-1 size--; //操作数+1 modCount++; return element;}//从指定节点位置截断链表，保留前段链表，返回指定节点元素，调用此方法传入的f默认 f == last，传入的都是尾节点//移除尾节点，并返回元素private E unlinkLast(Node&lt;E&gt; l) { // assert l == last &amp;&amp; l != null; //当前节点元素 final E element = l.item; //记录上一个节点 final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC //当上一节点置为尾节点 last = prev; if (prev == null) first = null; else prev.next = null; //只移除了尾节点，节点数量-1 size--; modCount++; return element;}//移除指定节点，并返回节点元素E unlink(Node&lt;E&gt; x) { // assert x != null; //记录当前节点元素 final E element = x.item; //记录下一个节点 final Node&lt;E&gt; next = x.next; //记录上一个节点 final Node&lt;E&gt; prev = x.prev; if (prev == null) { //如果上一个节点为null，说明当前节点为头节点，被移除之后，下一个节点就是头节点 first = next; } else { //否则将上一个节点的指向下一个 prev.next = next; //无效的节点的引用置为null x.prev = null; } if (next == null) { //如果下一个节点为null，说明当前节点为尾节点，那么上一个节点就是尾节点了 last = prev; } else { //否则下一个节点的前驱节点就是上一个节点了 next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element;}//移除并返回指定下标节点public E remove(int index) { checkElementIndex(index); return unlink(node(index));}//移除指定节点，如果不存在返回faslepublic boolean remove(Object o) { if (o == null) { //遍历为元素为null的节点 for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (x.item == null) { //移除素为null节点，返回true unlink(x); return true; } } } else { //遍历为元素为o的节点 for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) { //移除元素为o节点，返回true unlink(x); return true; } } } return false;}//移除元素节点，从链表头开始public boolean removeFirstOccurrence(Object o) { return remove(o);}//移除元素节点，从链表尾开始public boolean removeLastOccurrence(Object o) { if (o == null) { for (Node&lt;E&gt; x = last; x != null; x = x.prev) { if (x.item == null) { unlink(x); return true; } } } else { for (Node&lt;E&gt; x = last; x != null; x = x.prev) { if (o.equals(x.item)) { unlink(x); return true; } } } return false;} iterator迭代器跟ArrayList 一样，LinkedList也实现了自己的迭代器，关于ListIterator在ArrayList源码分析中也有说明。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152private class ListItr implements ListIterator&lt;E&gt; { //上次访问的节点 private Node&lt;E&gt; lastReturned; //下一个要迭代的节点 private Node&lt;E&gt; next; //下一个要迭代的位置 private int nextIndex; //期望值 private int expectedModCount = modCount; //唯一的构造方法，创建一个迭代器从index位置开始迭代 ListItr(int index) { // assert isPositionIndex(index); //&lt;1&gt;.如index == size，那么说明从尾部开始，下一个迭代的节点为null，否则获取下一个要迭代的节点 next = (index == size) ? null : node(index); //设置下一个要迭代的位置 nextIndex = index; } //是否存在下一个结点 public boolean hasNext() { return nextIndex &lt; size; } //获取下一个元素 public E next() { //&lt;1&gt;.校验链表是否发生了变化 checkForComodification(); //如果不存在下一个元素，则抛出异常 if (!hasNext()) throw new NoSuchElementException(); //上次访问的节点设置为当前操作的节点 lastReturned = next; //替换next为下一个要迭代的节点 next = next.next; //下一个要迭代的位置 + 1，向后 nextIndex++; //返回当前操作节点的元素 return lastReturned.item; } //是否存在上一个节点 public boolean hasPrevious() { return nextIndex &gt; 0; } //获取上一个元素 public E previous() { //&lt;2&gt;.校验链表是否发生了变化 checkForComodification(); //如果不存在上一个元素，则抛出异常 if (!hasPrevious()) throw new NoSuchElementException(); //设置上次访问的节点和最后一个迭代的节点 //&lt;3&gt;.如果next == null，说明&lt;1&gt;处，创建迭代器时index == size，此时下一个要迭代的就是尾元素 lastReturned = next = (next == null) ? last : next.prev; //下一个要迭代的位置 - 1，向前 nextIndex--; //返回上次访问的节点的元素 return lastReturned.item; } //获取下一个要迭代的元素位置 public int nextIndex() { return nextIndex; } //获取上一个要迭代的元素位置 public int previousIndex() { return nextIndex - 1; } //移除元素 public void remove() { //校验链表是否发生了变化 checkForComodification(); //如果上次访问的节点为null，说明当前没有迭代过元素，会抛出异常 if (lastReturned == null) throw new IllegalStateException(); //记录下一个元素 Node&lt;E&gt; lastNext = lastReturned.next; //调用外部的LinkedList的unlink方法，移除上次访问的节点 unlink(lastReturned); if (next == lastReturned) /** * 如果next == lastReturned，看&lt;3&gt;处，说明此时元素是向前迭代 * 那么next此时，就应该是当前移除元素的下一个节点， * 而下一次，迭代的节点，就是它的前驱节点, * 不明白可以看看&lt;3&gt;处 */ next = lastNext; else /** * 调用next方法中，nextIndex会+1，此时移除节点后， * 让nextIndex保持在当前元素准备移除前的位置 */ nextIndex--; //设置上次访问的节点为null lastReturned = null; //因为上面unlink方法操作数会+1，此时期望值也+1，保持同步， expectedModCount++; } //设置最后迭代的元素值 public void set(E e) { if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; } //从下一个处理节点后插入新节点 public void add(E e) { checkForComodification(); //设置上次访问的节点为null lastReturned = null; if (next == null) //如果next = null，&lt;1&gt;处，说明构造方法指定元素迭代位置在末尾，从末尾后添加元素 linkLast(e); else //否则，从指定元素处添加元素 linkBefore(e, next); nextIndex++; expectedModCount++; } //对每个元素执行某个操作 public void forEachRemaining(Consumer&lt;? super E&gt; action) { //传入的函数不能为null Objects.requireNonNull(action); //如果nextIndex&gt;= size 或者，期望值与操作值不同，说明链表可能被修改，抛出异常 while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) { //执行操作 action.accept(next.item); //记录上次访问的节点 lastReturned = next; //更新下一次访问的节点 next = next.next; //向后迭代 nextIndex++; } //检查链表是否被修改 checkForComodification(); } //跟ArrayList中迭代器一样，LinkedList也是非线程安全 //迭代期间，如果修改次数与预期值不等，则抛出异常 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); }} LinkedList和ArrayList迭代器中一样，都有一个预期值expectedModCount，同时他们作用也一样，检查内部结构是否被改变，同样LinkedList中，想要遍历移除节点，最安全的方式就是通过迭代器，使用它自己的remove()方法。因为它有一个expectedModCount++ 让期望值与操作值保持一致。 同ArrayList中的remove()方法一样,LinkedList中的unlink()、remove()方法都是将modCount+1。如果创建LinkedList的迭代器以后，调用LinkedList的remove()方法，那么调用迭代器的next()方法，就会因为modCount != expectedModCount而抛出异常。 迭代器的创建12345678910111213141516171819202122232425//返回以正向顺序在此双端队列的元素上进行迭代的迭代器。元素将从第一个（头部）到最后一个（尾部）的顺序返回。public ListIterator&lt;E&gt; listIterator(int index) { //检查传入的参数是否合法 checkPositionIndex(index); return new ListItr(index);}//返回以逆向顺序在此双端队列的元素上进行迭代的迭代器。元素将从最后一个（尾部）到第一个（头部）的顺序返回。public Iterator&lt;E&gt; descendingIterator() { return new DescendingIterator();}//通过代理ListItr来倒置下一节点的访问顺序private class DescendingIterator implements Iterator&lt;E&gt; { private final ListItr itr = new ListItr(size()); public boolean hasNext() { return itr.hasPrevious(); } public E next() { return itr.previous(); } public void remove() { itr.remove(); }} 作为双端队列，有一个反向遍历的方法，也很正常。实际上，通过listIterator创建的迭代器，通过判断上一个元素是否存在，以及获取上一个元素，已经可以实现队列的反向遍历了。这里加入一个DescendingIterator的内部类，可以在不修改业务逻辑的情况下。通过更换迭代器，实现反向遍历。 总结LinkedList的分析讲到这里，也就已经结束了。上面分析的方法，也不是LinkedList的全部方法，还有部分方法没有讲到的。例如，toArray、clone、序列化等方法，因为这些方法也不是LinkedList特有的，同时在LinkedList中，跟其他方法的关联度较小，所以就在这里偷了个懒。之后有时间，也会将所有未讲解的方法补全。如果各位小伙伴读完文章后，发现文章中有哪些错误或者不足之处，还请在评论区中留言。笔者看到也会尽快回复。","link":"/2019/06/15/LinkedList/"},{"title":"【阻塞队列】-- PriorityBlockingQueue源码解析(jdk1.8)","text":"概述​ PriorityBlockingQueue一个无界的带有优先级的动态阻塞队列，插入队列的元素默认情况下采用自然顺序升序排列，如果用户传入了Comparator，那么使用传入的Comparator进行排序。PriorityBlockingQueue内部使用一把锁用于消费，当容量到达阈值时，会自动扩容，扩容时由volatile修饰的allocationSpinLock作为cas自旋锁的标识（保证扩容操作不会阻塞take操作）。 结构 属性12345678910111213141516171819202122232425262728293031public class PriorityBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { private static final long serialVersionUID = 5595510919245408276L; //队列默认容量 private static final int DEFAULT_INITIAL_CAPACITY = 11; //队列最大容量 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //存储元素的数组 private transient Object[] queue; //队列元素个数 private transient int size; //比较器 private transient Comparator&lt;? super E&gt; comparator; //锁用于构建消费的条件锁 private final ReentrantLock lock; //用于消费的条件锁 private final Condition notEmpty; //扩容时，作为cas自旋锁的标识 private transient volatile int allocationSpinLock; //优先级队列 private PriorityQueue&lt;E&gt; q;} 方法构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//无参构造方法，默认容量为DEFAULT_INITIAL_CAPACITY=11public PriorityBlockingQueue() { this(DEFAULT_INITIAL_CAPACITY, null);}//带初始化容量的构造方法public PriorityBlockingQueue(int initialCapacity) { this(initialCapacity, null);}//带初始化容量与比较器的构造方法public PriorityBlockingQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) { if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity];}//带集合的构造方法public PriorityBlockingQueue(Collection&lt;? extends E&gt; c) { this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); //是否需要重建堆(堆它是一个数组，不过满足一个特殊的性质) boolean heapify = true; // true if not known to be in heap order //是否需要筛选空值 boolean screen = true; // true if must screen for nulls //如果传入的是一个有序集合，那么使用集合本身的比较器 if (c instanceof SortedSet&lt;?&gt;) { SortedSet&lt;? extends E&gt; ss = (SortedSet&lt;? extends E&gt;) c; this.comparator = (Comparator&lt;? super E&gt;) ss.comparator(); heapify = false; } //如果传入集合是PriorityBlockingQueue类型，则不进行堆有序化 else if (c instanceof PriorityBlockingQueue&lt;?&gt;) { PriorityBlockingQueue&lt;? extends E&gt; pq = (PriorityBlockingQueue&lt;? extends E&gt;) c; //使用阻塞队列的比较器 this.comparator = (Comparator&lt;? super E&gt;) pq.comparator(); screen = false; if (pq.getClass() == PriorityBlockingQueue.class) // exact match heapify = false; } Object[] a = c.toArray(); //记录数组长度 int n = a.length; // If c.toArray incorrectly doesn't return Object[], copy it. //&lt;1&gt;.如果c.toArray不正确地返回Object[]，请复制它 if (a.getClass() != Object[].class) a = Arrays.copyOf(a, n, Object[].class); //如果传入的集合类型不为有序集合或者PriorityBlockingQueue，那么要校验是否传入null值 //如果传入的集合中存在null，那么抛出NullPointerException // (n == 1 || this.comparator != null) 有两种情况 //1. if (screen &amp;&amp; (n == 1 || this.comparator != null)) { for (int i = 0; i &lt; n; ++i) if (a[i] == null) throw new NullPointerException(); } //讲a赋值给队列内部储存元素的数组 this.queue = a; //设置size为n this.size = n; if (heapify) //是否堆化 heapify();} heapify方法PriorityBlockingQueue内部采用二叉堆来实现。二叉堆是一种特殊的堆，近似完全二叉树。二叉堆有两种堆：最大堆和最小堆。最大堆：父节点的键值总是大于或者等于任何一个子节点的键值；最小堆：父节点的键值总是小于或等于任何一个子节点的键值。而我们的PriorityBlockingQueue就是采用的最小堆。 二叉堆一般使用数组来表示，不过他是顺序结构存储而不是链式结构。看图： 二叉堆来实现优先队列的特点： 一般通过数组存储的逻辑二叉树结构 要么为最大堆要么为最小堆 父节点索引位 = （当前节点索引位 - 1 ）/ 1 左子节点索引位 = 当前节点索引位 * 2 + 1 右子节点索引位 = 当前节点索引位 * 2 + 2 最后一个非叶子节点索引位 = 节点数/2 - 1； 二叉堆的三个操作： 堆化：将一个完全无序的数组转化为一个符合二叉堆结构的数组 元素插入：为了不破坏现有的二叉堆结构，插入都是从最后一个元素开始，然后对该节点进行上浮操作 元素移除：删除节点时从堆顶删除，将最后一个节点置换到堆顶，然后对堆顶的元素进行下沉操作 通过上面的这些特点，以及最后的四个公式，再来看接下来的代码就要轻松许多。 123456789101112131415161718//heapify就是上面三个操作中的堆化操作private void heapify() { Object[] array = queue; int n = size; //找到最后一个非叶子节点，也就是最后一个节点的父节点 int half = (n &gt;&gt;&gt; 1) - 1; Comparator&lt;? super E&gt; cmp = comparator; //如果比较器为null,那么使用自然排序 if (cmp == null) { //从half开始向前数，对所有非叶子节点进行下沉操作 for (int i = half; i &gt;= 0; i--) siftDownComparable(i, (E) array[i], array, n); } else { for (int i = half; i &gt;= 0; i--) siftDownUsingComparator(i, (E) array[i], array, n, cmp); }} 节点上浮操作1234567891011121314151617181920212223242526272829303132333435//对节点进行上浮操作，将新插入到末尾的节点进行上浮操作private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array) { Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;) x; //k&gt;0说明还有非子叶节点存在 while (k &gt; 0) { //获取父节点的下标 int parent = (k - 1) &gt;&gt;&gt; 1; //记录父节点的值 Object e = array[parent]; //经过对比后，如果该节点的优先级已经大于父节点，那么不用进行升序了，break跳出 if (key.compareTo((T) e) &gt;= 0) break; //当前下表位置的节点指向父节点 array[k] = e; //k置为parent，接下来通过while会继续向上找，如果此时已经到最顶端了那么 //k就为0了，就会跳出结束while k = parent; } //交换最终的节点 array[k] = key;}//跟siftUpComparable逻辑一致,不同点就是使用的是用户指定的Comparator比较器private static &lt;T&gt; void siftUpUsingComparator(int k, T x, Object[] array, Comparator&lt;? super T&gt; cmp) { while (k &gt; 0) { int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (cmp.compare(x, (T) e) &gt;= 0) break; array[k] = e; k = parent; } array[k] = x;} 节点下沉操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//下沉操作，从队列中移除堆顶元素，把最后一个叶子节点替换到头部时，需要进行下沉操作private static &lt;T&gt; void siftDownComparable(int k, T x, Object[] array, int n) { //如果传入的集合为空，那么就不需要下沉操作了 if (n &gt; 0) { Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x; //记录二叉树上最后一个非叶子节点的下标，如果当前操作的坐标小于half //说明k&gt;half说明k现在记录的位置是叶子节点的位置，不用再下沉了 int half = n &gt;&gt;&gt; 1; // loop while a non-leaf //k小于half说明可能还需要进行下沉操作 while (k &lt; half) { //获取左子节点下标 int child = (k &lt;&lt; 1) + 1; // assume left child is least //记录右子节点 Object c = array[child]; //获取右子节点下标 int right = child + 1; //如果左边的子节点大于右边的子节点，那么就要用右边的右子节点来交换当前节点 //（目的就是为了取一个最小值来交换） if (right &lt; n &amp;&amp; ((Comparable&lt;? super T&gt;) c).compareTo((T) array[right]) &gt; 0) c = array[child = right]; //如果当前节点的值已经小于最小的子节点，那么就不用再进行交换了 if (key.compareTo((T) c) &lt;= 0) break; //讲记录的最小的子节点来跟当前节点交换 array[k] = c; //将k指向较小的子节点，以便于下次while循环 //因为k跟子元素交换之后，子元素可能还有子元素，所以通过k来指向child //以便下次继续进行子节点的交换动作 k = child; } //交换最终的节点 array[k] = key; }}//逻辑跟上面的一样private static &lt;T&gt; void siftDownUsingComparator(int k, T x, Object[] array, int n, Comparator&lt;? super T&gt; cmp) { if (n &gt; 0) { int half = n &gt;&gt;&gt; 1; while (k &lt; half) { int child = (k &lt;&lt; 1) + 1; Object c = array[child]; int right = child + 1; if (right &lt; n &amp;&amp; cmp.compare((T) c, (T) array[right]) &gt; 0) c = array[child = right]; if (cmp.compare(x, (T) c) &lt;= 0) break; array[k] = c; k = child; } array[k] = x; }} 生产方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546//添加并返回元素到队列头，由offer方法实现，成功后返回truepublic boolean add(E e) { return offer(e);}//添加元素到队列头public boolean offer(E e) { //队列中不允许存储空值 if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); int n, cap; Object[] array; //如果当前元素的个数已经&gt;=当前容量，那么就需要扩容 while ((n = size) &gt;= (cap = (array = queue).length)) //扩容方法 tryGrow(array, cap); try { Comparator&lt;? super E&gt; cmp = comparator; //如果对比器不存在，那么使用自然排序 if (cmp == null) //通过上浮，调整堆结构 siftUpComparable(n, e, array); else siftUpUsingComparator(n, e, array, cmp); //元素数+1 size = n + 1; //唤醒一个消费的线程 notEmpty.signal(); } finally { lock.unlock(); } return true;}//添加元素到队列头，由offer方法实现，成功后返回true//生产方法永远不会被阻塞public void put(E e) { offer(e); // never need to block}//添加元素到队列头，由offer方法实现，成功后返回true//生产方法永远不会被阻塞，timeout和unit参数在本队列不生效，因为生产是不会阻塞的public boolean offer(E e, long timeout, TimeUnit unit) { return offer(e); // never need to block} tryGrow方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void tryGrow(Object[] array, int oldCap) { //释放锁，保证扩容操作不会阻塞消费 lock.unlock(); // must release and then re-acquire main lock Object[] newArray = null; //释放锁后，扩容会出现竞争 //allocationSpinLock == 0表示当前没有正在扩容的线程 //通过cas修改allocationSpinLockOffset为1，表示开始扩容 if (allocationSpinLock == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) { try { //如果旧的容量&lt;64,那么扩容为原来的2倍+2(容量越小，则增长的越快)，如果原来的容量 //大于或者等于64，那么扩容为原来的1.5倍 int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : // grow faster if small (oldCap &gt;&gt; 1)); //如果扩容后的容量&gt;最大容量 if (newCap - MAX_ARRAY_SIZE &gt; 0) { // possible overflow int minCap = oldCap + 1; //minCap &lt; 0，说明minCap整数已经溢出了 //minCap &gt; MAX_ARRAY_SIZE说明已经超出最大限制了 if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE) //抛出异常 throw new OutOfMemoryError(); //设置新容量为最大容量MAX_ARRAY_SIZE newCap = MAX_ARRAY_SIZE; } //newCap &gt; oldCap说明扩容的容量还未超过最大容量， //queue == array说明是第一次扩容 //只有满足这个两个条件，才有必要扩容创建新的数组 if (newCap &gt; oldCap &amp;&amp; queue == array) newArray = new Object[newCap]; } finally { //重置 allocationSpinLock = 0，表示扩容结束 allocationSpinLock = 0; } } //newArray == null表示扩容操作被其他线程抢先执行了 if (newArray == null) // back off if another thread is allocating //让出cpu资源 Thread.yield(); //获取锁 lock.lock(); if (newArray != null &amp;&amp; queue == array) { //如果newArray != null &amp;&amp; queue == array，说明queue没有发生变化那么讲新的数组指向queue queue = newArray; //讲原来的array中的值，复制到新的数组中 System.arraycopy(array, 0, newArray, 0, oldCap); }} 消费方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107//移除队头元素并返回，如果队列为空返回nullpublic E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { //出队 return dequeue(); } finally { lock.unlock(); }}//移除队头元素并返回，如果队列为空阻塞，响应中断public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try { //出队，如果元素为空那么阻塞等待 while ( (result = dequeue()) == null) notEmpty.await(); } finally { lock.unlock(); } return result;}//移除队头元素并返回，如果队列为空超时阻塞，响应中断public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try { while ( (result = dequeue()) == null &amp;&amp; nanos &gt; 0) nanos = notEmpty.awaitNanos(nanos); } finally { lock.unlock(); } return result;}//获取队头元素，如果队列为空返回nullpublic E peek() { final ReentrantLock lock = this.lock; lock.lock(); try { return (size == 0) ? null : (E) queue[0]; } finally { lock.unlock(); }}//元素出队并返回private E dequeue() { int n = size - 1; if (n &lt; 0) return null; else { Object[] array = queue; //记录头节点 E result = (E) array[0]; //记录尾节点 E x = (E) array[n]; //将尾节点位置置为null array[n] = null; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) //将原本尾节点x从堆顶进行下沉，调整堆结构，此时原本的头节点result会被替换掉 siftDownComparable(0, x, array, n); else siftDownUsingComparator(0, x, array, n, cmp); size = n; //返回被移除的头节点，也就是堆顶 return result; }}//一次从队列中获取所有元素到指定集合中public int drainTo(Collection&lt;? super E&gt; c) { return drainTo(c, Integer.MAX_VALUE);}//一次性获取指定元素个数到指定集合中，该方法不会阻塞public int drainTo(Collection&lt;? super E&gt; c, int maxElements) { if (c == null) throw new NullPointerException(); if (c == this) throw new IllegalArgumentException(); if (maxElements &lt;= 0) return 0; final ReentrantLock lock = this.lock; lock.lock(); try { //取小值，也就是如果传入的个数超过了队列中已存在的个数，那么以已有的数据为准 int n = Math.min(size, maxElements); for (int i = 0; i &lt; n; i++) { //将队头的元素添加到集合中 c.add((E) queue[0]); // In this order, in case add() throws. //将队头元素从集合中移除，那么下一次上一步的操作也就是添加新的队头 dequeue(); } return n; } finally { lock.unlock(); }}","link":"/2020/03/15/PriorityBlockingQueue/"},{"title":"redis总结","text":"结构String常用命令: set,get,decr,incr,mget 等。 特点：redis种最常用的一种数据结构 应用场景： 通过String的bitmap可以实现：布隆过滤器、AO权限、用户签到、活跃用户、用户在线状态。 通过自增、自减实现计数器、分布式锁 Hash常用命令：hget,hset,hgetall等 特点：存放的是结构化的对象，可以对对象中属性单独修改 应用场景：比较适合存储一些详情信息、例如购物车、对象 List常用命令：lpush,rpush,lpop,rpop,lrange等 特点：链表，按照插入顺序排序 应用场景：消息队列、最新列表、排行榜(定时计算)、利用lrange命令做分页 Set常用命令： sadd,spop,smembers,sunion 等 特点：不可重复、无序 应用场景：通过交集实现共同好友功能、通过差集实现推荐好友功能、去重 zset(sorted set)特点：可以通过权重参数score来对set中的元素进行排序 应用场景：排行榜(实时计算)、评论+动态分页 过期策略定时删除通过定时器监听所有key的过期，可以立即清除过期的key但是比较占用CPU资源，如果有大量的key需要清除，那么可能会影响数据的读写效率 惰性删除当访问指定key时，才会检测key是否需要清除，如果大量过期的key没有被访问到，那么会占用大量内存 定期过期每隔一定的时间，执行一次删除过期key操作。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。) redis默认使用定期删除+惰性删除策略：redis默认每100ms随机对redis中key进行检查，如果key过期那么删除，未删除的key在下一次使用时，会通过惰性删除策略检查并删除。如果用户一直不访问未被删除的key，那么最后过期的key会越来越多，那么此时就该采用内存淘汰策略了。 内存淘汰策略noeviction当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。 allkeys-random当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 ​ redis默认提供以上六种策略，用户可以通过redis.conf中的maxmemory-policy来配置，例如：maxmemory-policy allkeys-lru。如果没有设置 expire 的key, 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为和 noeviction基本上一致。 缓存穿透、缓存击穿、缓存雪崩缓存穿透特点：去请求缓存中不存在的数据，导致所有的请求都打到数据库，从而造成数据库连接异常。 解决方案： 布隆过滤器：内部维护数据库中所有数据的key，通过判断请求key是否有效，来决定是否需要去数据库中查询。 异步更新：无论key是否存在都返回，随后另开一个线程异步去数据库中查询。 缓存击穿特点：缓存穿透的一种情况，当前一条数据失效。(单个key请求量较大) 解决方案：如果当前数据不是热点数据且访问量小那么不需要解决，如果为热点数据或访问量大，那么可以通过分布式锁来解决。 缓存雪崩特点：缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都打到数据库上，从而导致数据库连接异常。 解决方案：给缓存的失效时间，加上一个随机值，避免集体失效。 持久化RDBRDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。redis默认开启。 优点：恢复速度快、使用单独的子线程进行持久化，主进程不会进行任何IO操作 缺点：持久化之间发生故障后丢失的数据较多 参数配置： 123456789101112131415#dbfilename：持久化数据存储在本地的文件dbfilename dump.rdb#dir：持久化数据存储在本地的路径，如dir ./##snapshot触发的时机，save #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。save 900 1 #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。save 300 10#在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。save 60 10000##当snapshot时出现错误无法继续时，是否阻塞客户端&quot;变更操作&quot;，&quot;错误&quot;可能因为磁盘已满/磁盘故障/OS级别异常等 stop-writes-on-bgsave-error yes ##是否启用rdb文件压缩，默认为&quot;yes&quot;，压缩往往意味着&quot;额外的cpu消耗&quot;，同时也意味这较小的文件尺寸以及较短的网络传输时间 rdbcompression yes AOFAOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 优点：持久化之间发生故障后丢失数据少 缺点：恢复速度较慢 123456789101112131415161718192021222324##此选项为aof功能的开关，默认为&quot;no&quot;，可以通过&quot;yes&quot;来开启aof功能 ##只有在&quot;yes&quot;下，aof重写/文件同步等特性才会生效 appendonly yes ##指定aof文件名称 appendfilename appendonly.aof ##指定aof操作中文件同步策略，有三个合法值：always everysec no,默认为everysec appendfsync everysec ##在aof-rewrite期间，appendfsync是否暂缓文件同步，&quot;no&quot;表示&quot;不暂缓&quot;，&quot;yes&quot;表示&quot;暂缓&quot;，默认为&quot;no&quot; no-appendfsync-on-rewrite no ##aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认&quot;64mb&quot;，建议&quot;512mb&quot; auto-aof-rewrite-min-size 64mb ##相对于&quot;上一次&quot;rewrite，本次rewrite触发时aof文件应该增长的百分比。 ##每一次rewrite之后，redis都会记录下此时&quot;新aof&quot;文件的大小(例如A)，那么当aof文件增长到A*(1 + p)之后 ##触发下一次rewrite，每一次aof记录的添加，都会检测当前aof文件的尺寸。 auto-aof-rewrite-percentage 100 AOF 是文件操作，对于变更操作比较密集的 server，那么必将造成磁盘 IO 的负荷加重；此外 linux 对文件操作采取了“延迟写入”手段，即并非每次 write 操作都会触发实际磁盘操作，而是进入了 buffer 中，当 buffer 数据达到阀值时触发实际写入(也有其他时机)，这是 linux 对文件系统的优化，但是这却有可能带来隐患，如果 buffer 没有刷新到磁盘，此时物理机器失效(比如断电)，那么有可能导致最后一条或者多条 aof 记录的丢失。通过上述配置文件，可以得知 redis 提供了 3 中 aof 记录同步选项：always：每一条 aof 记录都立即同步到文件，这是最安全的方式，也以为更多的磁盘操作和阻塞延迟，是 IO 开支较大。everysec：每秒同步一次，性能和安全都比较中庸的方式，也是 redis 推荐的方式。如果遇到物理服务器故障，有可能导致最近一秒内 aof 记录丢失(可能为部分丢失)。no：redis 并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据 buffer 填充情况 / 通道空闲时间等择机触发同步；这是一种普通的文件操作方式。性能较好，在物理服务器故障时，数据丢失量会因 OS 配置有关。 混合持久化Redis 4.0 开始支持 rdb 和 aof 的混合持久化(默认关闭)。如果把混合持久化打开，aof rewrite 的时候就直接把 rdb 的内容写到 aof 文件开头。也就是说日志只用来做增量恢复， 而快照用来使用恢复。打开混合持久化的配置： 12appendonly yesaof-use-rdb-preamble yes 集群主从复制(Replication)当你的业务需要对redis进行大量读请求，而你的redis服务器性能又不够时，就可以通过主从复制的方式对redis进行一个集群配置。 特点： 读写分离：master提供读写服务，slave(可以为多个)提供读服务 master挂了后，无法自动重新选举master,那么此时无法提供写服务 Redis的主从复制可以根据是否全量分为全量同步和增量同步。 主从复制的过程： ​ redis的主从复制策略是通过其持久化的RDB文件来实现的，当配置好Slave后，Slave与Master建立连接，然后发送sync命令。无论是第一次连接还是重新连接，Master都会启动一个后台进 程，将数据库RDB快照保存到文件中，同时Master主进程会开始收集新的写命令并缓存。后台进程完成写文件后，Master就发送文件给 Slave，Slave将文件保存到硬盘上，再加载到内存中，接着Master就会把缓存的命令转发给Slave，后续Master将收到的写命令发送给 Slave。如果Master同时收到多个Slave发来的同步连接命令，Master只会启动一个进程来写数据库镜像，然后发送给所有的Slave。 redis.conf参数配置： 12Master节点中配置读写分离 slave-read-only yesSlave节点中配置 slaveof master_ip master_port 6379 #指定master的ip和端口 哨兵模式(Sentinel) Redis从2.8开始正式提供了Redis Sentinel 架构，Sentinel用于监控redis集群中Master主服务器工作的状态，当前Master发生故障后，可以实现Master和Slave服务器的切换。 工作方式： 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个PING命令。 如果一个实例（instance）距离最后一次有效回复PING命令的时间超过 own-after-milliseconds 选项所指定的值，则这个实例会被Sentinel标记为主观下线。 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 当有足够数量的Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态，则Master会被标记为客观下线。 在一般情况下，每个Sentinel 会以每10秒一次的频率向它已知的所有Master，Slave发送 INFO 命令。 当Master被Sentinel标记为客观下线时，Sentinel 向下线的 Master 的所有Slave发送 INFO命令的频率会从10秒一次改为每秒一次。 若没有足够数量的Sentinel同意Master已经下线，Master的客观下线状态就会被移除。 若 Master重新向Sentinel 的PING命令返回有效回复，Master的主观下线状态就会被移除。 哨兵的主要功能 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。 sentinel.conf 参数配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154# Example sentinel.conf# *** IMPORTANT ***# 绑定IP地址# bind 127.0.0.1 192.168.1.1# 保护模式（是否禁止外部链接，除绑定的ip地址外）# protected-mode no# port &lt;sentinel-port&gt;# 此Sentinel实例运行的端口port 26379# 默认情况下，Redis Sentinel不作为守护程序运行。 如果需要，可以设置为 yes。daemonize no# 启用守护进程运行后，Redis将在/var/run/redis-sentinel.pid中写入一个pid文件pidfile /var/run/redis-sentinel.pid# 指定日志文件名。 如果值为空，将强制Sentinel日志标准输出。守护进程下，如果使用标准输出进行日志记录，则日志将发送到/dev/nulllogfile &quot;&quot;# sentinel announce-ip &lt;ip&gt;# sentinel announce-port &lt;port&gt;## 上述两个配置指令在环境中非常有用，因为NAT可以通过非本地地址从外部访问Sentinel。## 当提供announce-ip时，Sentinel将在通信中声明指定的IP地址，而不是像通常那样自动检测本地地址。## 类似地，当提供announce-port 有效且非零时，Sentinel将宣布指定的TCP端口。## 这两个选项不需要一起使用，如果只提供announce-ip，Sentinel将宣告指定的IP和“port”选项指定的服务器端口。# 如果仅提供announce-port，Sentinel将通告自动检测到的本地IP和指定端口。## Example:## sentinel announce-ip 1.2.3.4# dir &lt;working-directory&gt;# 每个长时间运行的进程都应该有一个明确定义的工作目录。对于Redis Sentinel来说，/tmp就是自己的工作目录。dir /tmp# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;## 告诉Sentinel监听指定主节点，并且只有在至少&lt;quorum&gt;哨兵达成一致的情况下才会判断它 O_DOWN 状态。### 副本是自动发现的，因此您无需指定副本。# Sentinel本身将重写此配置文件，使用其他配置选项添加副本。另请注意，当副本升级为主副本时，将重写配置文件。## 注意：主节点（master）名称不能包含特殊字符或空格。# 有效字符可以是 A-z 0-9 和这三个字符 &quot;.-_&quot;.sentinel monitor mymaster 127.0.0.1 6379 2# 如果redis配置了密码，那这里必须配置认证，否则不能自动切换# Example:## sentinel auth-pass mymaster MySUPER--secret-0123passw0rd# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;## 主节点或副本在指定时间内没有回复PING，便认为该节点为主观下线 S_DOWN 状态。## 默认是30秒sentinel down-after-milliseconds mymaster 30000# sentinel parallel-syncs &lt;master-name&gt; &lt;numreplicas&gt;## 在故障转移期间，多少个副本节点进行数据同步sentinel parallel-syncs mymaster 1# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;## 指定故障转移超时（以毫秒为单位）。 它以多种方式使用：## - 在先前的故障转移之后重新启动故障转移所需的时间已由给定的Sentinel针对同一主服务器尝试，是故障转移超时的两倍。## - 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。## - 取消已在进行但未生成任何配置更改的故障转移所需的时间## - 当进行failover时，配置所有slaves指向新的master所需的最大时间。# 即使过了这个超时，slaves依然会被正确配置为指向master。## 默认3分钟sentinel failover-timeout mymaster 180000# 脚本执行## sentinel notification-script和sentinel reconfig-script用于配置调用的脚本，以通知系统管理员或在故障转移后重新配置客户端。# 脚本使用以下规则执行以进行错误处理：## 如果脚本以“1”退出，则稍后重试执行（最多重试次数为当前设置的10次）。## 如果脚本以“2”（或更高的值）退出，则不会重试执行。## 如果脚本因为收到信号而终止，则行为与退出代码1相同。## 脚本的最长运行时间为60秒。 达到此限制后，脚本将以SIGKILL终止，并重试执行。# 通知脚本## sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;## 为警告级别生成的任何Sentinel事件调用指定的通知脚本（例如-sdown，-odown等）。# 此脚本应通过电子邮件，SMS或任何其他消息传递系统通知系统管理员 监控的Redis系统出了问题。## 使用两个参数调用脚本：第一个是事件类型，第二个是事件描述。## 该脚本必须存在且可执行，以便在提供此选项时启动sentinel。## 举例:## sentinel notification-script mymaster /var/redis/notify.sh# 客户重新配置脚本## sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;## 当主服务器因故障转移而变更时，可以调用脚本执行特定于应用程序的任务，以通知客户端，配置已更改且主服务器地址已经变更。## 以下参数将传递给脚本：## &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;## &lt;state&gt; 目前始终是故障转移 &quot;failover&quot;# &lt;role&gt; 是 &quot;leader&quot; 或 &quot;observer&quot;## 参数 from-ip, from-port, to-ip, to-port 用于传递主服务器的旧地址和所选副本的新地址。## 举例:## sentinel client-reconfig-script mymaster /var/redis/reconfig.sh# 安全# 避免脚本重置，默认值yes# 默认情况下，SENTINEL SET将无法在运行时更改notification-script和client-reconfig-script。# 这避免了一个简单的安全问题，客户端可以将脚本设置为任何内容并触发故障转移以便执行程序。sentinel deny-scripts-reconfig yes# REDIS命令重命名### 在这种情况下，可以告诉Sentinel使用不同的命令名称而不是正常的命令名称。# 例如，如果主“mymaster”和相关副本的“CONFIG”全部重命名为“GUESSME”，我可以使用：## SENTINEL rename-command mymaster CONFIG GUESSME## 设置此类配置后，每次Sentinel使用CONFIG时，它将使用GUESSME。 请注意，实际上不需要尊重命令案例，因此在上面的示例中写“config guessme”是相同的。## SENTINEL SET也可用于在运行时执行此配置。## 为了将命令设置回其原始名称（撤消重命名），可以将命令重命名为它自身：## SENTINEL rename-command mymaster CONFIG CONFIG Redis Sharding(客户端分片)redis 3.0以下使用客户端sharding分片技术，它是一主多备的实现方式。采用一致性Hash算法来实现数据的分片。通过将数据分散到多个Redis实例中，进而减轻单台redis实例的压力。 优点：服务端独立，降低了服务器集群的复杂性、减轻单台redis实例的压力、横向扩展可存储更多数据 缺点：需要实时获取集群节点的联系信息，动态添加节点需要客户端支持动态sharding，并且需要重启服务器 Redis-Cluster(服务端分片)redis 3.0推出的Redis-Cluster是基于Redis Sharding的一种集群方式。一个Redis Cluster由多个Redis节点组成。不同的节点组服务的数据无交集，每个节点对应数据sharding的一个分片。节点组内部分为主备2类，对应前面叙述的master和slave。两者数据准实时一致，通过异步化的主备复制机制保证。一个节点组有且仅有一个master，同时有0到多个slave。只有master对外提供写服务，读服务可由master/slave提供。 原理：redis cluster 默认分配了 16384(2^14) 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。必须要3个以上的主节点，否则在创建集群时会失败。 为什么RedisCluster有16384个槽？CRC16算法产生的hash值有16bit，该算法可以产生2^16-=65536个值。换句话说，值是分布在0~65535之间。那作者在做mod运算的时候，为什么不mod65536，而选择mod16384？ 因为节点在通讯的时候会携带消息头。如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。 一般情况下节点不会超过1000个，因此16384个槽位足够我们使用。 如果节点太少，而槽位有很多的情况下，压缩效率较低。 Redis Cluster原理 node1和node2首先进行握手meet，知道彼此的存在 握手成功后，两个节点会定期发送ping/pong消息，交换数据信息(消息头，消息体) 消息头里面有个字段：unsigned char myslots[CLUSTER_SLOTS/8]，每一位代表一个槽，如果该位是1，代表该槽属于这个节点 消息体中会携带一定数量的其他节点的信息，大约占集群节点总数量的十分之一，至少是3个节点的信息。节点数量越多，消息体内容越大。 每秒都在发送ping消息。每秒随机选取5个节点，找出最久没有通信的节点发送ping消息。 每100毫秒都会扫描本地节点列表，如果发现节点最近一次接受pong消息的时间大于cluster-node-timeout/2,则立即发送ping消息 一致性hash算法一致性hash算法是基于hash算法实现的，Redis Sharding使用了此算法。 原理：首先求出服务器的哈希值，并将其映射到0~2^32个槽的圆环上。不同的服务器经过hash计算后，分配到圆环上不同的槽。当用户存储数据时，也会通过计算数据键的哈希值的方式将数据映射到圆环上，接着从数据映射的位置开始顺时针查找，将数据保存到找到的第一个服务器上，如果找了一圈还没找到，那么最就会保存到第一台服务器上。 一致性hash算法的好处很明显，当需要新增节点时只会影响顺时针的下一个节点，但是这种方式也会带来一种问题，那么就是数据倾斜，如图： 从上面图就可以看出，当服务器分布不均时，可能会导致大量的数据存储到同一个数据库中，产生一个数据倾斜的问题，因此为了解决这种问题，一致性hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个hash，将每个计算结果都放置一个此服务器节点，称为虚拟节点。实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 常见优化 Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 尽量避免在压力很大的主库上增加从库 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 常见问题 为什么redis采用单线程？ 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。并且单线程更容易实现，不用考虑线程切换消耗性能的问题，也就不需要考虑线程安全问题。 redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。 Redis如何做内存优化？ 尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。 参考资料 https://www.jianshu.com/p/65765dd10671 https://blog.csdn.net/u010647035/article/details/90553596 https://www.cnblogs.com/williamjie/p/9477852.html https://blog.csdn.net/fouy_yun/article/details/81590252 https://www.cnblogs.com/Eugene-Jin/p/10819601.html https://blog.csdn.net/qq_41453285/article/details/106383157 ​","link":"/2020/05/04/RedisSummary/"},{"title":"ReentrantLock源码解析(jdk1.8)","text":"概述ReentrantLock是一个基于AQS(AQS源码解析)实现的可重入的独占锁，提供了公平锁与非公平锁的获取。与synchronized关键词实现的独占锁不同，ReentrantLock锁的粒度更细、功能更加丰富、使用也更灵活。不过ReentrantLock需要手动控制锁的释放。 结构特点 ReentrantLock实现了Lock接口，提供了获取锁，释放锁，创建Condition等功能。 ReentrantLock实现了 Serializable 接口， 表示 ReentrantLock支持序列化的功能 ，可用于网络传输。 重要属性ReentrantLock中Sync通过继承AQS实现同步器的同时，实现了AQS中获取锁、释放锁的模板方法。 而NonfairSync与FairSync通过继承自Sync，分别实现了非公平锁与公平锁的获取。 1234public class ReentrantLock implements Lock, java.io.Serializable { //继承自AQS做为内部的同步器 private final Sync sync;} Sync内部类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//Sync继承自AQS做为内部的同步器,实现了AQS中获取锁、释放锁的模板方法abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; //模板方法、留给子类实现，本类中分别由内部类NonfairSync、FairSync实现，通过lock接口分别获取 //非公平锁与公平锁 abstract void lock(); //获取非公平锁 final boolean nonfairTryAcquire(int acquires) { //记录当前线程 final Thread current = Thread.currentThread(); //获取锁状态 int c = getState(); if (c == 0) { //如果当前锁未被其他线程占有，通过cas设置state,占有锁 if (compareAndSetState(0, acquires)) { //占有锁成功后，设置当前锁的拥有者未当前线程 setExclusiveOwnerThread(current); return true; } } //判断当前锁是为当前线程持有，如果是那么可重入 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); //更新state setState(nextc); return true; } //如果锁已经被其他线程占有，返回false return false; } //释放锁 protected final boolean tryRelease(int releases) { int c = getState() - releases; //如果当前持有锁的线程不是当前线程，那么抛出IllegalMonitorStateException if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); //是否完全释放 boolean free = false; //c == 0，表示完成释放 if (c == 0) { free = true; //将当前持有锁线程置为null setExclusiveOwnerThread(null); } //更改state值 setState(c); //返回free标记 return free; } //当前锁的持有者是否为当前线程 protected final boolean isHeldExclusively() { return getExclusiveOwnerThread() == Thread.currentThread(); } //创建一个等待队列Condition(创建的方法在Aqs中) final ConditionObject newCondition() { return new ConditionObject(); } //获取当前持有锁的线程 final Thread getOwner() { return getState() == 0 ? null : getExclusiveOwnerThread(); } //获取持有锁的数量，如果当前线程持有锁，返回state，否则为0 final int getHoldCount() { return isHeldExclusively() ? getState() : 0; } //判断是否已经被锁定 final boolean isLocked() { return getState() != 0; } private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); setState(0); // reset to unlocked state }} NonfairSync内部类1234567891011121314151617181920//NonfairSync继承自Sync，实现了lock中非公平锁的功能static final class NonfairSync extends Sync { //获取非公平锁 final void lock() { //快速获取锁，通过cas修改state，标记获取锁 if (compareAndSetState(0, 1)) //获取锁成功后，将持有锁的线程置为当前线程 setExclusiveOwnerThread(Thread.currentThread()); else //调用acquire获取锁后，进入到aqs的acquire方法中，执行tryAcquire操作获取锁 //如果失败，将创建一个记录当前线程的节点，加入到同步队列中 acquire(1); } //获取锁 protected final boolean tryAcquire(int acquires) { //返回一个非公平锁 return nonfairTryAcquire(acquires); }} FairSync内部类12345678910111213141516171819202122232425262728293031323334353637//FairSync继承自Sync，实现了lock中公平锁的功能static final class FairSync extends Sync { //获取公平锁 final void lock() { //与NonfairSync中lock方法不同，该lock不会立即通过cas修改state的方式快速获取锁 //而是先通过acquire方法，尝试获取锁 acquire(1); } //尝试获取锁 protected final boolean tryAcquire(int acquires) { //记录当前线程 final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { //1.如果当前锁未被其他线程持有，hasQueuedPredecessors()判断当前同步队列中是否有等待的节点。 //2.如果当前同步队列中没有等待的节点，那么通过cas修改state获取锁 //3.如果当前同步节点中存在等待的节点，那么该方法会返回false，会被加入到同步队列末尾 //4.第三步不清楚的地方，可以看看aqs源码解析中的acquire方法 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { //获取锁成功后，设置当前占有的线程 setExclusiveOwnerThread(current); return true; } } //判断当前锁是为当前线程持有，如果是那么可重入，下面的操作，跟上面非公平锁中一致 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false; }} 常用方法构造方法12345678910//创建ReentrantLock锁，默认是非公平锁public ReentrantLock() { sync = new NonfairSync();}//通过fair标记来创建一个公平锁，或者非公平锁public ReentrantLock(boolean fair) { //fair为true时，创建公平锁，false创建非公平锁 sync = fair ? new FairSync() : new NonfairSync();} 基本方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//获取锁public void lock() { sync.lock();}//获取锁，响应中断public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1);}//尝试获取非公平锁public boolean tryLock() { return sync.nonfairTryAcquire(1);}//获取超时锁，响应中断public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout));}//释放锁public void unlock() { sync.release(1);}//创建一个等待队列public Condition newCondition() { return sync.newCondition();}//获取持有锁的数量（重入次数）public int getHoldCount() { return sync.getHoldCount();}//判断锁是否被当前线程持有public boolean isHeldByCurrentThread() { return sync.isHeldExclusively();}//当前是否已经被锁定public boolean isLocked() { return sync.isLocked();}//判断是否为公平锁public final boolean isFair() { return sync instanceof FairSync;}//获取持有锁的线程protected Thread getOwner() { return sync.getOwner();}//同步队列中是否有节点在等待public final boolean hasQueuedThreads() { return sync.hasQueuedThreads();}//判断传入的线程是否在同步队列中public final boolean hasQueuedThread(Thread thread) { return sync.isQueued(thread);}//获取同步队列长度public final int getQueueLength() { return sync.getQueueLength();}//获取同步队列中所有等待的线程protected Collection&lt;Thread&gt; getQueuedThreads() { return sync.getQueuedThreads();}//查询是否与指定condition有关的等待线程。public boolean hasWaiters(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(\"not owner\"); return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);}//获取指定等待condition有关的等待线程长度public int getWaitQueueLength(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(\"not owner\"); return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);}//获取指定等待condition有关的所有等待线程protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(\"not owner\"); return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition); } 总结ReentrantLock中同步委托给AQS，而加锁和解锁是通过改变AbstractQueuedSynchronizer的state属性。ReentrantLock方法比较少，也简单。下面针对非公平锁和公平锁做一个总结。 非公平锁： 1.线程获取锁时，检查该锁是否被占用，返回被获取的次数 2.如果线程未被占用获取，获取锁，利用CAS进行State的设置 ，设置当前获取锁次数为1，设置占用该锁的线程 3.如果线程被占用，检查被占用的线程是否 是当前线程 4.如果是当前线程，获取锁次数并且+1 公平锁： 1.上面第二步，同时会检查 当前节点是否拥有前驱节点，如果有前驱节点，证明有线程比当前线程更早请求自愿，根据公平性，当前线程获取资源失败 ​","link":"/2019/09/24/ReentrantLock/"},{"title":"【Springloc流程解析】--1. Springloc的基本组件和流程","text":"概述​ 本章开始解析SpringLoc的执行流程，我认为要搞懂spring的源码，最好的办法不是立即针对核心功能进行解析，而是我们首先要了解SpringLoc执行的步骤，纵观全局，最后再对单独的步骤逐个击破，最终串起SpringLoc的整个执行逻辑。 ​ 解析代码之前我们先来回顾一下，我们平时了解的SpringLoc步骤。我们知道SpringLoc是一个容器，根据我们定义bean信息的xml文件(此处不讨论注解)，最终来解析成一个个的bean对象存放到容器中，在我们需要使用到某个bean时，springloc会自动帮我们注入，当然我们也可以通过一个ApplicationContext的getBean(“myBean”)来获取一个我们需要的bean对象，那么从xml的读取转为bean，到最后我们成为一个可供我们使用的bean对象，这其中经历了哪些步骤呢？就让我们一起来看看吧！ 重要组件Resourceorg.springframework.core.io.Resource，资源访问定位。由于springloc支持以不同的方式、从不同的位置进行资源的获取，因此通过Resource类将资源抽象，而它的每一个实现类都代表了一种资源的访问策略，如ClassPathResource、FileSystemResource、ServletContextResource它们分别从不同的位置获取资源。 FileSystemResource：以文件系统绝对路径的方式进行访问 ClassPathResource：以类路径的方式进行访问 ServletContextResource：以相对于Web应用根目录的方式进行访问。 ResourceLoaderorg.springframework.core.io.ResourceLoader，有了资源，我们就需要加载资源。ResourceLoader的作用就是用来进行资源的加载。 123456789101112131415161718192021222324252627282930313233343536373839404142public interface ResourceLoader { //默认在classpath路径下，寻找文件加载 String CLASSPATH_URL_PREFIX = \"classpath:\"; //获取资源，返回一个Resource对象 Resource getResource(String var1); //获取当前的类加载器 @Nullable ClassLoader getClassLoader();}//根据不同的定位路径，选择不同的策略public Resource getResource(String location) { Assert.notNull(location, \"Location must not be null\"); Iterator var2 = this.getProtocolResolvers().iterator(); Resource resource; do { if (!var2.hasNext()) { if (location.startsWith(\"/\")) { return this.getResourceByPath(location); } if (location.startsWith(\"classpath:\")) { return new ClassPathResource(location.substring(\"classpath:\".length()), this.getClassLoader()); } try { URL url = new URL(location); return (Resource)(ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); } catch (MalformedURLException var5) { return this.getResourceByPath(location); } } ProtocolResolver protocolResolver = (ProtocolResolver)var2.next(); resource = protocolResolver.resolve(location, this); } while(resource == null); return resource;} ResourceLoader中只定义两个方法，getResource()根据给定的资源文件地址返回一个对应的Resource，getClassLoader()获取类加载器。 BeanDefinitionorg.springframework.beans.factory.config.BeanDefinition，它并不是我们使用的bean，而是用于描述bean的信息，里面存放着的是bean的元数据。相当于BeanDefinition是bean的一个模板，我们通过模板来创建的bean具有BeanDefinition的基础信息，当然我们也可以对将要创建的bean进行其他的扩展，自己定制不同特性的bean对象。 BeanDefinitionReaderorg.springframework.beans.factory.support.BeanDefinitionReader，用于读取配置的资源文件，并将其转化成容器中的BeanDefinition。BeanDefinitionReader是一个接口，类似于上面的Resource抽象资源，实现BeanDefinitionReader的子类，代表着不同的读取策略。而我们本系列的解析主要是针对XmlBeanDefinitionReader来进行讲解的。 BeanFactoryorg.springframework.beans.factory.BeanFactory，顾名思义bean工厂，用来存储BeanDefinition信息，以及创建并存储bean对象。前面说过通过BeanDefinition当做模板来进行bean的创建，当我们需要创建大量的bean对象时，使用工厂的方式来进行创建也就顺理成章了。通过实现BeanFactory我们就可以通过BeanDefinition创建不同的特性的bean对象了。BeanFactory在springloc中极为重要，实现了BeanFactory的接口也是非常之多，我们也不在这里一一列举了。 DefaultListableBeanFactory几乎继承了所有其他BeanFactory父接口，是一个集大成者的BeanFactory，涵盖了BeanFactory中的大部分功能，是功能最全的一个BeanFactory，同时继承自AliasRegistry具有别名注册的功能。 AliasRegistry：提供别名注册的接口。 BeanDefinitionRegistry：提供对BeanDefinition注册的接口。 SimpleAliasRegistry：实现了AliasRegistry，使用map作为alias的缓存。 SingletonBeanRegistry: 提供单例bean注册的接口。 DefaultSingletonBeanRegistry：继承自SimpleAliasRegistry、实现了SingletonBeanRegistry接口，因此它同时具有注册别名和单例bean的功能。 HierarchicalBeanFactory：实现了bean工厂的分层，可以将各个BeanFactory设置为父子关系，同时提供了父容器的访问功能。 ListableBeanFactory：提供了批量获取bean实例的方法。 FactoryBeanRegistrySupport：继承自DefaultSingletonBeanRegistry，增加了对FactoryBean的处理功能。 ConfigurableBeanFactory：提供了配置各种bean的方法。 AbstractBeanFactory：综合了FactoryBeanRegistrySupport与ConfigurableBeanFactory的功能。 AutowireCapableBeanFactory：继承自BeanFactory，提供创建bean、自动注入、初始化以及应用bean的后置处理器。 AbstractAutowireCapableBeanFactory：综合了AbstractBeanFactory与AutowireCapableBeanFactory的功能。 ConfigurableListableBeanFactory：BeanFactory的配置清单，指定忽略类型以及接口。 DefaultListableBeanFactory综合上面的所有功能，主要是对bean注册后的处理。 ApplicationContextorg.springframework.context.ApplicationContext，Spring的应用上下文，ApplicationContext继承自BeanFactory，同时还继承了其他丰富的组件，基本上ApplicationContext将Springloc中的所有组件功能都组合到一起了。 通过实现ApplicationContext提供不同的上下文环境。 ClassPathXmlApplicationContext：从类路径下的一个或多个xml配置文件中加载上下文定义，适用于xml配置的方式，也就是我们本系列需要讲解的重点。 AnnotationConfigApplicationContext：从一个或多个基于java的配置类中加载上下文定义，适用于java注解的方式。 FileSystemXmlApplicationContext：从文件系统下的一个或多个xml配置文件中加载上下文定义，也就是说系统盘符中加载xml配置文件。 XmlWebApplicationContext： 从web应用下的一个或多个xml配置文件加载上下文定义，适用于xml配置方式。后面我们讲解Springmvc的时候会讲到。 AnnotationConfigWebApplicationContext：专门为web应用准备的，适用于注解方式。 1234public static void main(String[] args) throws ExecutionException, InterruptedException { ApplicationContext context = new ClassPathXmlApplicationContext(\"testA.xml\"); TestA testA = (TestA)context.getBean(\"testA\");} 通过创建一个ClassPathXmlApplicationContext通过传入配置bean信息的xml文件名称，最终返回一个ApplicationContext对象。我们通过ApplicationContext对象的getBean()方法，就可以获取到我们想要的对象，而不用我们自己通过new方法去实例化一个对象，那么spring是怎么做的，这其中又经历了哪些方法，就让我们从这段代码开始。 ​ 我们先来看看ClassPathXmlApplicationContext的结构图。 ClassPathXmlApplicationContext到顶层BeanFactory、ResourceLoader继承关系较为复杂，让我们从最顶层的BeanFactory与ResourceLoader来介绍每个类的特点与作用。 流程解析从我们的 new ClassPathXmlApplicationContext(&quot;testA.xml&quot;)方法开始说起 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ClassPathXmlApplicationContext extends AbstractXmlApplicationContext { @Nullable private Resource[] configResources; public ClassPathXmlApplicationContext() { } //将传入的ApplicationContext对象设置为当前的父类 public ClassPathXmlApplicationContext(ApplicationContext parent) { super(parent); } //我们上面调用的构造方法 public ClassPathXmlApplicationContext(String configLocation) throws BeansException { this(new String[]{configLocation}, true, (ApplicationContext)null); } //传入多个XML配置的构造方法 public ClassPathXmlApplicationContext(String... configLocations) throws BeansException { this(configLocations, true, (ApplicationContext)null); } //传入多个XML配置，并指定父类ApplicationContext public ClassPathXmlApplicationContext(String[] configLocations, @Nullable ApplicationContext parent) throws BeansException { this(configLocations, true, parent); } //传入多个XML配置，选择是否需要刷新容器 public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh) throws BeansException { this(configLocations, refresh, (ApplicationContext)null); } //上面的构造方法最终都要调用此方法 public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException { //调用父类构造方法，最终在AbstractApplicationContext构造方法中完成构建 super(parent); //根据提供的路径，解析成配置文件数组 this.setConfigLocations(configLocations); if (refresh) { //刷新容器 this.refresh(); } } //省略一些方法..... //.......} ClassPathXmlApplicationContext中的super(parent)，一直到AbstractApplicationContext中完成构造工作。 123456789101112131415161718public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext { public AbstractApplicationContext() { this.logger = LogFactory.getLog(this.getClass()); //生成id this.id = ObjectUtils.identityToString(this); //生成展示名 this.displayName = ObjectUtils.identityToString(this); //初始化beanFactory的后置处理集合 this.beanFactoryPostProcessors = new ArrayList(); this.active = new AtomicBoolean(); this.closed = new AtomicBoolean(); this.startupShutdownMonitor = new Object(); //初始化监听器 this.applicationListeners = new LinkedHashSet(); //初始化资源解析器 this.resourcePatternResolver = this.getResourcePatternResolver(); }} 再来看看setConfigLocations方法中做了什么。 setConfigLocations方法123456789101112131415161718192021222324252627282930313233343536373839404142434445//AbstractRefreshableConfigApplicationContext #setConfigLocationspublic void setConfigLocations(@Nullable String... locations) { if (locations != null) { Assert.noNullElements(locations, \"Config locations must not be null\"); this.configLocations = new String[locations.length]; for(int i = 0; i &lt; locations.length; ++i) { //通过resolvePath解析路径并返回 this.configLocations[i] = this.resolvePath(locations[i]).trim(); } } else { this.configLocations = null; }}//AbstractRefreshableConfigApplicationContext #setConfigLocationsprotected String resolvePath(String path) { //获取一个ConfigurableEnvironment对象，用来解析占位符 return this.getEnvironment().resolveRequiredPlaceholders(path);}//public ConfigurableEnvironment getEnvironment() { if (this.environment == null) { //如果environment不存在，那么创建一个 this.environment = this.createEnvironment(); } return this.environment;}protected ConfigurableEnvironment createEnvironment() { return new StandardEnvironment();}public class StandardEnvironment extends AbstractEnvironment { public static final String SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME = \"systemEnvironment\"; public static final String SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME = \"systemProperties\"; public StandardEnvironment() { } protected void customizePropertySources(MutablePropertySources propertySources) { propertySources.addLast(new PropertiesPropertySource(\"systemProperties\", this.getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(\"systemEnvironment\", this.getSystemEnvironment())); }} 未完待续。。。","link":"/2020/04/28/Spring-loc-1/"},{"title":"【阻塞队列】--  Semaphore源码解析(jdk1.8)","text":"概述​ 上一篇我们解析了CountDownLatch，Semaphore、CyclicBarrier跟CountDownLatch一样，都是基于AQS实现的同步工具类。Semaphore用来控制线程的并发，初始时会指定一个许可数permits，线程执行前需要获取许可，获取到许可后许可数-1，线程会向下执行，如果没有可用许可，就会被阻塞。直到其他线程执行完成释放许可后，被阻塞线程才会继续尝试获取许可。也就是说Semaphore可以控制线程的并发量，如果一个线程执行完了，归还了许可，那么下一个线程才有机会获取许可，将同时执行的线程控制在设置的permits范围以内。 代码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211public class Semaphore implements java.io.Serializable { private static final long serialVersionUID = -3222578661600680210L; //基于AQS实现的共享锁 private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 1192457210091910933L; ///构造方法，设置设置许可数 Sync(int permits) { setState(permits); } //获取当前剩余许可 final int getPermits() { return getState(); } //获取非公平共享锁 final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); //计算剩余许可 int remaining = available - acquires; //如果remaining &lt; 0，说明许可已经用完了，此时返回remaining == -1，表示获取失败 //创建记录该线程的node节点加入到同步队列中，等待被唤醒 //如果CAS设置成功，返回remaining的值，肯定&gt;-1,代表成功 //如果CAS设置失败，表示许可被其他线程抢到，重试 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } } //尝试释放共享 protected final boolean tryReleaseShared(int releases) { for (;;) { int current = getState(); int next = current + releases; //next &lt; current，说明releases&lt;0 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); //更新许可 if (compareAndSetState(current, next)) return true; } } final void reducePermits(int reductions) { for (;;) { int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error(\"Permit count underflow\"); if (compareAndSetState(current, next)) return; } } //获取并返回立即可用的所有许可个数，并且将可用许可置0。 final int drainPermits() { for (;;) { int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; } } } //非公平锁 static final class NonfairSync extends Sync { private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) { super(permits); } //立马抢锁，许可有可能被新抢锁的线程获取 protected int tryAcquireShared(int acquires) { return nonfairTryAcquireShared(acquires); } } //公平锁 static final class FairSync extends Sync { private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) { super(permits); } //公平锁，会先检查同步队列中是否有其他的节点，如果存在的话，返回-1获取锁失败 protected int tryAcquireShared(int acquires) { for (;;) { //同步队列中是否存在节点 if (hasQueuedPredecessors()) return -1; int available = getState(); //记录新的可用许可数 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } } } //构造函数，指定许可数，默认采用非公平锁 public Semaphore(int permits) { sync = new NonfairSync(permits); } //构造函数，指定许可数，是否使用公平锁 public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } //获取锁，响应中断 public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1); } //获取锁，不响应中断 public void acquireUninterruptibly() { sync.acquireShared(1); } //尝试获取锁 public boolean tryAcquire() { return sync.nonfairTryAcquireShared(1) &gt;= 0; } //尝试获取锁超时 public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); } //释放锁 public void release() { sync.releaseShared(1); } //获取锁，指定许可数 public void acquire(int permits) throws InterruptedException { if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits); } //获取锁，指定许可，响应中断 public void acquireUninterruptibly(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireShared(permits); } //尝试获取锁，指定许可数 public boolean tryAcquire(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); return sync.nonfairTryAcquireShared(permits) &gt;= 0; } //尝试获取锁超时 public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { if (permits &lt; 0) throw new IllegalArgumentException(); return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout)); } //释放锁 public void release(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits); } //获取可以用的许可数 public int availablePermits() { return sync.getPermits(); } //获取并返回立即可用的所有许可个数，并且将可用许可置0。 public int drainPermits() { return sync.drainPermits(); } protected void reducePermits(int reduction) { if (reduction &lt; 0) throw new IllegalArgumentException(); sync.reducePermits(reduction); } //当前是否为公平锁 public boolean isFair() { return sync instanceof FairSync; } //当前同步队列中是否存在等待的线程 public final boolean hasQueuedThreads() { return sync.hasQueuedThreads(); } public final int getQueueLength() { return sync.getQueueLength(); } protected Collection&lt;Thread&gt; getQueuedThreads() { return sync.getQueuedThreads(); } public String toString() { return super.toString() + \"[Permits = \" + sync.getPermits() + \"]\"; }","link":"/2019/12/01/Semaphore/"},{"title":"ReentrantReadWriteLock源码解析(jdk1.8)","text":"概述ReentrantReadWriteLock基于AQS实现的读写锁，写锁和读锁分别使用排他锁、共享锁实现。读写锁允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他锁线程都会被阻塞。读锁或者写锁，都可以重入。并且写锁支持锁降级，也就是获取写锁的线程，可以同时获取读锁。 结构特点 ReentrantReadWriteLock继承自ReadWriteLock，读锁使用共享锁，写锁使用排它锁 ReentrantReadWriteLock实现了 Serializable 接口， 表示 ReentrantReadWriteLock支持序列化的功能 ，可用于网络传输。 重要属性123456//读锁private final ReentrantReadWriteLock.ReadLock readerLock;//写锁private final ReentrantReadWriteLock.WriteLock writerLock;//继承自AQS做为内部的同步器final Sync sync; Sync内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 6317671515068378041L; static final int SHARED_SHIFT = 16; // static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); //最大值为2^16 - 1 static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; //2^16 - 1，通过EXCLUSIVE_MASK可以将state的低16位取出来，详见exclusiveCount()方法 static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; //state的高16位代表着取读锁的获取次数，包括重入次数，获取到读锁一次加 1，释放掉读锁一次减 1 //此使通过右移16位后获取读锁的获取次数 static int sharedCount(int c) { return c &gt;&gt;&gt; SHARED_SHIFT; } //state的低16位代表着写锁的获取次数，因为写锁是独占锁，同时只能被一个线程获得，所以它代表重入次数 static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } //保持计数器，用来记录每个线程持有的读锁数量(读锁重入) static final class HoldCounter { int count = 0; final long tid = getThreadId(Thread.currentThread()); } //ThreadLocalHoldCounter继承自ThreadLocal，记录每个线程的HoldCounter计数器 static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; { public HoldCounter initialValue() { //初始化创建一个HoldCounter计数器 return new HoldCounter(); } } // 本地线程计数器，记录者各个线程读锁的数量 private transient ThreadLocalHoldCounter readHolds; //将最后一次获取读锁的线程的 HoldCounter计数器缓存到这里 private transient HoldCounter cachedHoldCounter; //第一个获取获取读锁的线程 private transient Thread firstReader = null; //第一个获取读锁的线程的锁数量 private transient int firstReaderHoldCount; //Sync默认构造方法 Sync() { //创建当前锁对象现成的HoldCounter计数器 readHolds = new ThreadLocalHoldCounter(); //设置state,初始为0 setState(getState()); } //写锁是否应该被阻塞，留给子类实现 abstract boolean readerShouldBlock(); //读锁是否应该被阻塞，留给子类实现 abstract boolean writerShouldBlock(); //尝试获取独占锁 protected final boolean tryAcquire(int acquires) { Thread current = Thread.currentThread(); int c = getState(); //获取c的低16位，锁的重入次数 int w = exclusiveCount(c); //c != 0，说明当前存在读锁，或写锁 if (c != 0) { //1.如果w==0，说明当前写锁空闲 //2.current != getExclusiveOwnerThread()，说明当前线程不是独占锁的持有者 //由1、2可以知道，如果想获取写锁，要么当前c == 0，也就是没有读锁和写锁 //要么当前存在独占锁且被当前线程持有 if (w == 0 || current != getExclusiveOwnerThread()) return false; //判断重入锁数量是否超过了最大值 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //更新重入锁数量 setState(c + acquires); return true; } //1.到这一步说明当前不存在锁 //2.判断写操作是否应该被阻塞(如果是非公平锁，读锁操作不需要阻塞，公平锁会判断当前 //同步队列是否有等待的节点) //3.如果失败，通过cas获取修改重入数，成功代表获取锁成功 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; //获取锁成功后，设置锁的持有者为当前线程 setExclusiveOwnerThread(current); return true; } //尝试释放锁 protected final boolean tryRelease(int releases) { //判断当前线程是否为持有锁的线程 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; //如果独占模式重入数为0了，说明独占模式被释放 boolean free = exclusiveCount(nextc) == 0; if (free) //将锁的持有者设置为null setExclusiveOwnerThread(null); //更新锁的state setState(nextc); return free; } //尝试释放共享锁 protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); //如果当前线程为第一个获取锁的线程 if (firstReader == current) { //firstReaderHoldCount == 1，说明当前线程持有的锁为只有一个 if (firstReaderHoldCount == 1) //将firstReader置为null firstReader = null; else //否则重入数-1 firstReaderHoldCount--; } else { //获取缓存的最后一个获取读锁的计数器 HoldCounter rh = cachedHoldCounter; //如果最计数器不存在，或者最后一次记录的不是当前线程的计数器 if (rh == null || rh.tid != getThreadId(current)) //获取当前线程的计数器 rh = readHolds.get(); //获取当前线程持有读锁的数量 int count = rh.count; //count &lt;= 1，说明当前线程持有读锁的重入数最多为1 if (count &lt;= 1) { //移除当前线程的读取器 readHolds.remove(); //count &lt;= 0（说明当前线程根本没有获取到读锁就释放锁），抛出异常 if (count &lt;= 0) throw unmatchedUnlockException(); } //读锁数量-1 --rh.count; } //自旋重试 for (;;) { int c = getState(); //读锁数-1，后剩余的锁数量 int nextc = c - SHARED_UNIT; //cas修改读锁数 if (compareAndSetState(c, nextc)) //如果nextc == 0，说明已经释放了所有的读锁 return nextc == 0; } } //没有加锁就释放锁，会引起异常 private IllegalMonitorStateException unmatchedUnlockException() { return new IllegalMonitorStateException( \"attempt to unlock read lock, not locked by current thread\"); } //尝试获取共享锁(写锁) protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); int c = getState(); //1.exclusiveCount(c) != 0，说明当前存在写锁 //2.getExclusiveOwnerThread() != current,持有写锁的对象线程不是当前线程 //由1、2可知，想要获取读锁，要么当前不存在写锁，要么写锁的持有者为当前线程 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) //返回-1表示失败 return -1; //获取共享锁数量 int r = sharedCount(c); //1.readerShouldBlock(),判断读锁是否应该被阻塞 //如果是非公平锁，同步队列存在写锁的时候阻塞 //如果是公平锁，同步节点中存在节点的时候阻塞 //也就是说，非公平锁中只有存在其他读锁的时候，才会阻塞 //而公平锁中不管读写锁，都需要被阻塞 //2.r &lt; MAX_COUNT,并且读锁的数量没有达到最大值 //3.compareAndSetState(c, c + SHARED_UNIT)，相当于高16位+1，修改锁状态 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) { //r == 0说明当前没有其他读锁 if (r == 0) { //设置第一个获取读锁的为当前线程 //firstReader是不会放到readHolds里的, 这样， //在读锁只有一个的情况下，就避免了查找readHolds。 firstReader = current; //读锁数量为1 firstReaderHoldCount = 1; } else if (firstReader == current) { //如果第一个读锁的为当前用户，那么将读锁数量+1 firstReaderHoldCount++; } else { //非firstReader读锁重入计数更新， //读锁重入计数缓存，基于ThreadLocal实现 HoldCounter rh = cachedHoldCounter; //如果最后一次缓存的计数器不存在，或者不是当前线程的计数器 if (rh == null || rh.tid != getThreadId(current)) //记录最后统计读锁的读取器 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) //设置当前的读取器 readHolds.set(rh); //将读锁的重入数+1 rh.count++; } return 1; } //如果第一次，获取读锁失败，通过fullTryAcquireShared再次尝试获取读锁， //锁定降级的逻辑在此方法中 return fullTryAcquireShared(current); } //获取读锁失败后重试 final int fullTryAcquireShared(Thread current) { HoldCounter rh = null; //自旋，重试 for (;;) { //获取锁状态 int c = getState(); //exclusiveCount(c) != 0，说明存在写锁 if (exclusiveCount(c) != 0) { //如果存在写锁且写锁的持有线程不是当前线程，返回-1 //此处的判断比较重要，如果用户获取写锁后，又获取读锁 //如果次数不判断读锁是否为当前锁的话，那么当前会被阻塞 //那么也就不能在释放写锁了，这个时候就会出现死锁 //通过这里我们也知道，获取的写锁的线程，可以继续获取读锁 //也就是我们所说的锁降级 if (getExclusiveOwnerThread() != current) return -1; //判断是否应该被阻塞 } else if (readerShouldBlock()) { //如果应该被阻塞的话，说明存在写锁(公平模式下可能是因为存在读锁) //如果第一个获取读锁的，说明锁重入 if (firstReader == current) { } else { //第一次重试进入，说明有其他新线程获取读锁了 if (rh == null) { //获取缓存的最后一次获取读锁的计数器 rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) { //获取当前线程的计数器 rh = readHolds.get(); //如果rh.count == 0，说明该线程第一次获取读锁 if (rh.count == 0) //移除当前线程的计数器 readHolds.remove(); } } //获取锁失败，跳出重试，后续的操作中会被加入到同步队列中 if (rh.count == 0) return -1; } } //如果获取读锁的数量超过最大值，抛出异常 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //记录锁状态，c + SHARED_UNIT相当于高16位+1(右移后相当于读锁数+1) if (compareAndSetState(c, c + SHARED_UNIT)) { //如果分享锁数为0,那么设置第一个获取读锁的为当前线程 if (sharedCount(c) == 0) { firstReader = current; firstReaderHoldCount = 1; //重入数+1 } else if (firstReader == current) { firstReaderHoldCount++; } else { if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); //读锁数+1 rh.count++; //记录最后访问的线程读取器 cachedHoldCounter = rh; // cache for release } return 1; } } } //获取写锁 final boolean tryWriteLock() { Thread current = Thread.currentThread(); int c = getState(); //当前存在读锁或者写锁 if (c != 0) { //记录当前写锁的冲入次数 int w = exclusiveCount(c); //1.如果w==0，说明当前没有写锁 //2.current != getExclusiveOwnerThread()，说明当前锁的持有写锁线程不是当前线程 //因此只有当前存在读锁，并且读锁的持有者为当前线程才会继续下去，否则返回false if (w == 0 || current != getExclusiveOwnerThread()) return false; //重入数超过最大值，抛出异常 if (w == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); } //通过cas修改state,占有锁 if (!compareAndSetState(c, c + 1)) return false; //设置独占锁的持有线程为当前线程 setExclusiveOwnerThread(current); return true; } //获取读锁 final boolean tryReadLock() { Thread current = Thread.currentThread(); //自旋，重试 for (;;) { int c = getState(); //1.exclusiveCount(c) != 0，表示当前存在写锁 //2.getExclusiveOwnerThread() != current表示写锁的线程不是当前线程 //因此想要获取锁，要么当前写锁空闲，要么锁重入 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return false; //获取读锁数量 int r = sharedCount(c); //如果读锁数量已经到达最大值，抛出异常 if (r == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //修改读锁数量，如果失败，会进入下一次自旋重试 if (compareAndSetState(c, c + SHARED_UNIT)) { //r == 0，说明当前不存在读锁 if (r == 0) { //记录第一个读锁和持有数量 firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { //如果第一个读锁为当前线程，那么将读锁数量+1 firstReaderHoldCount++; } else { //如果第一个获取读锁的线程不是当前线程 // HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return true; } } } //判断当前持有独占锁的线程是否为当前线程 protected final boolean isHeldExclusively() { return getExclusiveOwnerThread() == Thread.currentThread(); } //创建一个等待队列节点 final ConditionObject newCondition() { return new ConditionObject(); } //获取持有写锁的线程 final Thread getOwner() { return ((exclusiveCount(getState()) == 0) ? null : getExclusiveOwnerThread()); } //获取持有读锁的线程数量 final int getReadLockCount() { return sharedCount(getState()); } //是否为写锁 final boolean isWriteLocked() { return exclusiveCount(getState()) != 0; } //获取写锁的重入数 final int getWriteHoldCount() { return isHeldExclusively() ? exclusiveCount(getState()) : 0; } //获取读锁的数量 final int getReadHoldCount() { if (getReadLockCount() == 0) return 0; Thread current = Thread.currentThread(); //如果当前只有一个读线程，直接返回当前线程持有的读锁数 if (firstReader == current) return firstReaderHoldCount; //如果缓存的是当前线程的计数器，那么直接返回count HoldCounter rh = cachedHoldCounter; if (rh != null &amp;&amp; rh.tid == getThreadId(current)) return rh.count; //通过readHolds获取当前线程的计数器，如果数量为0，移除当前线程计数器 int count = readHolds.get().count; if (count == 0) readHolds.remove(); return count; } private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); readHolds = new ThreadLocalHoldCounter(); setState(0); // reset to unlocked state } //获取锁状态 final int getCount() { return getState(); }} NonfairSync内部类123456789101112131415161718192021//非公平锁static final class NonfairSync extends Sync { //是否应该阻塞，非公平锁中默认写锁不需要阻塞 final boolean writerShouldBlock() { return false; } final boolean readerShouldBlock() { //该方法在AQS中，判断当前同步队列是否有独占节点在等待 return apparentlyFirstQueuedIsExclusive(); }}//AQS中的方法，判断同步队列中是否有独占节点在等待final boolean apparentlyFirstQueuedIsExclusive() { Node h, s; return (h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; !s.isShared() &amp;&amp; s.thread != null;} FairSync内部类123456789101112//公平锁static final class FairSync extends Sync { private static final long serialVersionUID = -2274990926593161451L; //公平锁中，需不需要阻塞写操作，看当前同步队列中是否有其他线程等待 final boolean writerShouldBlock() { return hasQueuedPredecessors(); } //公平锁中，需不需要阻塞读操作，看当前同步队列中是否有其他线程等待 final boolean readerShouldBlock() { return hasQueuedPredecessors(); }} ReadLock内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static class ReadLock implements Lock, java.io.Serializable { //sync继承自AQS private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) { sync = lock.sync; } //获取读锁 public void lock() { //通过sync获取共享锁，会调用模板方法tryAcquireShared, //失败后会通过sync中的doAcquireShared方法生成一个记录当前线程的节点， //并加入到同步队列的末尾 sync.acquireShared(1); } //获取读锁，响应中断 public void lockInterruptibly() throws InterruptedException { sync.acquireSharedInterruptibly(1); } //尝试获取读锁，失败立即返回(使用此方法，失败不会创建同步节点，而是立即返回false) public boolean tryLock() { return sync.tryReadLock(); } //尝试获取读锁，指定超时时间(同上) public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); } //释放锁 public void unlock() { sync.releaseShared(1); } //ReadLock中，不允许创建等待队列节点 public Condition newCondition() { throw new UnsupportedOperationException(); } public String toString() { int r = sync.getReadLockCount(); return super.toString() + \"[Read locks = \" + r + \"]\"; }} ReadLock内部类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static class WriteLock implements Lock, java.io.Serializable { private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) { sync = lock.sync; } //获取写锁 public void lock() { sync.acquire(1); } //获取写锁，响应中断 public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } //尝试获取锁 public boolean tryLock( ) { return sync.tryWriteLock(); } //尝试获取超时锁 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); } //释放锁 public void unlock() { sync.release(1); } //创建等待队列 public Condition newCondition() { return sync.newCondition(); } public String toString() { Thread o = sync.getOwner(); return super.toString() + ((o == null) ? \"[Unlocked]\" : \"[Locked by thread \" + o.getName() + \"]\"); } //判断当前线程是否是该锁的持有者 public boolean isHeldByCurrentThread() { return sync.isHeldExclusively(); } //获取写锁的重入数 public int getHoldCount() { return sync.getWriteHoldCount(); }} 总结介绍完ReentrantReadWriteLock中几个内部类，也就没啥方法了。ReentrantReadWriteLock获取写锁部分的代码还比较简单。基本上跟之前解析的重入锁ReentrantLock没多大区别。关键在于读锁的部分，引入了计数器、锁降级部分，逻辑上要复杂那么一点。下面简单做一个总结 获取写锁 WriteLock通过lock()方法调用获取写锁后，会调用sync.acquire(1)获取锁方法。sync继承自AQS，该方法在AQS中用于获取锁，AQS通过调用模板方法tryAcquire()又回到本类中。看过前面ReentrantLock解析的，这里应该比较熟悉了。 tryAcquire()方法，尝试获取锁。通过exclusiveCount(c)方法，获取写锁的数量(获取低16位，也就是写锁的重入数)，如果从c != 0说明写锁存在，判断持有写锁的是否为当前线程，如果是，则表示重入，那么写锁重入数+1，返回true，获取锁成功。如果不是当前线程持有的锁，直接返回false，获取锁失败。 如果写锁不存在，通过writerShouldBlock判断写锁是否需要被阻塞。 非公平锁情况下，写锁不会被阻塞，那么会执行!compareAndSetState(c, c + acquires)方法修改锁状态，修改成功，那么获取锁成功。修改失败，返回false，设置锁失败。 公平情况下，会通过FairSync的方法最终调用hasQueuedPredecessors，判断当前同步队列是否存在节点。如果存在，说明前面有其他获取锁线程在等待，那么获取锁失败。如果同步队列中没有节点，那么跟上面一样，修改锁状态，看是否获取锁成功。 上面使用tryAcquire方法获取锁，如果成功，那么WriteLock的lock()方法直接返回。如果失败，那么AQS的acquire方法中，会调用addWaiter(Node.EXCLUSIVE), arg)方法，生成一个记录当前线程的节点，并加入到同步队列的末尾。最后通过acquireQueued方法，以自旋的方式，获取锁，直到获取锁成功。或者线程被中断。 释放写锁 WriteLock通过lock()方法释放写锁，会调用sync.release(1)方法。跟上面获取锁一样。该方法也在AQS中，release()会调用模板方法tryRelease(arg)释放锁。 tryRelease方法会通过isHeldExclusively判断，当前线程是否为持有锁的线程。如果不是抛出IllegalMonitorStateException。 判断boolean free = exclusiveCount(nextc) == 0，判断是否释放了所有的重入锁。如果是，设置持有写锁的持有者为null。设置新的state，返回free 。 如果第3步返回true,也就是释放所有的重入锁。那么判断同步队列头节点不为null，且状态是否为-1(表示后驱节点需要被唤醒，不了解的可以去看一下前面关于 AQS的解析)，那么通过unparkSuccessor唤醒后驱节点，返回true。 获取读锁 ReadLock通过lock()方法获取读锁，会调用sync.acquireShared(1)。通过tryAcquireShared尝试获取共享锁，exclusiveCount(c) != 0 ，判断当前是否存在独占锁(写锁)，如果存在，并且通过getExclusiveOwnerThread() != current判断，持有写锁的不是当前线程。会直接返回-1，表示尝试获取锁失败。 如果当前不存在写锁，或者写锁的持有者是当前线程。那么通过sharedCount(c)获取读锁的数量(将state的高16位向右移16位，获取读锁的数量)。随后，通过!readerShouldBlock()判断，读锁是否需要阻塞。 非公平锁情况下，会通过NonfairSync最终调用apparentlyFirstQueuedIsExclusive方法，判断当前同步队列中是否存在独占锁(写锁)，如果存在，那么应该被阻塞(我们知道存在写锁的情况下，是不能获取读锁的)，不会进入到if代码块中。 公平锁情况下，会通过FairSync最终调用hasQueuedPredecessors()方法，用来判断当前同步队列中是否存在锁(包括读锁)。 如果读锁没有被阻塞，判断读锁的数量是否小于最大值，随后通过cas修改锁状态(读锁+1)。成功获取读锁后，通过记录的读锁数判断，当前线程是否为第一次获取读锁线程。如果是则记录，如果不是，判断当前线程是否为第一个获取读锁的线程，如果是，那么记录首次获取锁的数量firstReaderHoldCount+1。 如果不是，那么获取缓存的最后一次获取锁的计数器cachedHoldCounter。如果cachedHoldCounter为空，说明当前线程是第二个获取读锁的线程。如果cachedHoldCounter记录的线程id不是当前线程，更新cachedHoldCounter缓存。 如果cachedHoldCounter存在，并且缓存的正是当前线程，如果rh.count == 0，说明这个线程原来获取读锁后被释放了，readHolds中没有cachedHoldCounter的记录了，那么通过readHolds.set(rh)重新记录到readHolds中，随后将读锁计数器+1 如果读锁被阻塞，或者读锁的数量超过最大值，又或者更改state状态失败了(说明被其他线程抢了)，那么通过fullTryAcquireShared(current)重新获取读锁。 fullTryAcquireShared方法上来就是一个死循环，用于重试。 通过exclusiveCount(c) != 0判断，是否存在写锁，如果存在，那么判断写锁是否被当前线程持有，如果不是，那么返回-1，跳出死循环，获取锁失败。 通过判断写锁的持有者是否为当前线程，就是锁降级的体现。说明如果当前线程持有写锁，那么也能获取到读锁。 下面的逻辑基本上跟tryAcquireShared中方法一致，获取锁失败后会返回-1。最后sync.acquireShared在tryAcquireShared返回-1后，会通过doAcquireShared(arg)方法生成一个记录当前线程的共享节点，并加入到同步队列中，等待被唤醒。 设想一下，如果没有第11步的判断直接返回-1，那么该线程获取读锁被阻塞之后，原来的写锁就没法释放，就会产生死锁。 释放读锁 ReadLock通过unlock()方法释放写锁。会调用sync.releaseShared(1)方法，通过tryReleaseShared(arg)方法尝试释放写锁。 tryReleaseShared(arg)首先通过firstReader == current判断，当前线程是否为第一个获取锁的线程，如果是，判断firstReaderHoldCount == 1，如果相等，说明当前锁数量只有一个，那么直接将firstReaderHoldCount 置为null。否则firstReaderHoldCount 数 -1. 如果不是，判断cachedHoldCounter是否存在，如果不存在，或者cachedHoldCounter不是当前线程的计数器，那么获取当前线程的计数器。判断计数器中count&lt;=1，如果是，那么通过readHolds.remove()移除当前线程的计数器。如果count &lt;= 0，说明当前不存在线程不存在写锁，抛出unmatchedUnlockException。最后计数器count–。 上面这些步骤，最终的操作只是将计数器的count-1，表示记录的读锁数-1。而真正释放锁的操作是通过cas修改state的值来实现的。毕竟当前是否存在读锁，还是通过state的值来判断的。 for死循环自旋，保证读锁最终能被释放。int nextc = c - SHARED_UNIT，高16位相当于-1操作，也就是将读锁数-1了。通过cas修改state的值，修改成功，判断是否已经释放完了所有的读锁，如果是返回true，如果不是返回false。cas修改失败，进入下一次自旋，保证最终释放锁成功。 如果tryReleaseShared最终返回了true，也就是释放了所有的写锁，那么sync.releaseShared(1)方法会通过doReleaseShared()，释放后继节点中的共享节点，也就是共享节点传播性的一个体现。","link":"/2019/10/21/ReentrantReadWriteLock/"},{"title":"【阻塞队列】-- SynchronousQueue源码解析(jdk1.8)","text":"概述​ SynchronousQueue是一个没有数据缓冲的阻塞队列，生产者线程对其的插入操作put必须等待消费者的移除操作take，反过来也一样。SynchronousQueue中因为不存储元素，所以peek方法永远返回null。 SynchronousQueue支持公平策略。SynchronousQueue看似是阻塞队列中最简单的一种，却是几个解析中最复杂的一个。 结构 SynchronousQueue实现自BlockingQueue,因此是一个阻塞队列。 SynchronousQueue有一个Transferer内部类，TransferStack与TransferQueue都继承自Transferer，当构建一个非公平队列时，会使用TransferStack以后进先出的顺序访问队列元素，当构建一个公平队列时，则会使用TransferQueue以先进先出的顺序访问队列元素，保证公平。 属性1234567891011121314151617181920212223242526public class SynchronousQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { private static final long serialVersionUID = -3223113410248163686L; //内部类 abstract static class Transferer&lt;E&gt; { abstract E transfer(E e, boolean timed, long nanos); } //获取处理器个数，用于判断后续自旋的条件 static final int NCPUS = Runtime.getRuntime().availableProcessors(); //指定超时时的自旋次数,如果处理器个数&lt;2，那么自旋次数为0否则为32 //处理器只有1个的时候，不需要自旋 static final int maxTimedSpins = (NCPUS &lt; 2) ? 0 : 32; //未指定超时的自旋次数，默认为maxTimedSpins * 16，最大为512 static final int maxUntimedSpins = maxTimedSpins * 16; //超时时间间隔阈值，当超时时间大于此阈值的时候，才有必要阻塞 //不然可能阻塞一秒马上超时，不如在这一秒之内直接让他快速重试，避免阻塞带来的效率问题 //也就是优化了这一步，AQS中也有一样的设计 static final long spinForTimeoutThreshold = 1000L; private transient volatile Transferer&lt;E&gt; transferer;} TransferStack类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287//非公平情况下使用栈，后进先出static final class TransferStack&lt;E&gt; extends Transferer&lt;E&gt; { //消费模式 static final int REQUEST = 0; //填充模式 static final int DATA = 1; //匹配中 static final int FULFILLING = 2; //是否正在匹配 static boolean isFulfilling(int m) { return (m &amp; FULFILLING) != 0; } static final class SNode { //下一个等待的节点 volatile SNode next; // next node in stack //匹配的节点 volatile SNode match; // the node matched to this //等待在当前节点上的线程，匹配上之后会释放该线程 volatile Thread waiter; // to control park/unpark Object item; // data; or null for REQUESTs int mode; SNode(Object item) { this.item = item; } //如果传入的节点是当前节点的下一个节点，那么替换它为指定节点 boolean casNext(SNode cmp, SNode val) { return cmp == next &amp;&amp; UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); } //尝试讲一个节点与当前匹配，成功后会释放当前节点阻塞的线程 boolean tryMatch(SNode s) { if (match == null &amp;&amp; UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) { Thread w = waiter; if (w != null) { // waiters need at most one unpark waiter = null; LockSupport.unpark(w); } return true; } //匹配上了返回true return match == s; } //尝试取消 void tryCancel() { UNSAFE.compareAndSwapObject(this, matchOffset, null, this); } //当前节点是否被取消，当节点的match指向自身的时候，说明被取消了 boolean isCancelled() { return match == this; } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long matchOffset; private static final long nextOffset; //以下静态方法都是根据UNSAFE类获取节点的偏移量，用于CAS更新 static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = SNode.class; matchOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"match\")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"next\")); } catch (Exception e) { throw new Error(e); } } } //当前链表头，每次都是从头匹配 volatile SNode head; //设置头 boolean casHead(SNode h, SNode nh) { return h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh); } //创建一个节点，如果s为null，那么e作为s中的item static SNode snode(SNode s, Object e, SNode next, int mode) { if (s == null) s = new SNode(e); s.mode = mode; s.next = next; return s; } //插入或者移除元素，移除时e默认为null @SuppressWarnings(\"unchecked\") E transfer(E e, boolean timed, long nanos) { SNode s = null; // constructed/reused as needed //判断当前模式，e为null时为REQUEST模式，否则为DATA模式 int mode = (e == null) ? REQUEST : DATA; //自旋重试 for (;;) { //记录头结点 SNode h = head; //如果头结点为null或者本次模式与头结点模式相同 if (h == null || h.mode == mode) { // empty or same-mode //如果配置了超时，判断是否已超时 if (timed &amp;&amp; nanos &lt;= 0) { // can't wait //如果超时，头结点不为null并且没有被取消，那么设置下一个节点为新的头结点 if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else //否则返回null return null; //如果没有设置超时，或者还未到超时时间，那么创建一个对象设置为新的头部 } else if (casHead(h, s = snode(s, e, h, mode))) { //等待被填充，填充完成后返回匹配节点 SNode m = awaitFulfill(s, timed, nanos); //如果匹配节点与等待的节点相同，说明被取消了，需要清理掉节点 if (m == s) { // wait was cancelled clean(s); return null; } //到这里说明匹配成功了，如果当前头部不为null，并且h.next == s //这里是等待匹配的，因此匹配节点应该是头结点， //头结点后面的节点就是我们被匹配的节点 if ((h = head) != null &amp;&amp; h.next == s) //设置新的头结点，也就是s后面的节点 casHead(h, s.next); // help s's fulfiller //如果为消费模式，那么返回匹配的元素 return (E) ((mode == REQUEST) ? m.item : s.item); } //如果头结点还没有进行匹配 } else if (!isFulfilling(h.mode)) { // try to fulfill //如果头结点被取消，那么设置下一个元素为头结点 if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry //设置新的头结点，FULFILLING|mode得到的值要么为2，要么为3 //通过isFulfilling得到的都是正在匹配 else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) { for (;;) { // loop until matched or waiters disappear //记录s的下一个节点m,也就是s要匹配的节点 SNode m = s.next; // m is s's match //如果m=null,说明被其他节点抢先给匹配了, //并且已经没有其他在等待匹配的节点了 if (m == null) { // all waiters are gone //将头结点置为null，下一次自旋会重新生成，接着往下看 casHead(s, null); // pop fulfill node //将s置为null,进行下一次自旋 s = null; // use new node next time break; // restart main loop } //记录m的下一个节点 SNode mn = m.next; //进行匹配，tryMatch方法中匹配成功后会释放m中阻塞的线程 if (m.tryMatch(s)) { //匹配成功后，mn应该置为新的头结点 casHead(s, mn); // pop both s and m //根据模式返回匹配的元素 return (E) ((mode == REQUEST) ? m.item : s.item); } else // lost match //如果匹配失败，说明m被其他节点匹配上了 //将m从栈中移除，s将对下一个节点进行匹配（也就是mn） s.casNext(m, mn); // help unlink } } //如果头结点正在匹配中 } else { // help a fulfiller //记录头结点的下一个节点，也就是跟头结点进行匹配的节点m SNode m = h.next; // m is h's match //如果m为null if (m == null) // waiter is gone //说明后面没有等待节点了，那么将头结点置为null,继续下一次自旋 casHead(h, null); // pop fulfilling node else { //记录m的被匹配的下一个节点 SNode mn = m.next; //帮助m与h进行匹配 if (m.tryMatch(h)) // help match //成功后设置新的头结点为mn casHead(h, mn); // pop both h and m else // lost match //如果匹配失败，说明m被其他节点匹配上了 //将m从栈中移除，h将对下一个节点进行匹配（也就是mn） h.casNext(m, mn); // help unlink } } } } //等待被填充 SNode awaitFulfill(SNode s, boolean timed, long nanos) { //记录超时时间 final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); //判断当前自旋次数，如果设置了超时则用maxTimedSpins，否则使用maxUntimedSpins int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) { //如果当前线程被中断，那么设置该节点为取消 if (w.isInterrupted()) s.tryCancel(); //记录匹配的节点 SNode m = s.match; //&lt;1&gt;.如果不为null，直接返回 if (m != null) return m; //如果配置了超时 if (timed) { nanos = deadline - System.nanoTime(); //检查是否超时，如果超时会取消当前节点，会将节点的match指向自身 //然后下次自旋，上面&lt;1&gt;处就会直接返回 if (nanos &lt;= 0L) { s.tryCancel(); continue; } } //检查自旋次数是否已经用完 if (spins &gt; 0) //判断是否应该自旋 spins = shouldSpin(s) ? (spins-1) : 0; //记录节点上等待的线程 else if (s.waiter == null) s.waiter = w; // establish waiter so can park next iter //如果没有配置超时，那么直接阻塞 else if (!timed) LockSupport.park(this); //如果配置超时了，那么超时阻塞 else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); } } //如果当前节点为头部，或者头部为null，又或者当前正在匹配中，那么还需要自旋 //这种时候说明很快就能匹配上了，不需要阻塞 boolean shouldSpin(SNode s) { SNode h = head; return (h == s || h == null || isFulfilling(h.mode)); } //节点被取消后需要清除 void clean(SNode s) { //将节点的item、waiter置为null s.item = null; // forget item s.waiter = null; // forget thread //记录要移除节点的下一个节点past SNode past = s.next; //&lt;1&gt;如果past存在并且被取消，那么找到past后面正常的节点 if (past != null &amp;&amp; past.isCancelled()) //那么继续向下，直到找到一个正常的节点 past = past.next; //从头节点开始清理 //如果头节点不为null，并且不是当前找到的最后一个正常的节点， //并且头部节点被取消了，那么设置p的下一个节点为头部 //此时新的头节点还是被取消之后，这步还会继续进行，直到头部被置为null， //或者置为一个正常的的节点，上面的&lt;1&gt;处，是从past后面开始找，这里是从head从后面开始找 SNode p; while ((p = head) != null &amp;&amp; p != past &amp;&amp; p.isCancelled()) casHead(p, p.next); //如果P不为null，说明经过了上一步的while改变了p的值，并且p为一个正常的节点 //如果p != past，说明p与past之间还有其他节点，针对这中间节点再做一次清理 //直到清理完整个队列或者past位置为止 while (p != null &amp;&amp; p != past) { SNode n = p.next; if (n != null &amp;&amp; n.isCancelled()) p.casNext(n, n.next); else p = n; } } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long headOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = TransferStack.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"head\")); } catch (Exception e) { throw new Error(e); } }} TransferQueue类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285//公平情况下使用队列，先进先出static final class TransferQueue&lt;E&gt; extends Transferer&lt;E&gt; { static final class QNode { //指向队列中的下一个节点 volatile QNode next; // next node in queue //存储元素 volatile Object item; // CAS'ed to or from null //节点中的等待线程 volatile Thread waiter; // to control park/unpark //是否为插入操作 final boolean isData; //节点构造方法 QNode(Object item, boolean isData) { this.item = item; this.isData = isData; } //通过cas设置下一个节点 boolean casNext(QNode cmp, QNode val) { return next == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); } //通过cas设置节点的item boolean casItem(Object cmp, Object val) { return item == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); } //尝试取消，节点中的item指向自身，说明被取消 void tryCancel(Object cmp) { UNSAFE.compareAndSwapObject(this, itemOffset, cmp, this); } //判断是否已经取消 boolean isCancelled() { return item == this; } // 节点是否从已经从队列中移除 boolean isOffList() { return next == this; } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = QNode.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"item\")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"next\")); } catch (Exception e) { throw new Error(e); } } } //队列头节点 transient volatile QNode head; //队列尾节点 transient volatile QNode tail; //指向一个被取消但是还没有从队列移除的节点 transient volatile QNode cleanMe; TransferQueue() { //默认初始化一个哨兵节点 QNode h = new QNode(null, false); // initialize to dummy node. head = h; tail = h; } //替换头节点 void advanceHead(QNode h, QNode nh) { if (h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh)) h.next = h; // forget old next } //替换尾节点 void advanceTail(QNode t, QNode nt) { if (tail == t) UNSAFE.compareAndSwapObject(this, tailOffset, t, nt); } boolean casCleanMe(QNode cmp, QNode val) { return cleanMe == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, cleanMeOffset, cmp, val); } @SuppressWarnings(\"unchecked\") E transfer(E e, boolean timed, long nanos) { QNode s = null; // constructed/reused as needed //是否是填充数据 boolean isData = (e != null); for (;;) { QNode t = tail; QNode h = head; if (t == null || h == null) // saw uninitialized value continue; // spin //如果队列没有其他元素或者模式相同 if (h == t || t.isData == isData) { // empty or same-mode //记录下一个节点 QNode tn = t.next; //如果t != tail，说明可能有其他节点插入了队列的尾部，重试 if (t != tail) // inconsistent read continue; //如果t != tail，说明可能有其他节点插入了队列的尾部 //通过cas更新新的尾部 if (tn != null) { // lagging tail advanceTail(t, tn); continue; } //超时 if (timed &amp;&amp; nanos &lt;= 0) // can't wait return null; //如果s为null，创建一个新节点 if (s == null) s = new QNode(e, isData); //将s添加到队列中，如果失败那么重试 if (!t.casNext(null, s)) // failed to link in continue; //更新尾节点，即使失败，其他节点也会进行这步操作 advanceTail(t, s); // swing tail and wait //等待匹配 Object x = awaitFulfill(s, e, timed, nanos); //匹配完成，如果x == s说明，被取消了 if (x == s) { // wait was cancelled clean(t, s); return null; } //如果节点还未从队列中移除 if (!s.isOffList()) { // not already unlinked //尝试将s置为头从队列中移除 advanceHead(t, s); // unlink if head //x!=null说明当前是插入操作 if (x != null) // and forget fields //说明节点被移除 s.item = s; s.waiter = null; } //如果是插入操作，那么返回插入的元素，移除操作，返回匹配的元素 return (x != null) ? (E)x : e; } else { // complementary-mode //如果队列存在元素并且与当前模式不同，那么就直接去队列中匹配 QNode m = h.next; // node to fulfill //只要存在其中的一种情况，就说明队列被改动过，那么重试 if (t != tail || m == null || h != head) continue; // inconsistent read //记录要匹配的元素 Object x = m.item; //如果isData == (x != null) 它们模式相同，说明已经被匹配了，重试 //x == m说明被取消了，重试 //将m的item设置为e表示匹配，如果失败重试 if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) { // lost CAS //出队并重试 advanceHead(h, m); // dequeue and retry continue; } //匹配成功 advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; } } } //等待匹配跟TransferStack中一样 Object awaitFulfill(QNode s, E e, boolean timed, long nanos) { /* Same idea as TransferStack.awaitFulfill */ final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) { if (w.isInterrupted()) s.tryCancel(e); Object x = s.item; if (x != e) return x; if (timed) { nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) { s.tryCancel(e); continue; } } if (spins &gt; 0) --spins; else if (s.waiter == null) s.waiter = w; else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); } } //节点被取消后，需要移除，pred为最开始记录尾节点，s是取消的节点 void clean(QNode pred, QNode s) { s.waiter = null; // forget thread //如果已经断开，那么提前返回 while (pred.next == s) { // Return early if already unlinked QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head //从头部向后找，如果下一个节点不为null，并且取消了，那么替换头节点 //直到队列没有其他节点，或者找到一个正常的节点为止 if (hn != null &amp;&amp; hn.isCancelled()) { advanceHead(h, hn); continue; } //记录尾节点 QNode t = tail; // Ensure consistent read for tail //如果头节点等于尾节点，那么返回 if (t == h) return; QNode tn = t.next; //如果t不为尾部节点，说明有新的节点进入到队列中，那么重试 if (t != tail) continue; //如果tn != null，说明该节点进入到队列中，但是还没有置为尾节点 //也就是确保新的节点能保证置换为尾节点，虽然其他地方也会执行这部操作 if (tn != null) { advanceTail(t, tn); continue; } //如果s不是尾节点，那么将该节点从队列中移除 if (s != t) { // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) return; } //dp表示被取消但是还未从队列中移除的节点 QNode dp = cleanMe; if (dp != null) { // Try unlinking previous cancelled node QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null); if (dp == pred) return; // s is already saved node //移除取消的节点 } else if (casCleanMe(null, pred)) return; // Postpone cleaning s } } private static final sun.misc.Unsafe UNSAFE; private static final long headOffset; private static final long tailOffset; private static final long cleanMeOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = TransferQueue.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"head\")); tailOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"tail\")); cleanMeOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"cleanMe\")); } catch (Exception e) { throw new Error(e); } }} 方法构造方法123456789//构造方法，默认使用非公平模式public SynchronousQueue() { this(false);}//构造方法，可以通过fair指定是否位公平模式public SynchronousQueue(boolean fair) { transferer = fair ? new TransferQueue&lt;E&gt;() : new TransferStack&lt;E&gt;();} 生产方法1234567891011121314151617181920212223242526//插入元素，响应中断public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); //返回null，表示被取消 if (transferer.transfer(e, false, 0) == null) { Thread.interrupted(); throw new InterruptedException(); }}//插入元素，超时阻塞，响应中断public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); if (transferer.transfer(e, true, unit.toNanos(timeout)) != null) return true; if (!Thread.interrupted()) return false; throw new InterruptedException();}//插入元素，返回成功或者失败public boolean offer(E e) { if (e == null) throw new NullPointerException(); return transferer.transfer(e, true, 0) != null;} 消费方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//获取元素，响应中断public E take() throws InterruptedException { E e = transferer.transfer(null, false, 0); //如果返回为null，说明被取消 if (e != null) return e; Thread.interrupted(); throw new InterruptedException();} //获取元素，超时阻塞，响应中断public E poll(long timeout, TimeUnit unit) throws InterruptedException { E e = transferer.transfer(null, true, unit.toNanos(timeout)); if (e != null || !Thread.interrupted()) return e; throw new InterruptedException();}//获取元素，如果被取消返回nullpublic E poll() { return transferer.transfer(null, true, 0);}//获取元素，由于SynchronousQueue中不存储元素，因此永远返回nullpublic E peek() { return null;}//将队列的元素放入指定集合中public int drainTo(Collection&lt;? super E&gt; c) { if (c == null) throw new NullPointerException(); if (c == this) throw new IllegalArgumentException(); int n = 0; for (E e; (e = poll()) != null;) { c.add(e); ++n; } return n;}//将指定个数的队列元素放入指定集合中public int drainTo(Collection&lt;? super E&gt; c, int maxElements) { if (c == null) throw new NullPointerException(); if (c == this) throw new IllegalArgumentException(); int n = 0; for (E e; n &lt; maxElements &amp;&amp; (e = poll()) != null;) { c.add(e); ++n; } return n;}","link":"/2020/03/18/SynchronousQueue/"},{"title":"【线程池】-- ThreadPoolExecutor源码解析(上)(jdk1.8)","text":"概述线程池就是一个缓存的概念，将使用完的线程放入到线程池中管理，这样有下一个任务需要执行时，直接从线程池中获取线程执行就行，避免重复的执行线程创建、销毁操作，做到线程复用，从而提高线程的利用率，还能通过线程池来对执行任务的线程进行控制，避免线程被滥用。java中通过Executors类提供了多种实现线程池的方式，以下列举常用的四种： newFixedThreadPool： 创建一个可重用固定线程数的线程池 newSingleThreadExecutor : 创建一个使用单个线程的线程池。 newCachedThreadPool： 创建一个可根据需要创建新线程的线程池 newScheduledThreadPool： 创建一个任务可延迟的线程池 以上创建线程池方法，都是以ThreadPoolExecutor为基础，等本章解析完，再来介绍上面几种创建线程池的用法。 结构 基本属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ThreadPoolExecutor extends AbstractExecutorService { //使用高3位存储线程池工作状态，使用低29位保存工作线程数量 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); //29位，用于位于操作 private static final int COUNT_BITS = Integer.SIZE - 3; //低29位用于保存线程的数量 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; //高3位：111：接受新任务并且继续处理阻塞队列中的任务(负数位移，高位补1) private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //高3位：000：不接受新任务但是会继续处理阻塞队列中的任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //高3位：001：不接受新任务，不在执行阻塞队列中的任务，中断正在执行的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS; //高3位：010：所有任务都已经完成，线程数都被回收，线程会转到TIDYING状态会继续执行模板方法 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //高3位：110：线程会转到TIDYING状态后，会执行模板方法，执行完毕后转为TERMINATED状态 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //用来保存等待被执行的任务的阻塞队列 private final BlockingQueue&lt;Runnable&gt; workQueue; private final ReentrantLock mainLock = new ReentrantLock(); //存储工作任务的集合，每次针对workers操作都需要加锁 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); private final Condition termination = mainLock.newCondition(); //记录同时运行过的最大工作线程数 private int largestPoolSize; //完成任务数 private long completedTaskCount; //创建线程的工厂 private volatile ThreadFactory threadFactory; //构造线程持时如果未指定拒绝策略，会使用该策略 private volatile RejectedExecutionHandler handler; //存活时间 private volatile long keepAliveTime; //是否允许核心线程超时，默认为false,只有非核心线程才会超时 private volatile boolean allowCoreThreadTimeOut; //核心线程数 private volatile int corePoolSize; //最大线程数，当前阻塞队列满了后，提交的任务 private volatile int maximumPoolSize; //默认执行的拒绝策略 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); private static final RuntimePermission shutdownPerm = new RuntimePermission(\"modifyThread\"); private final AccessControlContext acc;} Worker内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//继承自AQS、实现了Runnableprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable { private static final long serialVersionUID = 6138294804551838833L; //每个worker有自己的内部线程，ThreadFactory创建失败时为null final Thread thread; //初始化任务，可能为null Runnable firstTask; //完成任务数 volatile long completedTasks; //Worker构造方法，传入一个Runnable Worker(Runnable firstTask) { //&lt;1&gt;禁止线程在runWorker前被打断 setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; //通过工厂创建线程，传入自身， //因此通过thread.start后会调用Worker的run方法 this.thread = getThreadFactory().newThread(this); } //Runnable的run方法 public void run() { //执行任务，传入Worker自身 runWorker(this); } //锁是否被持有 protected boolean isHeldExclusively() { return getState() != 0; } //尝试获取锁 protected boolean tryAcquire(int unused) { //&lt;2&gt;.不允许重入 if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } //释放锁 protected boolean tryRelease(int unused) { setExclusiveOwnerThread(null); //直接设置为0 setState(0); return true; } public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } //如果线程已经开始了，那么中断 void interruptIfStarted() { Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) { try { t.interrupt(); } catch (SecurityException ignore) { } } }} Worker继承自AQS、实现了Runnable，通过使用AQS来实现锁，从上面代码，可以获取到的几条信息： Worker创建时就已经上锁了 Worker锁不允许重入 Worker内部thread创建时，传入的是Worker自身 以下问题建议先看完后面解析，再回来看，或者你可以带着问题先往下看。 为什么Worker在创建的时候就需要上锁呢? 从interruptIdleWorkers()方法就知道，任务未开始或者正在执行的时候不应该被中断，通过锁的状态来表示任务的运行状态 在runWorker()之前，Worker的锁状态一直为-1，表示未开始。随后runWorker()方法会释放Worker的锁，将它状态变为-1，表示可以被中断。获取到任务后runWorker()又会获取锁，表示任务正在执行，不可被中断，并且不可并发执行，此时锁状态为1。 所以Worker锁有三种状态：-1表示Worker被初始化后还未执行，不可被中断；0表示Worker准备开始执行(可被中断)或者已经执行结束；1表示Worker正在执行，不可被中断。 为什么Worker锁不允许重入? 如果Worker为重入锁，那么runWorker()中反复执行阻塞队列中的任务的时候， 就有可能同一个线程同时执行多个任务。 为什么Worker内部thread创建时，传入的是Worker自身？ 用户调用execute()方法,执行一个任务时，会传入一个Runnable，通过addWorker()方法后，会通过Runnable创建一个Worker，因此Worker内部既有一把锁，也有一个Runnable任务，执行thread.start时，实际上执行的是Runnable中的任务，而Worker又可以作为一把锁，保证执行的任务不会被中断 方法ctl相关方法123456789101112131415161718192021222324252627282930313233343536373839// 根据ctl计算runState，使用&amp;运算时，~CAPACITY表示只有高3位参与了计算private static int runStateOf(int c) { return c &amp; ~CAPACITY; }// 根据ctl计算workerCount，表示只有低29位参与了计算private static int workerCountOf(int c) { return c &amp; CAPACITY; }// 根据runState和workerCount计算clt值，rs的高3位与wc的低29通过|计算就是ctl的结果private static int ctlOf(int rs, int wc) { return rs | wc; }private static boolean runStateLessThan(int c, int s) { return c &lt; s;}private static boolean runStateAtLeast(int c, int s) { return c &gt;= s;}//判断是否为运行状态private static boolean isRunning(int c) { return c &lt; SHUTDOWN;}//工作线程数+1，失败返回falseprivate boolean compareAndIncrementWorkerCount(int expect) { return ctl.compareAndSet(expect, expect + 1);}//工作线程数-1，失败返回falseprivate boolean compareAndDecrementWorkerCount(int expect) { return ctl.compareAndSet(expect, expect - 1);}//工作线程数-1，直到成功为止private void decrementWorkerCount() { do {} while (! compareAndDecrementWorkerCount(ctl.get()));}//判断线程池是否被关闭的方法public boolean isShutdown() { return ! isRunning(ctl.get());} 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//该构造方法无需指定线程工厂，使用默认线程工厂defaultThreadFactory//该构造方法无需指定拒绝策略，使用默认的defaultHandlerpublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);}//该构造方法无需指定拒绝策略，使用默认的defaultHandlerpublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);}//该构造方法无需指定线程工厂，使用默认线程工厂defaultThreadFactorypublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);}//corePoolSize：核心线程数//maximumPoolSize：最大线程数//keepAliveTime：线程存活时间//unit：线程存活时间单位//workQueue：线程等待队列//threadFactory：线程工厂//handler： 拒绝策略public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;}//默认线程工厂public static ThreadFactory defaultThreadFactory() { //该类在Executors.class中 return new DefaultThreadFactory();} submit方法submit()方法在父类AbstractExecutorService.clss中，跟execute()方法不同的是submit()方法有返回值。通过返回的Future对象调用它的Future.get()方法，可以获取到任务执行完成后的返回值。 本章主要通过execute()方法，来展开分析线程池的运作机制，因此submit()方法具体细节留到了下一章 1234567891011121314151617181920212223242526//Runnable没有返回值public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); //将Runnable包装成RunnableFuture，Runnable没有返回值，默认返回null RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); //最终还是执行的execute(Runnable command)方法 execute(ftask); return ftask;}//Runnable没有返回值，可以指定一个result作为Runnable返回值，//任务完成后可以通过Future.get()获取到resultpublic &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;}//Callable自带返回值，任务完成后可以通过Future.get()获取到Callable中的返回值public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;} execute方法执行一个任务，大致分为三步： 当工作线程数小于核心线程数时，会通过addWorker(command, true)新建一个核心线程执行任务，成功后直接返回 如果核心线程没有空闲，且线程池还处于运行状态，那么通过workQueue.offer(command)将任务添加到阻塞队列 BlockingQueue 中等待执行，重新检查线程池状态后，如果此时线程池被关闭了，那么 remove(command)移除刚才添加的任务，如果未关闭，判断是否存在工作线程，如果不存在那么添加一个非核心线程执行任务,用于执行刚才offer到队列中的任务。 通过addWorker(command, false)创建一个非核心线程执行任务，如果失败，说明线程达到最大线程数，那么执行拒绝策略 123456789101112131415161718192021222324252627282930313233343536373839404142public void execute(Runnable command) { if (command == null) throw new NullPointerException(); //检查当前线程池状态 int c = ctl.get(); //&lt;1&gt;.如果工作线程小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) { //创建一个核心线程来执行当前command，如果执行成功，直接返回 //返回false，说明添加任务被拒绝了，或者command未执行 if (addWorker(command, true)) return; //检查线程池状态 c = ctl.get(); } //&lt;2&gt;.如果当前为运行状态，添加任务到阻塞队列中，如果失败说明阻塞队列已满 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { //重新检查线程池状态，因为状态有可能被其他线程操作改变 int recheck = ctl.get(); //如果不是运行状态，被其他线程给中断了，移除刚刚添加到阻塞队列中的任务 if (! isRunning(recheck) &amp;&amp; remove(command)) //移除成功后执行拒绝方法 reject(command); //如果是运行状态但是没有线程来执行这个任务 else if (workerCountOf(recheck) == 0) //创建一个非核心线程执行任务，传入的firstTask为null， //是因为刚才通过offer已经将任务添加到阻塞队列中了，直接去队列中获取任务就行了 addWorker(null, false); } //&lt;3&gt;如果阻塞队列也满了，那么创建一个非核心线程执行任务 //失败说明超过了最大线程数，那么执行拒绝策略 else if (!addWorker(command, false)) //详解看下面拒绝策略 reject(command);}//将任务从队列中移除public boolean remove(Runnable task) { boolean removed = workQueue.remove(task); //尝试终止线程池 tryTerminate(); // In case SHUTDOWN and now empty return removed;} addWorker方法添加一个工作线程用于执行任务，firstTask表示要执行的任务(可以为null )，core表示是否使用核心线程来作为是否新建任务的条件。那么通过传入不同的参数，有以下四种情况，execute方法用到了下面的三种： addWorker(command, true)：创建核心线程来执行command任务，如果核心线程没有空闲，那么返回false addWorker(null, false)：创建非核心线程来执行阻塞队列workQueue中的任务，如果已经达到最大线程数，那么返回false addWorker(command, false)：创建非核心线程来执行command任务，如果已经达到最大线程数，那么返回false addWorker(null, true)，创建核心线程来执行阻塞队列workQueue中的任务，如果核心线程没有空闲，那么返回false 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { //检查线程池状态 int c = ctl.get(); //获取运行状态 int rs = runStateOf(c); /** * 1.rs &gt;= SHUTDOWN 表示线程已关闭,不能接受新的任务 * 2.如果rs != SHUTDOWN,说明线程状态为STOP, TIDYING或TERMINATED的时候 * 这个时候不会接受新的任务，直接返回false * 3.firstTask != null(表示为新的任务),线程状态为SHUTDOWN， * 但是firstTask != null的时候，也不能接受任务 * 4.线程状态为SHUTDOWN，并且firstTask == null * 但是等待线程为空的时候（说明等待队列中已经没有可执行的任务了），也不能接受新的任务 * 5.总结下来就是，如果rs为SHUTDOWN，只有firstTask == null，并且等待线程不为空的时候 * 才能接受本次添加工作任务的操作，这样也跟上面说的语义符合：SHUTDOWN不接受新任务但是 * 会继续处理阻塞队列中的任务 */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; //自旋重试 for (;;) { //记录工作线程数 int wc = workerCountOf(c); //1.wc &gt;= CAPACITY，如果大于或者等于最大容量了，返回false //2.是创建核心线程，如果是，判断当前数量是否大于等于核心线程数， //否则判断是否大于等于最大线程数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //工作线程+1，失败说明工作线程的值被其他线程改变了，跳出当前循环 if (compareAndIncrementWorkerCount(c)) break retry; //重新获取线程池状态，因为状态有可能被其他线程改变 c = ctl.get(); // Re-read ctl //如果运行状态被改变了，重试 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } //任务是否开始 boolean workerStarted = false; //是否成功添加了任务 boolean workerAdded = false; Worker w = null; try { //创建一个新的任务线程 w = new Worker(firstTask); //获取执行任务线程（由线程工厂创建，可能会失败） final Thread t = w.thread; //如果创建线程失败，会进入到finally中执行addWorkerFailed方法 if (t != null) { final ReentrantLock mainLock = this.mainLock; //加锁，避免出现并发问题 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. //检查运行状态 int rs = runStateOf(ctl.get()); //1.线程池状态为RUNNING //2.线程池状态为SHUTDOWN，并且firstTask == null //前面说了firstTask == null表示任务已经加入到阻塞队列中了，直接去取任务就行了 //说明线程池在SHUTDOWN状态下，也能执行阻塞队列中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { //线程还没start情况下，如果t的状态为alive，说明线程状态异常 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //将要执行的任务记录到workers中，由于workers是一个HashSet， //因此需要lock保证线程安全 workers.add(w); int s = workers.size(); //largestPoolSize替换为较大值,记录线程池创建过的最大线程数 if (s &gt; largestPoolSize) largestPoolSize = s; //标记创建线程成功 workerAdded = true; } } finally { mainLock.unlock(); } //如果添加了任务，那么执行 if (workerAdded) { //最终会调用w的run方法，执行runWorker方法 t.start(); //标记任务已开始 workerStarted = true; } } } finally { //如果任务没有开始，说明任务没有创建成功 //那么前面将任务线程数+1的操作就要减掉，如果任务线程已经加入到了workers中，也需要移除 if (! workerStarted) //执行任务失败的操作 addWorkerFailed(w); } return workerStarted; } addWorker中方法分为两大步骤：外层的for循环，try代码块 for循环结束的四种情况： 线程池状态为SHUTDOWN，并且firstTask != null，直接返回false，结束addWorker方法 线程池状态为STOP、TIDYING或TERMINATED，直接返回false，结束addWorker方法 添加到核心线程，如果核心线程没有空闲，那么直接返回false。如果添加到非核心线程，如果超过最大线程数，那么直接返回false 线程池如果允许添加任务线程，则将工作线程数+1，如果成功跳出for循环，准备执行try代码块中的逻辑 通过上面三种情况也能看出，for循环的主要作用，确保当前线程池状态允许接收新的任务，如果可以就将工作线程数+1直到成功，否则直接结束addWorker方法。而只有两种情况还能执行下一步，要么线程池状态为RUNNING，要么线程池状态为SHUTDOWN并且firstTask == null 。 try代码块： 创建一个任务线程Worker，如果Worker内部通过线程工厂创建失败，那么会直接执行最后的finally块中的 addWorkerFailed(w)方法。 Worker创建成功后，在两种情况下才可以执行任务，要么线程池状态为RUNNING，要么线程池状态为SHUTDOWN，且firstTask == null（表示执行阻塞队列中的任务），否则会执行最后的finally块中的 addWorkerFailed(w)方法。 将要执行的任务记录到workers集合，由于workers是一个HashSet，因此需要lock加锁保证线程安全 通过Worker中的Thread.start()启动执行任务，最终会调用runWorker(Worker w)传入当前的Worker 任务创建失败后，也会进入到 addWorkerFailed(w)方法，将任务线程数-1，如果任务线程已经加入到了workers中，也需要移除。 runWorker方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//执行任务final void runWorker(Worker w) { Thread wt = Thread.currentThread(); //记录Worker中的任务，可能为null Runnable task = w.firstTask; w.firstTask = null; //解锁将w的状态置为0(Worker初始化时会将state置为-1)，表示开始运行，允许被中断 w.unlock(); // allow interrupts //是否出现异常 boolean completedAbruptly = true; try { /** * task != null说明执行的是新的任务 * (task = getTask()) != null，从阻塞队列中取出一个任务 * 也就是说如果传入的task为null，并且从阻塞队列中获取不到任务的情况下，就会退出while循环 */ while (task != null || (task = getTask()) != null) { //加锁 w.lock(); /** * 1.如果当前线程池的状态&gt;=STOP,并且未中断任务线程，那么就中断任务线程 * 2.检查当前线程是否被中断，再次检查线程池的状态，如果&gt;=STOP， * 并且未中断任务线程，那么就中断任务线程 * 从这一步可以看出，如果线程池的状态&gt;=STOP,那么不会执行阻塞队列中的任务并且中断 * 正在执行任务的线程 */ if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { //任务执行之前模板方法 beforeExecute(wt, task); //记录异常 Throwable thrown = null; try { //执行任务 task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { //任务执行后的模板方法 afterExecute(task, thrown); } } finally { //将task置为null，进入while循环，执行下一次任务 //这就是线程池回收线程的关键 task = null; //完整任务数+1 w.completedTasks++; w.unlock(); } } //将是否出现异常标记置为false completedAbruptly = false; } finally { //执行最终的退出方法 processWorkerExit(w, completedAbruptly); }} 释放Worker中的锁，表示Worker的线程允许被中断 判断传入的Worker中是否存在task，如果不存在，那么去通过getTask()方法去阻塞队列中获取，如果获取失败，直接执行processWorkerExit(w, completedAbruptly)退出方法 执行任务前会判断线程池的状态，如果此时线程池的状态为STOP, TIDYING、TERMINATED，并且未中断任务线程，那么就中断任务线程。 如果第一次检查线程池的状态为RUNNING或者SHUTDOWN ，那么检查当前线程是否被中断，如果被中断，那么再次检查线程池的状态，如果状态为STOP, TIDYING、TERMINATED，并且未中断任务线程，那么就中断任务线程。 如果线程池状态始终为RUNNING或者SHUTDOWN ，接下来就要准备执行任务，执行任务前会先执行前置beforeExecute(wt, task)模板方法，然后通过task.run()执行任务，任务执行完毕后，会执行后置 afterExecute(task, thrown)方法，无论执行任务期间是否抛出异常，最终都会将task置为null，并且将完成任务数量+1，task置为null后又会进入到while循环，继续从队列中获取任务执行 整个任务结束前，会执行processWorkerExit(w, completedAbruptly)退出方法。 通过该方法可以窥探出线程池复用线程的原理，也就是上面的第5步，将task置为null后，当前线程执行任务后不会立马退出，而是经过上面的while循环，继续去阻塞队列中获取未执行的任务，直到队列中不存在任务为止。 getTask方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//从阻塞队列中取出任务private Runnable getTask() { //上次轮询是否超时 boolean timedOut = false; // Did the last poll() time out? //自旋重试 for (;;) { int c = ctl.get(); //检查线程池运行状态 int rs = runStateOf(c); // Check if queue empty only if necessary. //仅在必要的时候检查队列是否为空 //只有在状态为SHUTDOWN时才会检查队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { //如果线程池状态为STOP, TIDYING、TERMINATED，或者状态为 //SHUTDOWN，但是队列为空的时候，就会执行退出 //工作线程数-1 decrementWorkerCount(); //返回null return null; } //获取工作线程数量 int wc = workerCountOf(c); // Are workers subject to culling? //当前是否线程是否允许超时 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //这几种情况下才可以获取任务 //1.当前工作线程小于最大线程数并且没有经历过超时 //2.上次虽然超时了，但是阻塞队列不为空 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) { //工作线程数-1，设置失败后重试 if (compareAndDecrementWorkerCount(c)) //返回null return null; continue; } //到了这一步说明当前工作线程还未达到最大线程数，并且未经历过超时 try { //如果设置了超时，那么超时获取队列中的任务，否则使用take()从队列中获取任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); //如果不为null,任务获取成功，返回任务 if (r != null) return r; //标记任务获取超时，进入下一次循环 timedOut = true; } catch (InterruptedException retry) { //如果线程被中断，那么将超时标记设为false //可能执行了shutdownNow方法 timedOut = false; } }} 获取任务中有三种情况会结束方法： 如果线程池状态为STOP, TIDYING、TERMINATED，或者状态为SHUTDOWN，且队列为空的时候，将工作线程数-1，成功后会返回null。 工作线程大于最大线程的，并且执行工作线程-1操作成功时，将工作线程数-1，成功后会返回null。 上次获取任务超时并且还存在工作线程时，并且执行工作线程-1操作成功时，将工作线程数-1，成功后会返回null。 上次获取任务超时并且阻塞队列为空的时候(上次获取任务失败，说明队列中已经没有任务可以获取了，再判断一次，如果没有的话直接退出) 从阻塞队列中获取到任务，返回队列中的任务 从上面方法了解到： 核心线程默认不会超时，除非设置allowCoreThreadTimeOut=true 是否为核心线程只是一个逻辑并不存在具体的标记来划分，当前是否为核心线程，是根据当前活动线程数是否大于核心线程数来判定 判定结果为非核心线程时，从阻塞队列中获取任务的操作会超时，超时后返回null，会回到runWorker()方法中会跳出while循环，而结束掉该线程。 判定结果为核心线程时，从阻塞队列中获取任务的操作不会超时，知道获取到值为止，因此一般情况下核心线程不会结束，除非设置allowCoreThreadTimeOut=true 由于判断是否为核心线程是有当前活动线程来决定的，因此任何线程都有可能成为核心线程，之前为核心线程获取到任务之后，下一次执行不一定就是核心线程。 拒绝策略1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//当达到最大线程数后，不会在接受新的任务，此时会通过此方法，执行拒绝策略final void reject(Runnable command) { //通过调用RejectedExecutionHandler #rejectedExecution方法 handler.rejectedExecution(command, this);}//线程池自带四种拒绝策略public static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { //如果线程池还处于运行状态，那么使用调用者线程来执行任务 if (!e.isShutdown()) { r.run(); } }}//默认使用的拒绝策略public static class AbortPolicy implements RejectedExecutionHandler { public AbortPolicy() { } //丢弃任务并抛出异常 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); }}public static class DiscardPolicy implements RejectedExecutionHandler { public DiscardPolicy() { } //丢弃任务 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }}public static class DiscardOldestPolicy implements RejectedExecutionHandler { public DiscardOldestPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { //如果线程池还处于运行状态，丢弃阻塞队列尾部的一个任务，将该任务加入到队列尾部 if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } }} 线程持默认提供了四种拒绝策略： CallerRunsPolicy：如果线程池还处于运行状态，那么会用调用者的线程执行任务，否则丢弃任务 AbortPolicy：丢弃任务并抛出RejectedExecutionException异常 DiscardPolicy：直接丢弃任务 DiscardOldestPolicy：如果线程池还处于运行状态，丢弃阻塞队列尾部的一个任务，将该任务加入到队列尾部 tryTerminate方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546//尝试终止线程池，回收线程，每次减少worker或者从队列中移除任务的时候都需要调用这个方法final void tryTerminate() { //自旋重试 for (;;) { //检查线程池状态 int c = ctl.get(); //1.如果线程池为RUNNING运行状态，直接返回 //2.如果线程池状态为TIDYING、TERMINATED直接返回 //3.如果线程状态为SHUTDOWN并且workQueue不为空，直接返回 //也就是说1、2、3种情况，都不会继续执行终止线程池操作 //只有线程池状态为STOP或者SHUTDOWN且workQueue为空的情况下，才会继续执行 //终止线程池操作 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; //当前线程数不为0时，才有资格终止线程池 if (workerCountOf(c) != 0) { // Eligible to terminate //中断空闲的任务线程 interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try { //将线程池运行状态设置为TIDYING，工作线程数置为0 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { //执行模板方法 terminated(); } finally { //模板方法执行完成后，将线程池状态设置为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); //awaitTermination()方法中，会调用termination.awit方法 termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } 尝试终止线程池，从这里可以看出线程池状态的变化 SHUTDOWN 一&gt; TIDYING: workQueue为空，且工作线程数为0 STOP一&gt; TIDYING：工作线程数为0 TIDYING 一&gt; TERMINATED: 执行完terminated()后 interruptIdleWorkers方法12345678910111213141516171819202122232425262728//中断空闲的线程(也就是等待从阻塞队列中获取任务的线程)private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { //遍历workers集合中的所有任务线程 for (Worker w : workers) { Thread t = w.thread; //如果任务的线程未被中断，那么尝试通过tryLock获取锁 //线程如果还未开始或者正在执行，不能获取锁 if (!t.isInterrupted() &amp;&amp; w.tryLock()) { try { //中断线程 t.interrupt(); } catch (SecurityException ignore) { } finally { //解除锁 w.unlock(); } } //如果只有一个中断完成之后，跳出循环 if (onlyOne) break; } } finally { mainLock.unlock(); }} addWorkerFailed方法1234567891011121314151617//任务创建失败后，还原任务创建前执行的其他操作private void addWorkerFailed(Worker w) { final ReentrantLock mainLock = this.mainLock; //加锁，避免多个线程并发中断 mainLock.lock(); try { //如果任务线程存在，从待执行的任务集合中去除 if (w != null) workers.remove(w); //工作线程数-1 decrementWorkerCount(); //尝试中断线程池 tryTerminate(); } finally { mainLock.unlock(); }} processWorkerExit方法1234567891011121314151617181920212223242526272829303132333435363738//调用runWorker方法完成后，会执行此方法，表示退出 completedAbruptly表示是否出现过异常private void processWorkerExit(Worker w, boolean completedAbruptly) { //如果程序退出前出现过异常，那么将当前工作线程数-1 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; //加锁，workers非线程安全 mainLock.lock(); try { //统计完成的任务数 completedTaskCount += w.completedTasks; //将任务线程从workers集合中移除 workers.remove(w); } finally { mainLock.unlock(); } //尝试终止线程池 tryTerminate(); //检查线程池状态 int c = ctl.get(); //如果线程池状态为RUNNING或者SHUTDOWN if (runStateLessThan(c, STOP)) { //如果执行的任务没出现异常 if (!completedAbruptly) { //如果允许核心线程失效，那么为0，否则为核心线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; //如果允许核心线程失效，并且阻塞队列不为空，设置min为1 if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; //如果工作线程有一个就返回 if (workerCountOf(c) &gt;= min) return; // replacement not needed } //否则创建一个任务线程，去执行阻塞队列中还未执行的任务 addWorker(null, false); }} shutdown方法停止线程池，不会接受新任务，但是会继续处理阻塞队列中的任务，中断没被执行的任务 12345678910111213141516171819202122232425262728293031323334353637383940//关闭线程池public void shutdown() { final ReentrantLock mainLock = this.mainLock; //获取锁 mainLock.lock(); try { //检查是否允许执行shutdown checkShutdownAccess(); //将线程池状态设置为SHUTDOWN advanceRunState(SHUTDOWN); //中断所有空闲的线程 interruptIdleWorkers(); //钩子方法，ScheduledThreadPoolExecutor中重写了 onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } //尝试终止线程池 tryTerminate();}//检查是否允许执行shutdownprivate void checkShutdownAccess() { SecurityManager security = System.getSecurityManager(); if (security != null) { security.checkPermission(shutdownPerm); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) security.checkAccess(w.thread); } finally { mainLock.unlock(); } }}//空方法，留给子类实现void onShutdown() {} shutdownNow方法立刻停止线程池，不接受新任务，中断正在执行的任务，不在执行阻塞队列中的任务，并返回阻塞队列中未执行的任务 12345678910111213141516171819202122232425262728293031323334353637public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { //检查是否允许执行shutdown checkShutdownAccess(); //将线程池状态设置为STOP advanceRunState(STOP); //中断所有线程 interruptWorkers(); //获取阻塞队列中未执行的任务 tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); //返回阻塞队列中未执行的任务 return tasks;}private List&lt;Runnable&gt; drainQueue() { BlockingQueue&lt;Runnable&gt; q = workQueue; ArrayList&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); //将阻塞队列中的任务添加到taskList中 q.drainTo(taskList); //确保所有的任务都已经移动到taskList中 if (!q.isEmpty()) { for (Runnable r : q.toArray(new Runnable[0])) { //从队列中移除 if (q.remove(r)) //添加到taskList中 taskList.add(r); } } return taskList;} interruptWorkers方法1234567891011//中断所有已启动的线程private void interruptWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) w.interruptIfStarted(); } finally { mainLock.unlock(); }} 总结线程池状态图","link":"/2020/03/19/ThreadPoolExecutor-1/"},{"title":"mysql总结","text":"存储引擎MySql支持多种存储引擎，通过navicat新建表可以看到，MySql一共支持7种存储引擎。我们平时听到最多的MyISAM与InnoDB就在其中。MyISAM是5.1版本之前的默认引擎，5.1之后InnoDB就成为了Mysql的默认引擎，一直沿用至今。那么这两种引擎之间有什么区别呢？ 全文检索 事务 锁 外键 数据类型 MVCC InnoDB 不支持(5.6及以上支持) 支持 支持行锁 支持 聚簇索引 支持 MyISAM 支持 不支持 只支持表锁 不支持 非聚簇索引 不支持 InnoDB与MyISAM区别： 由于MyISAM不支持事务和行锁，因此针对数据的写操作，会锁住整张表，这在高并发情况下是极为不利的。因此MyISAM只适合大量查询少量插入的场景来使用。而InnoDB支持行锁，外键，并且可以通过MVCC来支持高并发，因此在高并发下情况下，InnoDB有更好的表现。 InnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。 对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务。 InnoDB为什么推荐使用自增ID作为主键？ 自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。 InnoDb与Myisam数据存储在哪里？以什么方式？ Innodb存储文件有FRM(表框架)、IDB(索引与表数据) Myisam存储文件有FRM(表框架)、MYD(表数据)、MYI(索引数据） InnoDb四大特性 插入缓冲（insert buffer)：在MySQL5.5之前，叫插入缓冲(insert buffer)，只针对insert做了优化；现在对delete和update也有效，叫做写缓冲(change buffer)。 二次写(double write)：doublewrite buffer 自适应哈希索引(ahi)：由于通过二级索引查找数据行时，每次都要去查找对应的主键值后，才能去主键索引中找到数据行。而这种方式会导致进行了两次B+TREE的查找工作。因此Innodb存储引擎会监控对表上二级索引的查找，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引,称之为自适应哈希索引。自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。而且不需要对整张表构建哈希索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。(hash表类似于HashMap的桶) 预读(read ahead)：磁盘读写，并不是按需读取，而是按页读取，一次至少读一页数据（一般是4K），如果未来要读取的数据就在页中，就能够省去后续的磁盘IO，提高效率。 索引逻辑角度 普通索引：最基本的索引，没有任何限制。 唯一索引：要求关键字不能重复。同时增加唯一约束。 主键索引：要求关键字不能重复，也不能为NULL，同时增加主键约束，且可以被其他表应用为外键。 组合索引：将几个列作为一条索引进行检索，使用最左匹配原则。 全文索引：关键字的来源不是所有字段的数据，而是从字段中提取的特别关键词。 存储角度聚簇索引(聚集索引)特点 聚簇索引就是按照每张表的主键构造一颗B+树，用来保存索引与数据。 索引结构的叶子节点存储整张表的行数据。数据的物理存放顺序与索引顺序是一致的。 由于聚簇索引是通过主键来将数据聚集，因此使用聚簇索引的引擎不能没有主键。如果表中没有定义主键，那么 InnoDB 会选择一个唯一且非空的索引代替。如果没有这样的索引，那么InnoDB 会隐式定义一个主键，来作为聚簇索引。 聚簇索引的每个叶子节点都包含了键值、事务ID、用于事务和MVCC的回滚指针以及所有的剩余列。 聚集索引是 InnoDB引擎下主键索引的实现， InnoDB引擎中每张表只能有一个聚簇索引。 检索过程 由于聚簇索引中主键索引与数据放到了一起，所以通过主键索引来检索的之后，可以直接查找对应主键的行数据。 通过辅助索引查数据时，首先查到索引位置对应的主键值，然后通过主键值去主键索引中，查找对应的行数据。 优点 可以把相关数据保存在一起。 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快。 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。 缺点 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键。但如果不是按照主键顺序加载数据，那么加载完成后最好使用OPTIMIZE TABLE (碎片整理)命令来重新组织一下表。 更新聚簇索引的代价很高，因为会强制InooDB将每个更新的数据移动到新的位置。 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。 二级索引(辅助索引)访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。 非聚簇索引(辅助索引) 非聚簇索引是将索引与数据分开存储，索引结构的叶子节点指向了数据对应的物理地址。 由于表数据存放在独立的位置，因此辅助索引访问数据总是需要二次查找。 辅助索引叶子节点存储的不再是行的物理位置，而是主键值。 非聚集索引是 MyISAM引擎下的索引实现。 检索过程 由于非聚簇索引表数据单独存放，因此无论是通过主键索引还是二级索引的方式，都需要通过查找到的表行记录指针去查找对应的表数据。 优点： 插入速度不依赖插入顺序，插入速率快。 缺点： 检索效率低于聚簇索引，每次定位数据需要二次查找。 使用角度 覆盖索引：索引是高效找到行的一个方法，当能通过二级索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。 索引下推：索引下推具体是在复合索引的查询中，针对特定的过滤条件而进行减少回表次数而做的优化。 数据结构MySql中储存索引的方法有两种：B+TREE、HASH，MySql默认采用的B+TREE，那么为什么MySql不用其他数据结构来存储呢？ 二叉树：二分查找法，会有左倾或者右倾的情况，且不适合做范围查询。 平衡二叉树：避免的左倾和右倾，但是数据量大的时候，树高会很高，也就是IO次数会很多，并且存储的数据少。 B-Tree：相比平衡二叉树，树高是降低了，但是还是不适合范围查询，范围查询需要遍历所有数据。 B+Tree：将所有数据都放到叶子节点，所有的叶子结点使用链表相连(可以做范围查询），非叶子节点只放键值，每个数据叶中的有效数据就多了，可以减少IO次数。 B-TREE 绝对平衡树，所有的叶子节点都为同一高度。 每个节点都是一个二元数组: [key, data]，所有节点都可以存储数据。key为索引key,data为除key之外的数据。 区间查找可能需要返回上层节点重复遍历，IO操作繁琐。 B+TREE B-TREE的变种，B -TREE能解决的问题，B+TREE也能够解决（降低树的高度，增大节点存储数据量）。 非叶子节点不存储data，只存储索引，可以存放更多的索引。 Mysql中B+Tree，在经典B+Tree的基础上进行了优化，增加了双向指针。（经典的B+TREE只有单项指针） 查询所有数据时，只需要扫描所有的叶子节点，并且所有的叶子节点相连。 B+TREE磁盘读写能力更强。他的根节点和支节点不保存数据区，所以根节点和支节点同样大小的情况下，保存的关键字要比B TREE要多。而叶子节点不保存子节点引用，能用于保存更多的关键字和数据。所以，B+TREE读写一次磁盘加载的关键字比B -TREE更多。 B+TREE查询性能稳定。B+TREE数据只保存在叶子节点，每次查询数据，查询IO次数一定是稳定的。当然这个每个人的理解都不同，因为在B TREE如果根节点命中直接返回，确实效率更高。 HASH 对索引的key进行一次hash计算，计算就可以定位出数据存储的位置。 很多时候HASH索引比B+TREE索引更高效。 仅能满足“=”，“in”，不支持范围查找。 会产生hash冲突问题。 InnoDb引擎下图为innodb官方提供的架构图： ​ 下图为buffer pool结构图： 在MySql中我们插入的数据库存储引擎存储，最终持久化到磁盘。当我们查询存储的数据时，又通过存储引擎将数据加载到内存。为了加速数据的访问，MySql会将热点数据放入缓存中，避免每次去查询数据库。而我们的InnoDb作为MySql的一个存储引擎，内部的buffer pool就是为此而设计的。 buffer pool是如何被使用的呢？ 当我们通过mysql查询一条数据时，mysql从磁盘中读取到数据所属的页，mysql会先将查询的页缓存到buffer pool中，下次查询相同数据时，直接通过buffer pool中缓存的页数据。 mysql查询数据时，如果知道放入buffer pool的那个位置呢？ free链表用来记录我们buffer pool中空闲区的位置，当我们需要向buffer pool中缓存数据时，会查询free链表头部节点的下一个节点的buffer pool空闲的位置，将数据插入到该位置，并在free链表中将此节点删除。 mysql修改数据时，innodb是如何操作的？ mysql修改数据时，buffer pool中如果存放着该数据对应的页，那么此时为了同步数据，Innodb不仅需要更新buffer pool中缓存的页，还需要修改磁盘中的页。但Innodb为了避免频繁的访问磁盘，仅仅修改了buffer pool中的页数据，又通过后台线程定时将修改的数据刷新到磁盘，此时未被持久化到磁盘中的页，我们称之为脏页。此时fulsh链表就是用来记录那些buffer pool中脏页的位置。后期我们只需要定时去刷新fulsh链表，将对应找脏页的数据，刷新到磁盘即可。 如果buffer pool满了怎么办？ buffer pool默认的大小默认为128M，我们页的数据为16k，因此buffer pool总会有满的时候，那么后续查询的数据，还会存储到buffer pool中吗？这就要说到Buffer pool的淘汰机制，lru链表记录Buffer pool最近访问数据页的地址。每当读取页数据时，都会将该页位置放入lru链表的头部，lru链表本身有长度，当链表满时，lru尾部的数据就会被淘汰。(详情了解lru算法) 如果淘汰的是脏页，那么需要强制执行checkPoint，将脏页刷入磁盘。 优化点：理论上将buffer pool设置到足够大，存储的热点数据越多，效率越高。 热数据区、冷数据区？ 上面的方式也会产生一个问题。当前用户查询所有数据时，大量的数据导致lru链表节点被频繁淘汰。表扫描只是偶发的行为，但该行为会导致存放的热点数据全部失效，这显然是不合理的。因此Innodb将lru链表一分为二，分为热数据区、冷数据区。Innodb将访问到的页节点位置，加入到冷数据区的头部，这个时候热数据区与冷数据区就隔离开了，那么什么时候将页位置节点加入热数据区呢？Innodb制定了规则，新加入节点的时间点 - 上一个节点加入的时间点 &gt; 1秒，则直接加入热数据区。该方式就是为了防止全表扫描对热数据区带来的影响。因为一般频繁的全表扫描，两个节点插入的时间一般小于1秒。 什么时候Innodb将Buffer pool的脏页数据，持久化到磁盘中？如果中途MySql程序挂了呢？ InnoDB作为事务数据库采用了Write Ahead Log策略：当事务提交时，先写重做日志，再修改页。所以当数据库发生宕机导致脏页的刷新丢失时，可以通过重做日志(redo log)来完成数据的恢复。这便是事务数据库中Durability(持久性)的保证。 执行update语句时，innodb修改buffer pool数据使页成为脏页，记录到fulsh链表，修改成功之后，生成一个redo.log对象，并存放到log buffer中，如果需要持久化，那么将redo.log持久化，返回客户端修改成功。重启之后会针对redo.log对数据进行修复。redo.log持久化比较快，因为将随机IO转换为顺序IO，这也是为什么不直接修改磁盘数据的原因。 为什么redo.log有两个文件？ 从官方的图可以看出redo.log有两个文件，logfile0、logfile1。logfile0默认大小为48M,当前logfile存储满后，会切换到logfile1，但是此时logfile0中可能还有未持久化到磁盘的数据，因此当切换redo.log时，Innodb会触发的检查点(Checkpoint)，检查点会检查当前整个buffer pool中与文件中相同的数据，并将数据持久化到页中。 调优点：调大logfile的大小和个数，但是调大之后mysql重启恢复数据就会变慢（一般使用中我们很少考虑重启的恢复时间）。 开启事务的情况下，使用update整个时候需要持久化redo.log吗？ Innodb提供了三种处理方式： 事务提交时，不立即去持久化，交给后台线程，此方法缺点在于丢失数据多。 事务提交时，持久化(默认)，性能最慢，丢失数据少。 事务提交时，将redo.log写入操作系统的缓冲区，操作系统定时将日志写入硬盘。这种情况下，即时MySql挂了只要操作系统没挂，那么事务的持久化还是能保证。直接断电或者关机的情况下，就会丢失数据。 什么是Change Buffer? 前面说了当用户修改数据后，最终会将数据持久化到磁盘中的数据页。但是我们在使用mysql时，还会为MySql建立索引。如果我们修改的数据涉及到索引页，那么也应该将索引页中的数据持久化到磁盘。一张表可能有多个索引页，同时修改这么多的索引页，Innodb又是如何来优化的呢？ 根据Inoodb官方提供的架构图中，可以看到Change Buffer是属于Buffer pool的一部分。Change Buffer默认占Buffer pool中25%的空间。那么Change Buffer作用是什么？ 对于一次更新操作，innodb引擎会看更新的页是否在buffer pool中，如果在，那么直接更新buffer pool，并且写入一条redo log。这样后续的读取操作可以读到最新的值。如果不在，那么就先将本次更新操作记录到Change buffer中，而不是立刻去更新，最后再记录一条redo log。如果后面有读操作，那么再将对应的数据页载入到buffer pool中，同时将change pool中的更新操作应用到该数据页，这个过程叫做merge。当然如果系统是空闲状态，也会有后台线程去做merge过程。 change buffer仅用于更新普通索引，对唯一性索引无效，因为唯一性索引肯定要读数据页做唯一性判断的。 优化点：在多写少读的情况下，可以将Change Buffer调大(比如日志系统)。 Doublewrite buffer是什么？ inndb的16k的数据页，如果写入磁盘中。操作系统中的页数据大小只有4k，因此想要写入操作系统种，那么分四次才能写完。如果在写第二次的时候，操作系统挂掉了，或者机器断电了，最后怎么判断哪些数据改了，那些数据没改呢？ 因此Innodb将16k的页数据页分四次写入Doublewrite buffer，即使出问题了，也能通过redo.log还原。 Doublewrite buffer分四次写入磁盘中，中途写失败了，也通过redo.log来还原。 最后通过Doublewrite buffer分四次写入磁盘的页中，这种方式经历了两次磁盘IO，效率更低，但是为什么要这么做呢？ 主要还是因为磁盘无法支持原子性写入，Doublewrite buffer主要是为了解决，多次写的数据丢失的问题。 如果从Doublewrite buffer写入到磁盘业数据失败了，也能通过Doublewrite buffer来还原。 为什么不直接将数据分四次写入磁盘，然后通过redo.log来还原呢？ redo.log中记录的是对页的物理修改。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。 Binlogbinlog是属于mysql的概念，binlog功能与redo.log类似，也是用来记录mysql的操作，那么为什么Inndb为什么还要设计redo.log呢？ 因为redo.log记录的是某一页中某些数据的物理位置的数据，进行的那些修改，因此在使用redo.log时，Innodb能更快的对数据进行修复。 而Binlog记录的是执行的语句，因此恢复的效率不如redo.log。 Binlog本质上是一种逻辑日志，因此能够适用所有的存储引擎，并进行数据复制。 Binlog与redo.log一样，也是在fulsh链表后进行的持久化。 Binlog主从复制： 主从复制的场景中在Master 端会开启binlog ，然后将 binlog 发送到各个Slave 端，Slave 端重放binlog 从而达到Slave 端的数据和Master端的数据保持一致。在数据恢复场景，通过使用mysqlbinlog 工具以及对应的binlog 将数据恢复到指定的时间点。那么可以把binlog 解决的问题总结为两点，就是主从复制和数据恢复。 undo_logundo_log用于存放不同事务版本下的不同数据，undo_log中记录事务操作前的原始数据，每次数据变更都会产生undolog记录，undo_log记录分为 insert undo_log 和 update undo_log。insert操作属于insert undo_log，只针对当前事务，在insert操作后产生undo_log记录，在事务提交后删除undo_log记录，说白了就是给当前事务自己看的。update 和 delete操作属于update undo_log，会根据隔离级别不同事务版本的数据可见性不同。当事务回滚后，通过undo_log日志内容，将数据还原为原始数据。 索引优化优化点 联合索引遵循左前缀原则。 小表 (参与查询数据量小的表) 驱动大表。 避免使用IS NULL、IS NOT NULL 因为有时候不走索引。 索引避免进行进操作运算。例如：date('1970-01-01') 避免LIKE以%开头的查询，例如 A LIKE '%1'。 索引列避免隐式转换，例如字段A是一个字符串‘1’，但是查询的时候使用的 A = 1, 虽然也能查到(内部会数值类型的1转换为‘1’)，但是不会走索引。 使用OR的时候，保证OR的前后都有索引，不然该索引会失效。 查询的结果尽量保证覆盖索引，避免回表。 某些时候使用前缀索引可以提高查询效率，但是注意前缀索引不能用于覆盖索引。 MySql的全文索引不支持中文索引，基本上不会使用，一般使用搜索引擎，例如LUCENE、SOLR、ES。 对字段进行的操作，都会造成索引失效。 注意点 不要过度索引。索引越多，占用空间越大，反而性能变慢。 只对WHERE子句中频繁使用的建立索引。 尽可能使用唯一索引，重复值越少，索引效果越强。 使用短索引，如果char(255)太大，应该给它指定一个前缀长度，大部分情况下前10位或20位值基本是唯一的，那么就不要对整个列进行索引。 充分利用左前缀，这是针对复合索引，因为WHERE语句如果有AND并列，只能识别一个索引(获取记录最少的那个)，索引需要使用复合索引，那么创建时应该将WHERE最频繁的放置在左边。 索引存在，如果没有满足使用原则，也会导致索引无效。 优化步骤 开启查询缓存，优化查询。 explain你的select查询。 通过 show status 命令了解各种sql的执行频率,定位执行效率较低的sql语句。 通过explain分析低效sql的执行计划。 通过 show profile 分析sql。 通过trace分析 优化器 如何选择执行计划;确定问题并采取相应的优化措施。 隔离级别 Read uncommitted (读未提交)：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 Read committed (读已提交)：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 Repeatable read (可重复读)：这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。（当前事务查询的数据，不受其他事务影响） Serializable (串行化)：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 MVCCMVCC为了提高并发的读写性能，不用加锁就能让多个事务并发读写。InnoDB中，MVCC 是通过 readview + undolog 来实现的。 在事务中进行写入操作时，会生成一条undo_log日志。日志中记录原数据信息，以及操作数据对应的事务id。undo_log根据日志的先后生成顺序，形成了一条日志记录链表。 当用户执行查询sql时，会生成一致性视图read-view。它由执行查询时所有未提交事务id数据组和已创建的最大事务id组成。此时我们查询的数据结果需要跟read-view做比对，从undo_log日志中获取快照结果。 read-view根据生成时间不同，产生了RC,RR两种可见性。 RC：每条select创建一个新的readview ，所以导致读提交 读到的都是最新提交的。 RR：事务开始的时候创建一个readview, 一直到事务结束都用的这个readview，也就避免了不可重复读 事务读数据的原则就是： 读版本号小于等于当前版本的数据(意思就是读不到在当前事务之后修改的数据 避免了不可重复读) 读删除事务版本号大于等于当前版本的数据(意思就是如果这条数据在之后的事务里删了，当前事务也不能再读了) EXPLAIN在日常工作中我们可以通过explain这个命令，来查看某些SQL语句的执行计划，通过执行计划来定位执行中效率较低的SQL。下面是我们 参数 描述 id 选择标识符，多条语句同时执行的情况下，id值越大优先级越高，越先被执行 select_type 查询的类型。 table 输出结果集的表 partitions 匹配的分区，表分区的时候会用到 type 表的连接类型 possible_keys 查询时可能使用的索引 key 实际使用的索引 key_len 索引字段的长度，联合索引情况下，可以推算出运用了那些索引 ref 列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows 估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 filtered 按表条件过滤的行百分比 Extra 执行情况的描述和说明 以下将对explain命令中几个描述较多的参数详细介绍： select_type SIMPLE：简单SELECT，不使用UNION或子查询等 PRIMARY：子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY UNION：UNION中的第二个或后面的SELECT语句 DEPENDENT UNION： UNION中的第二个或后面的SELECT语句，取决于外面的查询 UNION RESULT： UNION的结果，union语句中第二个select开始后面所有select SUBQUERY：子查询中的第一个SELECT，结果不依赖于外部查询 DEPENDENT SUBQUERY：子查询中的第一个SELECT，依赖于外部查询 DERIVED：派生表的SELECT, FROM子句的子查询 UNCACHEABLE SUBQUERY：一个子查询的结果不能被缓存，必须重新评估外链接的第一行 type ALL：全表扫描，扫描所有叶子节点。 index：index与ALL区别为index类型只遍历索引树。 range：只搜索给定范围的行，使用一个索引来选择行。 ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。 eq_ref：类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件。 const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system。 NULL：MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 ALL 一&gt; index 一&gt; range 一&gt; ref 一&gt; eq_ref 一&gt; const 一&gt; system 一&gt; NULL（从左到右，性能从差到好）。 日常使用中尽量将SQL优化到range级别。 Extra Using where：不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 No tables used：Query语句中使用from dual 或不含任何from子句 常用命令与设置查看查询缓存 show variables like '%query_cache%';，query_cache_type=NO 表示已经开启）. 开启查询缓存 123vi /etc/my.cnfquery_cache_size = 20Mquery_cache_type = ON 重启mysql service mysql restart。 查看缓存使用情况 show status like 'qcache%'; 其中各个参数的意义如下： Qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。 Qcache_free_memory：缓存中的空闲内存。 Qcache_hits：每次查询在缓存中命中时就增大 Qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。 Qcache_lowmem_prunes：缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看;如果这个 数字在不断增长，就表示可能碎片非常严重，或者内存很少。(上面的 free_blocks和free_memory可以告诉您属于哪种情况) Qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。 Qcache_queries_in_cache：当前缓存的查询(和响应)的数量。 Qcache_total_blocks：缓存中块的数量。 对于某些不想使用缓存的语句，可以这样使用： select SQL_NO_CACHE count(*) from users where email = 'hello'; 参考资料：https://blog.csdn.net/u010900754/article/details/106744734 ​ https://www.cnblogs.com/ttaall/p/14339130.html","link":"/2020/05/04/MySqlSummary/"},{"title":"【线程池】-- ThreadPoolExecutor源码解析(下)(jdk1.8)","text":"概述​ 上一章我们主要通过execute()方法，来展开分析线程池的运作机制，这一章我们就来看看线程池中submit()这个具有返回值的方法是如何是实现的，又是如何获取返回值的。 结构AbstractExecutorService类ThreadPoolExecutor继承自AbstractExecutorService类，而submit()方法就在父类AbstractExecutorService中 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractExecutorService implements ExecutorService { //通过传入的Runnable,value来构造一个RunnableFuture， //runnable作为线程执行的任务，value作为返回值 protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { //将Runnable包装成一个FutureTask返回 return new FutureTask&lt;T&gt;(runnable, value); } //由于Callable本身就有返回值，因此不用指定 protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { //将Callable包装成一个FutureTask返回 return new FutureTask&lt;T&gt;(callable); } //提交一个任务返回一个Future，通过Future.get()方法可以获取返回值null public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } //提交一个任务返回一个Future，通过Future.get()方法可以获取返回值result public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; } //提交一个任务返回一个Future，通过Future.get()方法可以获取Callable中的返回值 public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; }} ​ Callable是一个接口，里面声明了一个具有返回值的call()方法，类似Runnable中的run()方法，不同的是call()方法具有返回值，并且可以抛出异常。 Callable接口1234@FunctionalInterfacepublic interface Callable&lt;V&gt; { V call() throws Exception;} 从AbstractExecutorService中的submit()方法可以看到，无论当你传入一个Runnable还是Callable，最终都会包装成一个FutureTask返回，我们看看FutureTask里面的结构： FutureTask类FutureTask类结构 从FutureTask结构图看到，FutureTask实现了RunnableFuture接口，而RunnableFuture又继承了Runnable和Future接口，因此FutureTask也具有RunnableFuture的特点，在成功执行run()方法后，可以通过Future访问执行结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; { private volatile int state; //任务新建正在执行中 private static final int NEW = 0; //任务即将完成 private static final int COMPLETING = 1; //任务正常执行完成 private static final int NORMAL = 2; //任务异常 private static final int EXCEPTIONAL = 3; //任务线程被取消 private static final int CANCELLED = 4; //任务线程将被中断 private static final int INTERRUPTING = 5; //任务线程已被中断 private static final int INTERRUPTED = 6; //存储传入的任务 private Callable&lt;V&gt; callable; //保存get方法返回的结果，也有可能保存的是一个异常 //这里没有使用volatile修饰，意欲何为 private Object outcome; // non-volatile, protected by state reads/writes /** The thread running the callable; CASed during run() */ //执行任务的线程 private volatile Thread runner; /** Treiber stack of waiting threads */ //等待节点，多个节点组成一个链表 private volatile WaitNode waiters; @SuppressWarnings(\"unchecked\") private V report(int s) throws ExecutionException { Object x = outcome; //如果正常执行，返回任务结果 if (s == NORMAL) return (V)x; //如果任务被取消，抛出任务CancellationException异常 if (s &gt;= CANCELLED) throw new CancellationException(); //抛出任务执行ExecutionException异常 throw new ExecutionException((Throwable)x); } //通过Callable来构造一个FutureTask public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; //初始状态为NEW this.state = NEW; // ensure visibility of callable } //通过FutureTask来构造一个FutureTask,result作为方法执行后的返回值 public FutureTask(Runnable runnable, V result) { // this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable } //Executors.class中的方法，通过RunnableAdapter将Runnable适配为一个Callable public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) { if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result); } //Executors.class的内部类，RunnableAdapter实现了Callable接口 //通过传入Runnable构造一个Callable，当使用Callable.call时，实际上 //执行的是Runnable的run方法 static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; { final Runnable task; final T result; RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } public T call() { task.run(); return result; } } //检查任务是否被取消 public boolean isCancelled() { return state &gt;= CANCELLED; } //检查任务是否执行完毕 public boolean isDone() { return state != NEW; } //取消任务，mayInterruptIfRunning为false表示不允许在线程运行时中断 public boolean cancel(boolean mayInterruptIfRunning) { //如果任务状态为NEW，如果允许中断运行中的线程，那么将任务状态设置为INTERRUPTING //否则设置为CANCELLED，如果设置失败，直接返回false //如果任务状态不为NEW，直接返回false if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try { // in case call to interrupt throws exception //如果允许在线程运行时候取消 if (mayInterruptIfRunning) { try { Thread t = runner; if (t != null) //中断线程，中断后会唤醒waiters上等待获取该任务结果的线程 t.interrupt(); } finally { // final state //将线程状态设置为INTERRUPTED UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); } } } finally { //执行任务完成方法 finishCompletion(); } //取消成功 return true; } //获取任务执行完成之后的返回值，响应中断 public V get() throws InterruptedException, ExecutionException { int s = state; //如果任务还未完成 if (s &lt;= COMPLETING) //那么阻塞等待 s = awaitDone(false, 0L); return report(s); } //超时获取任务执行完成之后的返回值，响应中断 public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { if (unit == null) throw new NullPointerException(); int s = state; //如果任务还未完成，那么阻塞等待 if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s); } //空方法 protected void done() { } //通过cas设置任务的状态为即将完成状态，成功后记录返回值 //将任务最终状态置为NORMAL //执行finishCompletion()方法完成任务 protected void set(V v) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { //记录返回值 outcome = v; //设置任务最终状态为正常执行 UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state //完成任务 finishCompletion(); } } //通过cas设置任务的状态为即将完成状态，设置成功后 //记录异常作为返回值，设置任务最终状态为EXCEPTIONAL //执行finishCompletion()方法完成任务 protected void setException(Throwable t) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { //记录返回值为异常 outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); } } //执行任务 public void run() { //如果任务状态不为NEW，或者执行任务的不是当前线程 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { //获取任务 Callable&lt;V&gt; c = callable; //任务状态为NEW的时候才执行 if (c != null &amp;&amp; state == NEW) { V result; //是否正常执行 boolean ran; try { //执行任务 result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; //如果发生异常，设置异常 setException(ex); } if (ran) //正常执行后设置 set(result); } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() //执行任务的线程置为null runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; //如果线程被中断 if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } //通过该方法可以执行多次任务，任务执行完成后不会修改线程状态，并且不会设置返回值 protected boolean runAndReset() { //如果状态不为NEW或者更改任务线程为当前线程失败，那么直接返回false if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) { try { //不设置返回结果 c.call(); // don't set result ran = true; } catch (Throwable ex) { setException(ex); } } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts s = state; //如果任务即将被中断 if (s &gt;= INTERRUPTING) //等待任务变为中断状态 handlePossibleCancellationInterrupt(s); } return ran &amp;&amp; s == NEW; } //等待任务变为中断状态 private void handlePossibleCancellationInterrupt(int s) { // It is possible for our interrupter to stall before getting a // chance to interrupt us. Let's spin-wait patiently. if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt } //等待节点 static final class WaitNode { volatile Thread thread; volatile WaitNode next; WaitNode() { thread = Thread.currentThread(); } } //完成任务操作 private void finishCompletion() { // assert state &gt; COMPLETING; //如果有线程在等待任务结果 for (WaitNode q; (q = waiters) != null;) { //将链表设置为null,然后释放等待节点中的线程 if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) { for (;;) { Thread t = q.thread; if (t != null) { q.thread = null; LockSupport.unpark(t); } WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; } break; } } done(); callable = null; // to reduce footprint } //等待完成 private int awaitDone(boolean timed, long nanos) throws InterruptedException { //计算超时时间，如果未设置超时deadline为0 final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) { //如果当前线程被中断，那么从等待节点中移除 if (Thread.interrupted()) { removeWaiter(q); //抛出中断异常 throw new InterruptedException(); } int s = state; //如果任务已经完成 if (s &gt; COMPLETING) { if (q != null) q.thread = null; //返回任务状态 return s; } //如果任务即将完成，那么让给cpu资源 else if (s == COMPLETING) // cannot time out yet Thread.yield(); //如果等待链表不存在，设置等待节点 else if (q == null) q = new WaitNode(); //将q放置到waiters前面 else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); //如果设置超时了 else if (timed) { nanos = deadline - System.nanoTime(); //判断是否超时，如果超时移除等待节点，返回任务状态 if (nanos &lt;= 0L) { removeWaiter(q); return state; } //超时阻塞 LockSupport.parkNanos(this, nanos); } //如果未设置超时，那么直接阻塞 else LockSupport.park(this); } } //移除等待节点 private void removeWaiter(WaitNode node) { if (node != null) { node.thread = null; retry: for (;;) { // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) { s = q.next; if (q.thread != null) pred = q; else if (pred != null) { pred.next = s; if (pred.thread == null) // check for race continue retry; } else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; } break; } } } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long stateOffset; private static final long runnerOffset; private static final long waitersOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = FutureTask.class; stateOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"state\")); runnerOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"runner\")); waitersOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"waiters\")); } catch (Exception e) { throw new Error(e); } }} 总结现在我们基本知道了，调用submit()方法来执行、获取返回值的一个过程，我们来回顾一下： 通过submit()来提交一个任务，无论提交的是Runnable还是Callable，最终都会包装为一个FutureTask对象，FutureTask内部有一个Callable用于存储任务，Callable的call()会返回一个执行结果，FutureTask通过get()方法可以获取到Callable任务正常执行完成后的一个结果 Callable的call()方法有结果，而我们Runnable的run()方法没有返回结果, 因此当我们通过submit传入一个Runnable时，会通过FutureTask的构造方法使用Executors.callable(runnable, result)将传入的Runnable适配Callable，创建一个RunnableAdapter适配器，并且以result作为它的返回值。 FutureTask通过get()方法到任务正常执行完成后的一个结果，如果任务此时还未完成，那么会调用awaitDone()方法创建一个WaitNode等待节点，并将它加入到以WaitNode组成的waiters链表的头部。 当任务执行正常执行完成后，会移除并释放在waiters上等待的节点线程，线程被唤醒后，如果发现结束，那么report判断是否正常结束，如果正常返回result结果，否则抛出异常。如果任务执行中被中断，那么移除waiters上等待该结果的节点，抛出异常。","link":"/2020/03/20/ThreadPoolExecutor-2/"},{"title":"【深入理解java虚拟机】-- 垃圾收集器与内存分配策略","text":"本系列内容，大量引用自《深入理解java虚拟机》，说是照抄一遍也不为过。不过作者自己也加入了一些图文用来帮助理解。 对象是否存活​ 在堆中存放着java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象之中哪些还“存活”着，那些已经“死去”(即不能再被任何途径使用的对象)。 引用计数法​ 给对象中添加一个引用计数器，每当有一个地方引用它时，计时器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象，就是不可能再被使用的。这种方式虽然实现简单、效率也很高，但是主流的java虚拟机里面没有选用引用计数法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。例如： 1234567891011Object q1 = new GcObject(); //实例1，引用数+1Object q2 = new GcObject(); //实例2，引用数+1q1.instance = q2; //将实例1中的instance熟悉指向实例2，实例2，引用数+1q2.instance = q1; //将实例2中的instance熟悉指向实例1，实例1，引用数+1q1 = null; //实例1，引用数-1q2 = null; //实例2，引用数-1//垃圾回收后，实例1，实例2还存在堆中，不会被回收//System.gc(); ​ 上面代表就描述了，引用计数器在实际使用中会出现的一个循环引用的问题。对象没有被其他地方引用，但是计数器值不为0，此时实例1、2无法被回收，也就是我们常说的内存泄漏。 ​ 之前看到过一个问题，为什么jvm知道object的细节，但是在实现q1=null这条语句之前,不先将q1内部实例全部引用设置为null(也就是将q1.instance也置为null)呢？ 问题是，虚拟机不能肯定q1.instance指向的也是垃圾，就不能随便修改它的内容。当遇到复杂的庞大的循环链结构时，我们又如何确定指向的对象会成为垃圾呢，就算是一个个寻找是否有其他对象引用，最终还是会存在循环引用问题。因此如果采用计数器法，那么必然要手动将instance置为null。 可达性分析算法​ 在主流的商用程序语言的主流实现中，都是称通过可达性分析来判断对象是否存活的。这个算法的基本思路就是通过一系列的成为“GC Roots”的对象做为起始点，从这些节点开始向下搜索，搜索所走过的路径成为引用链(Reference Chain),当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。下图中，对象5、6、7虽然互相有关联，但是他们到GC Root是不可达的，所以他们江湖判定为是可回收的对象。 在java语言中，可做为GC Root的对象包括下面几种 虚拟机栈(栈帧中的本地变量表)中引用的对象。 元空间中类静态属性引用的对象 元空间中常量引用的对象 本地方法中JNI(即一般说的Native方法)引用的对象 引用​ 无论是通过引用计数法判断对象的引用数量，还是通过可达性分析法判断对象的引用链是否可达，判断对象是否存货都与“引用“有关。JDK 1.2以前，java中的引用定义很传统：如果reference类型的数据中存储的数据代表的是另一块内存的起始地址，就成这块内存代表着一个引用。一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些”食之无味，弃之可惜“的对象就显得无能为力。 ​ 因此在JDK 1.2以后，Java对引用的概念进行了扩充，将应用分为强引用(Strong Reference)、软引用(Soft Reference)、弱引用(Weak Reference)、虚引用(Phantom Reference)四种、这4中引用强度依次逐渐减弱。 强引用：就是指在程序代码中普普遍存在的，类似”Object obj = new Object()“这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用：用来描述一些还有用，但并非必需的对象。JVM在将要发生内存溢出前，会把这些对象回收。通过SoftReference类来实现软引用。 弱引用：也是用来描述非必需对象的。当垃圾收集器工作时，无论当前内存是否足够，弱引用对象都会被回收。通过WeakReference类来实现弱引用时，可以指定一个ReferenceQueue，如果弱引用所引用的对象被回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用：是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响；也无法通过虚引用来取的一个对象实例。一个对象设置虚引用关联的唯一目的就是能在这个对象被垃圾回收时收到一个系统通知。通过PhantomReference类来实现虚引用时必须指定一个ReferenceQueue队列，目标对象被回收前，它的引用会被放入该队列。目前在NIO中，就运用了虚引用管理堆外内存，通过虚引用指向堆外内存的地址，如果被回收，那么去堆外内存中查看对象是否存在，如果存在，那么将其回收。 对象死亡判定​ 即使在可达性分析算法中不可达的对象，也并非是“非死不可的”，这个时候它们暂时处于”缓刑“阶段，要真正宣告一个对象死亡，至少要经历两次标记过程： 通过可达性分析法判断对象的引用链不可达时，进行第一次标记，并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize方法或者该方法被虚拟机调用过，虚拟机将这两种情况视为“没有必要去执行”。 如果该对象被判定为有必要执行finalize()方法，那么这个对象会被放置到一个叫做F-Queue的队列中，并在稍后由一个虚拟机自动建立的、低优先级的Finalize线程去执行它。这里所谓的”执行“就是去触发该方法，但并不会承诺等待它执行结束，这样做的原因是，如果对象在finalize()方法中执行缓慢，或者发生死循环，将会导致整个队列中的对象永久处于等待，甚至导知整个内存回收系统崩溃。 finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中拯救自己——只要重新与引用链上的一个对象重新建立关联即可，譬如将自己（this关键字）赋值给某个类变量或者成员变量，那么在第二次标记的时候就会被移除“即将回收”的集合；如果对象这时候还没有逃脱，那么就会被真的回收了。 回收方法区​ 很多人认为方法区是没有垃圾收集的，java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的”性价比“一般比较低；在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%~95%的空间，而永久代的垃圾收集效率远低于此。 ​ 永久代的垃圾收集主要回收两部分内容，废弃常量和无用的类。判断一个常量是否是”废弃常量“比较简单，而要判定一个类是否是”无用的类“的条件则相对苛刻许多。类需要同时满足一下三种条件才算是“无用的类”。 该类所有的实例都已经被回收，也就是java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对于的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里仅仅是”可以“，而不是和对象一样不使用了就必然会回收。 垃圾收集算法标记-清除算法​ 最基础的收集算法(Mark-Sweep)，顾名思义，先标记再清除。 ​ 首先标记出所有需要回收的对象，再标记完成后统一回收所有被标记的对象。之所以说是最基础的收集算法，是因为后续的收集算法都是基于这种思路改进的。 优点：简单 缺点： 效率不高，标记和清除两个过程效率都不高 标记清除后会产生大量不连续的内存碎片，空间碎片较多可能会导知以后再程序运行过程中需要分配大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 适用于老年代，一般和标记整理算法搭配使用，老年区可能经过多次GC后，才会采用标记整理的算法压缩内存 复制算法​ 为了解决效率问题，复制收集算法出现了，它将可用内存按照容量划分为大小相等的两块，每次只需使用其中的一块。当这一块内存用完了，就将存活着的对象复制到另外一块上面。然后把已经使用过的内存空间一次清理掉。这样使的每次都是对整个半区进行内存回收，也不用考虑内存碎片的问题。只要移动指针，按顺序分配内存即可，实现简单，运行高效，不足之处在于内存的使用率太低。 ​ 现在商业虚拟机都采用这种收集算法来回收新生代，有公司研究表明，新生代中的对象98&amp;都是”朝生夕死“，所以并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性地复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机中默认Eden和Survivor的大小比例是8：1，也就是每次新生代中可用内存空间为整个新生代的90%，只有10%被浪费。当然，98%的对象可回收只是一般场景下的数据，我们没法保证每次回收的都只有不多于10%的对象存货，当Survivor空间不够是，需要依赖其他内存(这里指老年代)进行分配担保(Handle Promotion)。 ​ 分配担保：如果另一块Survivor空间没有足够的空间存放上一次新生代中收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。 优点：简单，高效 缺点：内存使用率低 适用于新生代，针对频繁的回收，通过空间换时间方法提高回收的效率，同时保持内存的使用率在一个可接受的范围。 标记-整理算法​ 复制收集算法在对象存活率较高时就要较多的复制操作，效率会较低。更关键的是如果不想浪费50%的空间，就需要额外的空间进行担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 ​ 根据老年的特性，有人提出来另外一种“标记-整理”算法，标记过程与“标记-清除”算法一样，但后续的步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后清理掉端边界以外的内存。 优点：简单，节省空间 缺点：比标记-清除算法还多了整理这一步，而整理的效率也很低 适用于老年代，不会频繁的回收，同时具有压缩功能，节省老年代内存，减小触发Full GC收集的次数 分代收集算法​ 根据对象存活周期的不同将内存划分为几块。一般是把java堆分为新生代和老年代，这样就可以根据个年代的特点采用最适合的收集算法。新生代中每次垃圾收集时都发现有大批对象死去，只有少量存活，适合复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为存活率较高、没有额外的空间进行担保，就必须使用“垃圾-清除”或者“标记-整理”算法来进行回收。 hptspot的算法实现​ 前面介绍了对象存活判定算法和垃圾收集算法，而在HotSpot虚拟机上是实现这些算法时，必须对算法的执行效率有严格的考量，才能保证虚拟机高效运行。 枚举根节点​ 前面可达性分析法中说过通过GC Roots节点找引用链，通过是否可达判断对象的存活。而GC Root节点主要在全局的引用(例如常量或类静态属性)与执行上下文(例如栈帧中的本地变量表)，如何快速高效找出可作为GC Root的节点，便成为了一个问题。 ​ 可达性分析必须在一个能确保一致性的快照中进行，也就是说在执行可达性分析时，不能出现分析过程中对象引用关系还在不断发生变化的情况，否则分析结果的准确性无法得到保证。这点是导致GC进行时必须停顿所有java执行线程的其中一个重要原因，即使是在号称(几乎)不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。 ​ 由于目前主流的java虚拟机使用的都是准确性GC，所以当前执行系统停顿下来时，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放者对象的引用,在HotSpot的实现中,是使用一组称为OopMap的数据结构来达到这个目的得,在类加载完成的时候,HotSpot就把对象内什么偏移量上是什么类型的数据计算出来,在JIT编译过程中,也会在特点的位置记录下来栈和寄存器中哪些位置是引用,这样GC在扫描时就可以直接得知这些信息了。 安全点​ 枚举根节点通过OopMap中记录的数据，可以快速准确的完成GC Roots枚举，但是又会导致引用关系变化，或者说OopMap内容变化的指令非常多，如果每一条都生成对应的OopMap，将会需要大量的额外空间，这样GC的空间成本太高。因此在实际中，HotSpot也没有为每条指令都生成OopMap，只是在“特定的位置”记录这些信息，这些位置被称为安全点(Safepoint)，即程序执行时并非在所有地方都能停顿下来开始GC，只有到达安全点时才能在暂停。 ​ 安全点的选定既不能太少以至于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的，因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显的特征就是指令序列服用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。 ​ 对于Safepoint，另一个需要考虑的问题就是如何在GC发生时让所有线程都“跑”到最近的安全点上再停顿下来。有两种方案可供选择：抢先式中断和主动式中断，其中抢先式中断不需要线程的执行代码主动区配合，在GC发生时，首先把所有的线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，就让它“跑“到安全点上。不过现在几乎没有虚拟机采用抢先式中断来暂停线程而响应GC事件。 ​ 而主动中断的思想是当前GC需要中断线程的时候，不直接对线程操作，仅仅简单的设置一个标记，各个线程执行时主动去轮询这个标志，发现中断标志位真时就自己中断挂起，轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地址。 安全区域​ 前面说了通过让所有线程集中”跑“到Safepoint，来进入GC，如果此时程序处于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，去安全的地方挂起，这个时候就需要安全区域来(Safe Region)解决。 ​ 安全区域是指再一段代码片段中，引用关系不会发生变化。这个区域中任何地方GC都是安全的，可以把Safe Region看做是被扩展的Safepoint。 ​ 在线程执行到Safe Region中的代码时，首先表示自己已经进入了Safe Region，那样，当这段事件里JVM要发起GC时，就不用管标识自己的为Safe Region状态的线程了。在线程离开时，它要检查系统是否已经完成了根节点枚举(或者是整个GC过程)，如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。 垃圾收集器 ​ 上面展示了不同分代的收集器，如果两个收集器之间存在连线，就说明他们可以搭配使用。虚拟机所处的区域，则表示它属于新生代收集器还是老年代收集器。 Serial收集器​ 采用复制算法的单线程收集器，进行垃圾收集器必须暂停其他所有工作线程，直到它收集结束(Stop The Word)。由于没有线程开销，可以在单CPU环境下获得最高的单线程收集效率。比较适合在运行在Client模式下的虚拟机。 ParNew收集器​ Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、收集策略等都与Serial收集器完全一样。 除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作。 Parallel Scavenge收集器​ 使用复制算法并行的多线程新生代收集器，看起来和ParNew一样。不过Parallel Scavenge收集器关注点与其他收集器不同，CMS更关注缩短用户收集时线程的停顿时间，而Parallel Scavenge目标是达到一个可控的吞吐量。 所谓吞吐量就是CPU用于运行用户代码与CPU总消耗时间的比值，即 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)，虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 ​ 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户提亚，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互任务。 ​ Parallel Scavenge收集器提供了两个参数用于控制吞吐量，分别是最大垃圾收集停顿时间的-XX:MaxGCPauseMills参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 ​ MaxGCPauseMills参数设置一个值，收集器尽量保证内存回收花费的时间不超过设定值。但是GC停顿时间缩短是以牺牲吞吐量为代价的，比如：停顿时间设置较少，原先收集500M，现在只收集300M，但这也导致垃圾收集更频繁，原先10秒收集一次，每次停顿100毫秒，现在变为5秒收集一次，每次停顿70毫秒，停顿时间变少了，但是吞吐量也下来了。 无法与CMS收集器配合工作 Serial Old收集器​ Serial收集器的老年代版本，采用“标记-整理”算法，也是适用于Client模式下的虚拟机。不过同样适用于Server端，jdk1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，还有就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old​ 看名字就知道，是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。是jdk1.6之后才提供的，抛弃了上面的Serial Old收集器，主要是Serial Old作为一个单线程收集器会拖后腿。无法将整体应用上获得吞吐量最大化的效果。还不如ParNew+CMS给力。 ​ Parallel Scavenge+Parallel Old组合，本着“吞吐量优先”的原则，在注重吞吐量以及CPU资源敏感的场合下，都可以优先此组合。 CMS收集器​ CMS(Concurrent Mark Sweep)收集器关注于获取最短回收停顿时间为目标的收集器，基于“标记-清除”算法实现，它的运作过程比前几款收集器更复杂，整个过程分为4个步骤 初始标记(CMS initial mark): 标记GC Roots能直接关联的对象，速度很快，标记时需要Stop The World。 并发标记(CMS concurrent mark): 进行GC Roots Tracing的过程。耗时长，但是可以与用户线程一起工作。 重新标记：修正并发标记期间因用户程序继续运作而导知标记产生变动的那一部分对象的标记记录，也会Stop The World，并且停顿时间一般会比初始标记阶段稍长一些，但比并发标记时间短。 并发清楚：清除标记的垃圾，耗时长，可以与用户线程一起工作。 CMS的缺点： CMS收集器对CPU资源非常敏感。在并发阶段，会因为占用一部分线程而导致应用程序变慢，总吞吐量会降低。 无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导知另一次Full Gc的产生。由于在垃圾收集阶段用户线程还需要运行，那也就需要预留足够的内存空间给用户线程使用，因此CMS不能等到老年代满了才收集，需要预留一部分空间提供并发收集时的程序运作使用。JDK 1.6中，CMS收集器启动阈值为92%(可以通过-XX：CMSInitiatingOccupancyFraction来设置)，要是预留的内存无法满足需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机启动后备预案：临时启动Serial Old收集器来重新进行老年代的垃圾收集，这样停顿就很高了。所以说-XX：CMSInitiatingOccupancyFraction设置的太高，容易导知大量“Concurrent Mode Failure”失败，性能反而降低。 CMS基于‘“标记-清除”算法实现，收集结束时会有大量空间碎片。因此CMS收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数(默认开启)，用于在CMS收集器顶不住要进行Full GC时开启内存碎片的合并整理过程，但是副作用就是停顿时间会变长。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction,用来设置执行了多少次不压缩的Full GC后，跟着来一次带压缩的(默认为0，标识每次Full GC时都要进行碎片整理)。 G1收集器​ G1收集器中还保留着新生代，老年代的概念，但是它们不再是物理隔离的了。在G1中，内存空间被分割成一个个的Region区，所谓新生代和老年代，都是由一个个Region组成的。同时G1也不需要跟别的收集器一起配合使用，自己就可以完成所有的收集工作，一款全能收集器。 ​ 与CMS的“标记-清除”算法不同，G1从整体上看时基于“标记-整理”算法实现的收集器，从局部(两个Region之间)上来看是基于“复制”算法实现的，无论如何，这两种算法都意味着G1运行期间不会产生内存空间碎片。 ​ 在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用Remembered Set来避免全堆扫描的。G1中每一个Region都有一个与之对应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier展示中断写操作，检查Reference引用的对象是否处以不同的Region之中(在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象)，如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set中，当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。 ​ 如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为一下几个步骤： 初始标记：跟CMS收集器一样，标记GC Roots能直接关联的对象 并发标记：从GC Root开始对堆中对象进行可达性分析，找出存活对象，这步耗时久，但是可以与用户程序并发执行。 最终标记：由于并发标记阶段，用户线程仍然在运行，会对标记产生一些偏差，通过Remembered Set Log记录这些变化，此阶段会将这些变化合并到remembered set中，需要停顿线程，但是可以并行执行。 最终筛选：对各个Region回收价值和成本排序，根据用户期望的GC停顿时间来制定回收计划。 内存分配与回收策略​ 对象的内存分配，往大的方向讲，就是在对上分配(但是也有可能经过JIT编译后被拆散为标量类型并间接地栈上分配)，对象主要分配在新生代地Eden区上，如果启动了本地线程分配缓冲，则按照线程优先在TLAB上分配。少数情况下也会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 对象优先在eden分配​ 大多数情况下，对象在新生代Eden区中分配。当前Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 大对象直接进入老年代​ 所谓大对象是指，需要大量连续内存空间的对象，最典型的就是很长的字符串以及数组。虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代中分配，避免在Eden和两个Survivor区之间发生大量的内存复制。 长期存活对象进入老年代​ 虚拟机给每个对象定义了一个对象年龄计数器。Eden中的对象经历过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设置为1。每经历一次Minor GC，年龄数+1，年龄增加到一定程度(CMS默认6，其他默认15，可以通过-XX:MaxTenuringThreshold参数设置)，就会晋升到老年代中。 动态对象年龄判定​ 虚拟机并不是永远要求对象年龄必须达到MaxTenuringThreshold设置的值才能晋升到老年代，如果Survivor中相同年龄所有对象大小的总和大于Survivor空间的一般，年龄大于或者等于该年龄的对象就可以直接进入老年代。 空间分配担保​ 发生Minor GC前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保安全。如果不成立，虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用联系空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC,尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。 ​ JDK 1.6以后，规则变为只要老年代的连续空间大于新生代对象总大小或历次晋升的平均大小就行进行Minor GC，否则进行Full GC。 总结​ 垃圾收集器与内存分配策略到这里就结束了。后面会将JVM中所有的参数专门整合为一章，方便查找。:small_airplane:","link":"/2020/04/05/jvm-GarbageCollection/"},{"title":"【深入理解java虚拟机】-- 自动内存管理机制","text":"本系列内容，大量引用自《深入理解java虚拟机》，说是照抄一遍也不为过。不过作者自己也加入了一些图文用来帮助理解。 java内存区域与内存溢出异常运行时数据区域​ java虚拟机在执行java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁时间，有的区域随着虚拟机的进程的启动而存在，有的预取则依赖用户线程的启动和结束而销毁。 ​ Java虚拟机所管理的内存包括以下几个运行时数据区域：（下图中图形大小，不代表实际大小比例，只表示相对关系） ​ 从上面的图可以清晰的看出，jdk1.8之后取消了方法区，本地内存中增加了一个元空间。jdk1.8中方法区由元空间实现，现在的元空间可以看作之前的方法区(也称为永久代)。 程序计数器 程序计数器是一块较小的内存空间。它可以看作是当前线程锁执行字节码的行号指示器。在虚拟机的概念中，字节码解释器工作时就是通过改变计数器的值来选取下一条需要执行的字节码指令、分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖计数器完成。 ​ 由于java虚拟机中多线程的实现，因此每一个线程都有自己独立的程序处理器，保证各线程之间计数器不受影响。 如果线程执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果执行的是native方法，这个计数器则为空(null)。此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemotyError情况的区域。 java虚拟机栈 与程序计数器一样，java虚拟机栈也是线程私有的。他的生命周期与线程相同，虚拟机栈描述的是java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame，可以这么理解栈帧，虚拟机栈包含N个栈帧每个栈帧包含局部变量表,操作数栈，动态链接，方法出口等信息）。每个方法从调用到执行完成这个过程，就对应这一个栈帧在虚拟机栈中的入栈到出栈的过程。 局部变量表 局部变量表存放了编译期可知的各种基本数据类型（boolean,byte,char,short,int,float,long,double），对象引用（reference类型，他不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此相关的位置）和returnAddress类型（指向了一条字节码指令的地址） 其中64位长度的long和double类型会占用2个局部变量空间，其余的数据类型只会占用1个局部变量空间。局部变量表所需的内存空间在编译期间完成内存分配，当进入一个方法时，这个方法需要在帧中分配多大的内存空间是完全确定的，在方法运行期间不会改变局部变量表的大小。在java虚拟机规范中，对这个区域规定了两种异常状态：如果线程请求的栈的深度大于虚拟机允许的深度，将抛出StackOverFlowError异常（栈溢出），如果虚拟机栈可以动态扩展（现在大部分java虚拟机都可以动态扩展，只不过java虚拟机规范中也允许固定长度的java虚拟机栈），如果扩展时无法申请到足够的内存空间，就会抛出OutOfmMemoryError异常（没有足够的内存） 操作数栈、动态链接，方法出口后面的章节会讲到。 本地方法栈​ 本地方法栈与虚拟机栈所发挥的作用是相似的。区别在于虚拟机栈是为java方法服务，而本地方法栈则为虚拟机使用的native方法服务。HotSpot虚拟机中将本地方法栈和虚拟机栈合二为一。与虚拟机栈一样本地方法栈也会抛出StackOverFlowError和OutOfmMemoryError异常。 java堆​ 堆是被所有线程共享的一块内存区域，也是java虚拟机中管理的最大一块区域。几乎所有的对象实例都在这里分配，java虚拟机中虽然规定，所有的对象实例以及数组都需要在堆上分配，但是随着JIT编译器的发展与逃逸技术逐渐成熟，栈上分配、标量替换技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。 ​ java栈与堆相比，java栈存储速度比较块，但由于存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。 ​ 堆的优势是可以动态地分配内存大小，生存期也不必事先告诉编译器，因为它是在运行时动态分配内存的，Java的垃圾收集器会自动收走这些不再使用的数据。但缺点是，由于要在运行时动态分配内存，存取速度较慢。 方法区​ 方法区也被称作为”永久代“，与堆一样方法区也是线程共享的内存区域。用来存储类的信息，例如：方法，方法名，返回值，常量。当它无法满足内存分配需求时，方法区会抛出OutOfMemoryError。 ​ jdk1.7以后取消了方法区，用元空间替代。类的元信息被存储在元空间中。元空间没有使用堆内存，而是与堆不相连的本地内存区域。这样的好处就是元空间不会受到堆内存大小的限制，只跟本地内存有关，所以不会出现永久代存在时的内存溢出问题。但也不能滥用，不然会耗尽本地内存。 运行时常量池常量池：class文件常量池，是class文件的一部分，用于保存编译时确定的数据。 运行时常量池： Java语言并不要求常量一定只能在编译期产生，运行期间也可能产生新的常量，这些常量被放在运行时常量池中。类加载后，常量池中的数据会在运行时常量池中存放！ 字符串常量池： ​ HotSpot VM里，记录interned string的一个全局表叫做StringTable，它本质上就是个HashSet&lt;String&gt;。注意它只存储对java.lang.String实例的引用，而不存储String对象的内容 jdk 1.7后，移除了方法区，字符串常量池依旧保持在堆中，常量池移动到元空间中了。 元空间​ Meta Space是JDK1.8引入的，在JDK1.8使用的是方法区，永久代（Permnament Generation）。元空间存储的是元信息，使用的是操作系统的本地内存（Metaspace与PermGen之间最大的区别），可以是不连续的，由元空间虚拟机进行管理。可以产生OutOfMemoryError。 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是Java 虚拟机规范中农定义的内存区域。在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O 方式，它可以使用native 函数库直接分配堆外内存，然后通脱一个存储在Java堆中的DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 hospot虚拟机对象探秘对象的创建new指令：虚拟机遇到一条new的指令时，首先去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并检查这个符号代表的类是否已被加载、解析和初始化过。如果没有，那么先执行相对于的类加载过程。类加载检查后，接下来虚拟机将对新生对象分配内存。 分配内存： 指针碰撞：假设java堆中内存时绝对规整的，所有用过的内存放在一边，空闲的放到另外一边，中间放一个指针做为分界点的指示器，那么分配内存仅仅只需要将指针往空闲空间的那边移动与对象大小相等的距离。 空闲列表：如果java堆中内存并不是规整的，已使用和未使用的互相交错，那么就没办法使用指针碰撞了，虚拟机就必须维护一个列表，记录哪些内存块是可用的，再分配时找到一块足够大的空间，分给对象实例并记录为已使用。 使用哪种方式是由堆是否规整来决定的，而堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 使用指针碰撞来分配从内存的收集器： ​ Serial、ParNew等带Compact过程的收集器 使用空闲列表来分配从内存的收集器： ​ CMS这种基于Mark-Sweep算法(标记-清除算法)的收集器 ​ 除了如何划分可用空间外，对象的创建是否频繁也是考虑一个点。即使是修改指针位置，在并发情况下也会出现，A在计算完需要分配的内存还未移动后，B又使用原来的指针分配内存。而解决这种情况有两种方法： 采用cas+失败重试机制，保证更新的原子性（跟java中，AQS中获取锁方式一样，通过cas修改状态值，失败后，循环重试，直到成功或抛出异常为止） 把内存分配的动作按照线程划分到不同的空间中进行，即每个线程在java堆中预分配一块较小的区域，成为本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)。哪个线程需要分配内存，就在那个线程的TLAB上分配，只有TLAB用完了并分配新的TLAB时，才需要锁定。是否使用TLAB,可以通过-XX:+/-UseTLAB参数来设置。 初始化：内存分配完成之后，虚拟机需要将分配到的内存空间都初始化为0值(不包括对象头)。如果使用TLAB,这一工作过程也可以提前至TLAB分配时进行。这一步保证了对象的实例字段在java代码中不用赋初始值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。 对象的初始设置：接下来虚拟机要对对象进行必要的设置。例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄。这些信息存放在对象头中(Object Header)。根据当前虚拟机运行状态不同是否需要启用偏向锁等，对象头会有不同的设置。 init方法：上面的工作都完成之后，从虚拟机的角度看，一个新的对象已经产生了，但是从java的角度来看，对象的创建才刚刚开始，init方法还没有执行，所有的字段都还为零，所以一般来说执行new指令之后会接着执行init方法，这时候才算真正完成对象的创建。 对象的内存布局​ 在Hotspot虚拟机中，对象在内存中储存的布局可以分配三块区域：对象头(Object Header)、实例数据(Instance Data)和对其填充(Padding)。 ​ Hotspot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身运行时数据，如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程id、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称它为“Mark Word”。 以下描述，引用自https://www.cnblogs.com/duanxz/p/4967042.html 锁状态 25bit 4bit 1bit 2bit 23bit 2bit 是否偏向锁 锁标志位 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量(重量级锁)的指针 10 GC标记 空 11 偏向锁 线程ID Epoch 对象分代年龄 1 01 HotSpot虚拟机对象头Mark Word 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀(重量级锁定) 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 ​ 对象头的另一部分是类型指针，即元素指向它的类元数据的指针，虚拟机通过这个指针来确定是哪个对象的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话来说，查找对象的元数据信息并不一定要经过对象本身，另外如果对象是一个java数组，那么对象头还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通对象的元数据信息确定java对象的大小，但是从数据的元数据中却无法确认数组的大小。 Mark Word(标记字段)：对象的Mark Word部分占4个字节，其内容是一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。 Klass Pointer（Class对象指针）：Class对象指针的大小也是4个字节，其指向的位置是对象对应的Class对象（其对应的元数据对象）的内存地址 对象实际数据：这里面包括了对象的所有成员变量(无论是从父类继承下来的，还是子类中定义的)，其大小由各个成员变量的大小决定，比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节。 对齐：最后一部分是对齐填充的字节，按8个字节填充。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。对象头正好是8字节的倍数（1倍或者2倍），因此当对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。 Mrak Word 三大作用： 记录锁信息，通过更改锁标志加锁 记录GC信息，由于Mrak Word中只为对象分代年龄分配了4bit，所以记录的最大数也就是1111，转换为十进制也就是15，所以锁年龄最大为15。 记录hashcode(identifyHashCode) System类提供一个identifyHashCode(Object o)的方法，该方法返回指定对象的精确hashCode值，也是根据该对象的地址计算得到的HashCode值。当某个类的hashCode()方法被重写之后，该类实例的hashCode()的方法就不能唯一标识该对象。但是通过identifyHashCode()方法返回的依然是hashCode()值，依然是根据该对象的地址计算得到 hashCode值。所以两个对象的identifyHashCode()值相同，该对象就绝对是一个对象 对象的访问定位​ 建立对象是为了使用对象，我们的java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在java虚拟机规范中只规定了一个指向对象的引用，并没有定义通过何种方式去定位、访问堆中的对象的具体位置，所以对象的访问方式也是由虚拟机实现而定的。目前主流方式有使用句柄和直接指针两种。(hotspot使用的直接指针) 句柄：java堆中划分一块内存出来锁为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的地址信息。使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。 直接指针：java堆对象布局中就必须考虑如何放置类型数据的相关信息，而reference中存储的直接就是对象地址。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。HotSpot使用的是直接指针这种方式访问对象的。 下图为jdk 1.7中，两种访问方式定位的内存结构图，为了方便描述，将reference一分为二，实际中只会有一个reference。 放一张自己翻阅资料后，画的一张JVM内存结构图。 如果有错误，还请在评论区中指出哦。","link":"/2020/03/29/jvm-MemoryManagement/"}],"tags":[{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"阻塞队列","slug":"阻塞队列","link":"/tags/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"集合","slug":"集合","link":"/tags/%E9%9B%86%E5%90%88/"},{"name":"juc","slug":"juc","link":"/tags/juc/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"ETL","slug":"ETL","link":"/tags/ETL/"},{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"工具","slug":"工具","link":"/tags/%E5%B7%A5%E5%85%B7/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"class","slug":"class","link":"/tags/class/"},{"name":"DDD","slug":"DDD","link":"/tags/DDD/"},{"name":"架构","slug":"架构","link":"/tags/%E6%9E%B6%E6%9E%84/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"loc","slug":"loc","link":"/tags/loc/"},{"name":"线程池","slug":"线程池","link":"/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"内存","slug":"内存","link":"/tags/%E5%86%85%E5%AD%98/"}],"categories":[{"name":"源码","slug":"源码","link":"/categories/%E6%BA%90%E7%A0%81/"},{"name":"集合","slug":"源码/集合","link":"/categories/%E6%BA%90%E7%A0%81/%E9%9B%86%E5%90%88/"},{"name":"阻塞队列","slug":"源码/阻塞队列","link":"/categories/%E6%BA%90%E7%A0%81/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"name":"并发","slug":"源码/并发","link":"/categories/%E6%BA%90%E7%A0%81/%E5%B9%B6%E5%8F%91/"},{"name":"大数据","slug":"大数据","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"},{"name":"架构","slug":"架构","link":"/categories/%E6%9E%B6%E6%9E%84/"},{"name":"ETL","slug":"大数据/ETL","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/ETL/"},{"name":"spring","slug":"源码/spring","link":"/categories/%E6%BA%90%E7%A0%81/spring/"},{"name":"线程池","slug":"源码/线程池","link":"/categories/%E6%BA%90%E7%A0%81/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"docker","slug":"工具/docker","link":"/categories/%E5%B7%A5%E5%85%B7/docker/"},{"name":"redis","slug":"工具/redis","link":"/categories/%E5%B7%A5%E5%85%B7/redis/"},{"name":"mysql","slug":"工具/mysql","link":"/categories/%E5%B7%A5%E5%85%B7/mysql/"},{"name":"垃圾回收","slug":"jvm/垃圾回收","link":"/categories/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"内存","slug":"jvm/内存","link":"/categories/jvm/%E5%86%85%E5%AD%98/"}]}